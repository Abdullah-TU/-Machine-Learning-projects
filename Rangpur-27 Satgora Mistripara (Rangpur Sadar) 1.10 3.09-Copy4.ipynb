{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6d594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a51831ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Rangpur_Tave</th>\n",
       "      <th>Rangpur_PRCP</th>\n",
       "      <th>Rangpur_NDVI</th>\n",
       "      <th>IOD_Value</th>\n",
       "      <th>SOI_Value</th>\n",
       "      <th>Nina3.4_Value</th>\n",
       "      <th>MEI_Value</th>\n",
       "      <th>Rangpur-27 Satgora Mistripara (Rangpur Sadar)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.1993</td>\n",
       "      <td>15.1</td>\n",
       "      <td>49</td>\n",
       "      <td>0.1763</td>\n",
       "      <td>-0.025962</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.925</td>\n",
       "      <td>3.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02.01.1993</td>\n",
       "      <td>15.1</td>\n",
       "      <td>49</td>\n",
       "      <td>0.1763</td>\n",
       "      <td>-0.025962</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.925</td>\n",
       "      <td>3.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03.01.1993</td>\n",
       "      <td>15.1</td>\n",
       "      <td>49</td>\n",
       "      <td>0.1763</td>\n",
       "      <td>-0.025962</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.925</td>\n",
       "      <td>3.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04.01.1993</td>\n",
       "      <td>15.1</td>\n",
       "      <td>49</td>\n",
       "      <td>0.1763</td>\n",
       "      <td>-0.025962</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.925</td>\n",
       "      <td>3.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05.01.1993</td>\n",
       "      <td>15.1</td>\n",
       "      <td>49</td>\n",
       "      <td>0.1763</td>\n",
       "      <td>-0.025962</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.925</td>\n",
       "      <td>3.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9126</th>\n",
       "      <td>27.12.2017</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1372</td>\n",
       "      <td>-0.204937</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>2.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9127</th>\n",
       "      <td>28.12.2017</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1372</td>\n",
       "      <td>-0.204937</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>2.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9128</th>\n",
       "      <td>29.12.2017</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1372</td>\n",
       "      <td>-0.204937</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>2.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9129</th>\n",
       "      <td>30.12.2017</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1372</td>\n",
       "      <td>-0.204937</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>2.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9130</th>\n",
       "      <td>31.12.2017</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1372</td>\n",
       "      <td>-0.204937</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>2.800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9131 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Rangpur_Tave  Rangpur_PRCP  Rangpur_NDVI  IOD_Value  \\\n",
       "0     01.01.1993          15.1            49        0.1763  -0.025962   \n",
       "1     02.01.1993          15.1            49        0.1763  -0.025962   \n",
       "2     03.01.1993          15.1            49        0.1763  -0.025962   \n",
       "3     04.01.1993          15.1            49        0.1763  -0.025962   \n",
       "4     05.01.1993          15.1            49        0.1763  -0.025962   \n",
       "...          ...           ...           ...           ...        ...   \n",
       "9126  27.12.2017          22.6             0        0.1372  -0.204937   \n",
       "9127  28.12.2017          22.6             0        0.1372  -0.204937   \n",
       "9128  29.12.2017          22.6             0        0.1372  -0.204937   \n",
       "9129  30.12.2017          22.6             0        0.1372  -0.204937   \n",
       "9130  31.12.2017          22.6             0        0.1372  -0.204937   \n",
       "\n",
       "      SOI_Value  Nina3.4_Value  MEI_Value  \\\n",
       "0          -8.2           0.28      0.925   \n",
       "1          -8.2           0.28      0.925   \n",
       "2          -8.2           0.28      0.925   \n",
       "3          -8.2           0.28      0.925   \n",
       "4          -8.2           0.28      0.925   \n",
       "...         ...            ...        ...   \n",
       "9126       -1.4          -0.85     -0.404   \n",
       "9127       -1.4          -0.85     -0.404   \n",
       "9128       -1.4          -0.85     -0.404   \n",
       "9129       -1.4          -0.85     -0.404   \n",
       "9130       -1.4          -0.85     -0.404   \n",
       "\n",
       "      Rangpur-27 Satgora Mistripara (Rangpur Sadar)  \n",
       "0                                             3.286  \n",
       "1                                             3.286  \n",
       "2                                             3.286  \n",
       "3                                             3.286  \n",
       "4                                             3.286  \n",
       "...                                             ...  \n",
       "9126                                          2.800  \n",
       "9127                                          2.800  \n",
       "9128                                          2.800  \n",
       "9129                                          2.800  \n",
       "9130                                          2.800  \n",
       "\n",
       "[9131 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(r'D:\\Jupyter\\Ground water level prediction(Towfiq Sir)\\final_data_updated.xlsx')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0da445da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors in DataFrame:\n",
      "No errors found in DataFrame\n"
     ]
    }
   ],
   "source": [
    "from DataFrame_Checker import DataFrameChecker\n",
    "\n",
    "#  an instance of DataFrameChecker\n",
    "checker = DataFrameChecker(df)\n",
    "\n",
    "\n",
    "# Called the checking functions\n",
    "checker.check_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c36a8df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values found in DataFrame\n"
     ]
    }
   ],
   "source": [
    "checker.check_missing_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf276e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Rangpur_Tave', 'Rangpur_PRCP', 'Rangpur_NDVI', 'IOD_Value',\n",
      "       'SOI_Value', 'Nina3.4_Value', 'MEI_Value',\n",
      "       'Rangpur-27 Satgora Mistripara (Rangpur Sadar)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1878bf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9131 entries, 0 to 9130\n",
      "Data columns (total 9 columns):\n",
      " #   Column                                         Non-Null Count  Dtype  \n",
      "---  ------                                         --------------  -----  \n",
      " 0   Date                                           9131 non-null   object \n",
      " 1   Rangpur_Tave                                   9131 non-null   float64\n",
      " 2   Rangpur_PRCP                                   9131 non-null   int64  \n",
      " 3   Rangpur_NDVI                                   9131 non-null   float64\n",
      " 4   IOD_Value                                      9131 non-null   float64\n",
      " 5   SOI_Value                                      9131 non-null   float64\n",
      " 6   Nina3.4_Value                                  9131 non-null   float64\n",
      " 7   MEI_Value                                      9131 non-null   float64\n",
      " 8   Rangpur-27 Satgora Mistripara (Rangpur Sadar)  9131 non-null   float64\n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 642.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71c6b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "cols_to_convert = df.columns.difference(['Date'])\n",
    "\n",
    "df[cols_to_convert] = df[cols_to_convert].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8b1a0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9131.000000\n",
       "mean        3.089596\n",
       "std         0.660229\n",
       "min         1.212500\n",
       "25%         2.647500\n",
       "50%         3.125000\n",
       "75%         3.550000\n",
       "max         4.750000\n",
       "Name: Rangpur-27 Satgora Mistripara (Rangpur Sadar), dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Rangpur-27 Satgora Mistripara (Rangpur Sadar)\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00315010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9131 entries, 0 to 9130\n",
      "Data columns (total 9 columns):\n",
      " #   Column                                         Non-Null Count  Dtype  \n",
      "---  ------                                         --------------  -----  \n",
      " 0   Date                                           9131 non-null   object \n",
      " 1   Rangpur_Tave                                   9131 non-null   float64\n",
      " 2   Rangpur_PRCP                                   9131 non-null   float64\n",
      " 3   Rangpur_NDVI                                   9131 non-null   float64\n",
      " 4   IOD_Value                                      9131 non-null   float64\n",
      " 5   SOI_Value                                      9131 non-null   float64\n",
      " 6   Nina3.4_Value                                  9131 non-null   float64\n",
      " 7   MEI_Value                                      9131 non-null   float64\n",
      " 8   Rangpur-27 Satgora Mistripara (Rangpur Sadar)  9131 non-null   float64\n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 642.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e76beffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d.%m.%Y')\n",
    "\n",
    "df_train = df.loc[df['Date'].dt.year <= 2012]\n",
    "df_test = df.loc[df['Date'].dt.year >= 2013]\n",
    "\n",
    "X_train = df_train.drop(columns=['Rangpur-27 Satgora Mistripara (Rangpur Sadar)', 'Date']).to_numpy()\n",
    "y_train = df_train['Rangpur-27 Satgora Mistripara (Rangpur Sadar)'].to_numpy()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f086d309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1289\n",
      "[LightGBM] [Info] Number of data points in the train set: 5844, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 3.094913\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1289\n",
      "[LightGBM] [Info] Number of data points in the train set: 5844, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 3.094913\n",
      "Linear Regression RMSE: 0.5807501854776889\n",
      "Decision Tree RMSE: 1.0094950828885286e-15\n",
      "Random Forest RMSE: 4.518092466281155e-15\n",
      "Ridge Regression RMSE: 0.5807580200006073\n",
      "K-Nearest Neighbors RMSE: 1.6151202582352662e-16\n",
      "Gaussian Process RMSE: 1.3301686933559528e-11\n",
      "Polynomial Regression RMSE: 0.4055127033934677\n",
      "Poly Kernel RMSE: 0.405512702448706\n",
      "RBF Kernel RMSE: 1.2549158456250204e-11\n",
      "Gaussian Process Regression RMSE: 1.3301686933559528e-11\n",
      "Weighted K-NN RMSE: 1.6151202582352662e-16\n",
      "Gradient Boosting Regressor RMSE: 0.2535028161847791\n",
      "AdaBoost Regressor RMSE: 0.4390947742946434\n",
      "LightGBM Regressor RMSE: 0.006883847971166662\n",
      "CatBoost Regressor RMSE: 0.0014210994782213001\n",
      "XGBoost RMSE: 0.00019926970598050484\n",
      "LightGBM Regressor RMSE: 0.006883847971166662\n",
      "\n",
      "Linear Regression MAE: 0.4584230760351297\n",
      "Decision Tree MAE: 7.781439953567147e-16\n",
      "Random Forest MAE: 3.738890708939559e-15\n",
      "Ridge Regression MAE: 0.458384916528452\n",
      "K-Nearest Neighbors MAE: 6.094448088633645e-17\n",
      "Gaussian Process MAE: 1.2774273387505519e-11\n",
      "Polynomial Regression MAE: 0.3113893378447838\n",
      "Poly Kernel MAE: 0.3113893320696301\n",
      "RBF Kernel MAE: 8.969593491402283e-12\n",
      "Gaussian Process Regression MAE: 1.2774273387505519e-11\n",
      "Weighted K-NN MAE: 6.094448088633645e-17\n",
      "Gradient Boosting Regressor MAE: 0.1932137417962033\n",
      "AdaBoost Regressor MAE: 0.3708639272087772\n",
      "LightGBM Regressor MAE: 0.005509232341982605\n",
      "CatBoost Regressor MAE: 0.0011204719414542725\n",
      "XGBoost MAE: 0.00015809938313850414\n",
      "LightGBM Regressor MAE: 0.005509232341982605\n",
      "\n",
      "Linear Regression R-squared: 0.23790934538841502\n",
      "Decision Tree R-squared: 1.0\n",
      "Random Forest R-squared: 1.0\n",
      "Ridge Regression R-squared: 0.2378887835113066\n",
      "K-Nearest Neighbors R-squared: 1.0\n",
      "Gaussian Process R-squared: 1.0\n",
      "Polynomial Regression R-squared: 0.6284332453758397\n",
      "Poly Kernel R-squared: 0.6284332471071887\n",
      "RBF Kernel R-squared: 1.0\n",
      "Gaussian Process Regression R-squared: 1.0\n",
      "Weighted K-NN R-squared: 1.0\n",
      "Gradient Boosting Regressor R-squared: 0.854791012156572\n",
      "AdaBoost Regressor R-squared: 0.5643432385339491\n",
      "LightGBM Regressor R-squared: 0.9998929244133552\n",
      "CatBoost Regressor R-squared: 0.9999954367224799\n",
      "XGBoost R-squared: 0.9999999102756167\n",
      "LightGBM Regressor R-squared: 0.9998929244133552\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from statsmodels.nonparametric.kernel_regression import KernelReg\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU, Dense\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from tbats import TBATS\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU, Dense\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "\n",
    "\n",
    "random_state = 42 \n",
    "\n",
    "# Initialize different base models\n",
    "linear_regression = LinearRegression()\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "random_forest = RandomForestRegressor(random_state=random_state)\n",
    "ridge = Ridge()\n",
    "knn = KNeighborsRegressor()\n",
    "gaussian_process = GaussianProcessRegressor()\n",
    "poly_reg = make_pipeline(PolynomialFeatures(3), LinearRegression())\n",
    "poly_kernel = make_pipeline(StandardScaler(), PolynomialFeatures(3), LinearRegression())\n",
    "rbf_kernel = make_pipeline(StandardScaler(), GaussianProcessRegressor(kernel=None, n_restarts_optimizer=10, random_state=random_state))\n",
    "gpr = GaussianProcessRegressor(random_state=random_state)\n",
    "weighted_knn = KNeighborsRegressor(weights='distance')\n",
    "lightgbm = LGBMRegressor(random_state=random_state)\n",
    "catboost = CatBoostRegressor(random_state=random_state, verbose=0)\n",
    "xgb_model = XGBRegressor()\n",
    "lgb_regressor = lgb.LGBMRegressor()\n",
    "gbr = GradientBoostingRegressor(random_state=random_state)\n",
    "abr = AdaBoostRegressor(random_state=random_state)\n",
    "\n",
    "\n",
    "# Train each base model on the training set\n",
    "linear_regression.fit(X_train, y_train)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "ridge.fit(X_train, y_train)\n",
    "knn.fit(X_train, y_train)\n",
    "gaussian_process.fit(X_train, y_train)\n",
    "poly_reg.fit(X_train, y_train)\n",
    "poly_kernel.fit(X_train, y_train)\n",
    "rbf_kernel.fit(X_train, y_train)\n",
    "gpr.fit(X_train, y_train)\n",
    "weighted_knn.fit(X_train, y_train)\n",
    "lightgbm.fit(X_train, y_train)\n",
    "catboost.fit(X_train, y_train)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "lgb_regressor.fit(X_train, y_train)\n",
    "gbr.fit(X_train, y_train)\n",
    "abr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Train and evaluate Linear Regression\n",
    "linear_pred_val = linear_regression.predict(X_val)\n",
    "linear_rmse_val = mean_squared_error(y_val, linear_pred_val, squared=False)\n",
    "linear_mae_val = mean_absolute_error(y_val, linear_pred_val)\n",
    "linear_r2_val = r2_score(y_val, linear_pred_val)\n",
    "\n",
    "# Train and evaluate Decision Tree\n",
    "dt_pred_val = decision_tree.predict(X_val)\n",
    "dt_rmse_val = mean_squared_error(y_val, dt_pred_val, squared=False)\n",
    "dt_mae_val = mean_absolute_error(y_val, dt_pred_val)\n",
    "dt_r2_val = r2_score(y_val, dt_pred_val)\n",
    "\n",
    "# Train and evaluate Random Forest\n",
    "rf_pred_val = random_forest.predict(X_val)\n",
    "rf_rmse_val = mean_squared_error(y_val, rf_pred_val, squared=False)\n",
    "rf_mae_val = mean_absolute_error(y_val, rf_pred_val)\n",
    "rf_r2_val = r2_score(y_val, rf_pred_val)\n",
    "\n",
    "# Train and evaluate Ridge Regression\n",
    "ridge_pred_val = ridge.predict(X_val)\n",
    "ridge_rmse_val = mean_squared_error(y_val, ridge_pred_val, squared=False)\n",
    "ridge_mae_val = mean_absolute_error(y_val, ridge_pred_val)\n",
    "ridge_r2_val = r2_score(y_val, ridge_pred_val)\n",
    "\n",
    "\n",
    "# Train and evaluate K-Nearest Neighbors\n",
    "knn_pred_val = knn.predict(X_val)\n",
    "knn_rmse_val = mean_squared_error(y_val, knn_pred_val, squared=False)\n",
    "knn_mae_val = mean_absolute_error(y_val, knn_pred_val)\n",
    "knn_r2_val = r2_score(y_val, knn_pred_val)\n",
    "\n",
    "# Train and evaluate Gaussian Process\n",
    "gp_pred_val = gaussian_process.predict(X_val)\n",
    "gp_rmse_val = mean_squared_error(y_val, gp_pred_val, squared=False)\n",
    "gp_mae_val = mean_absolute_error(y_val, gp_pred_val)\n",
    "gp_r2_val = r2_score(y_val, gp_pred_val)\n",
    "\n",
    "\n",
    "# Train and evaluate Polynomial Regression\n",
    "poly_reg_pred_val = poly_reg.predict(X_val)\n",
    "poly_reg_rmse_val = mean_squared_error(y_val, poly_reg_pred_val, squared=False)\n",
    "poly_reg_mae_val = mean_absolute_error(y_val, poly_reg_pred_val)\n",
    "poly_reg_r2_val = r2_score(y_val, poly_reg_pred_val)\n",
    "\n",
    "# Train and evaluate Poly Kernel\n",
    "poly_kernel_pred_val = poly_kernel.predict(X_val)\n",
    "poly_kernel_rmse_val = mean_squared_error(y_val, poly_kernel_pred_val, squared=False)\n",
    "poly_kernel_mae_val = mean_absolute_error(y_val, poly_kernel_pred_val)\n",
    "poly_kernel_r2_val = r2_score(y_val, poly_kernel_pred_val)\n",
    "\n",
    "# Train and evaluate RBF Kernel\n",
    "rbf_kernel_pred_val = rbf_kernel.predict(X_val)\n",
    "rbf_kernel_rmse_val = mean_squared_error(y_val, rbf_kernel_pred_val, squared=False)\n",
    "rbf_kernel_mae_val = mean_absolute_error(y_val, rbf_kernel_pred_val)\n",
    "rbf_kernel_r2_val = r2_score(y_val, rbf_kernel_pred_val)\n",
    "\n",
    "# Train and evaluate Gaussian Process Regression\n",
    "gpr_pred_val = gpr.predict(X_val)\n",
    "gpr_rmse_val = mean_squared_error(y_val, gpr_pred_val, squared=False)\n",
    "gpr_mae_val = mean_absolute_error(y_val, gpr_pred_val)\n",
    "gpr_r2_val = r2_score(y_val, gpr_pred_val)\n",
    "\n",
    "# Train and evaluate Weighted K-NN\n",
    "wknn_pred_val = weighted_knn.predict(X_val)\n",
    "wknn_rmse_val = mean_squared_error(y_val, wknn_pred_val, squared=False)\n",
    "wknn_mae_val = mean_absolute_error(y_val, wknn_pred_val)\n",
    "wknn_r2_val = r2_score(y_val, wknn_pred_val)\n",
    "\n",
    "# Train and evaluate Gradient Boosting Regressor\n",
    "gbr_pred_val = gbr.predict(X_val)\n",
    "gbr_rmse_val = mean_squared_error(y_val, gbr_pred_val, squared=False)\n",
    "gbr_mae_val = mean_absolute_error(y_val, gbr_pred_val)\n",
    "gbr_r2_val = r2_score(y_val, gbr_pred_val)\n",
    "\n",
    "# Train and evaluate AdaBoost Regressor\n",
    "abr_pred_val = abr.predict(X_val)\n",
    "abr_rmse_val = mean_squared_error(y_val, abr_pred_val, squared=False)\n",
    "abr_mae_val = mean_absolute_error(y_val, abr_pred_val)\n",
    "abr_r2_val = r2_score(y_val, abr_pred_val)\n",
    "\n",
    "# Train and evaluate LightGBM Regressor\n",
    "lightgbm_pred_val = lightgbm.predict(X_val)\n",
    "lightgbm_rmse_val = mean_squared_error(y_val, lightgbm_pred_val, squared=False)\n",
    "lightgbm_mae_val = mean_absolute_error(y_val, lightgbm_pred_val)\n",
    "lightgbm_r2_val = r2_score(y_val, lightgbm_pred_val)\n",
    "\n",
    "# Train and evaluate CatBoost Regressor\n",
    "catboost_pred_val = catboost.predict(X_val)\n",
    "catboost_rmse_val = mean_squared_error(y_val, catboost_pred_val, squared=False)\n",
    "catboost_mae_val = mean_absolute_error(y_val, catboost_pred_val)\n",
    "catboost_r2_val = r2_score(y_val, catboost_pred_val)\n",
    "\n",
    "# Train and evaluate XGBoost\n",
    "xgb_pred_val = xgb_model.predict(X_val)\n",
    "xgb_rmse_val = mean_squared_error(y_val, xgb_pred_val, squared=False)\n",
    "xgb_mae_val = mean_absolute_error(y_val, xgb_pred_val)\n",
    "xgb_r2_val = r2_score(y_val, xgb_pred_val)\n",
    "\n",
    "# Train and evaluate LightGBM Regressor\n",
    "lgb_pred_val = lgb_regressor.predict(X_val)\n",
    "lgb_rmse_val = mean_squared_error(y_val, lgb_pred_val, squared=False)\n",
    "lgb_mae_val = mean_absolute_error(y_val, lgb_pred_val)\n",
    "lgb_r2_val = r2_score(y_val, lgb_pred_val)\n",
    "\n",
    "\n",
    "# Print evaluation metrics for each model on the validation set\n",
    "\n",
    "# Print the evaluation metrics for each model\n",
    "print(\"Linear Regression RMSE:\", linear_rmse_val)\n",
    "print(\"Decision Tree RMSE:\", dt_rmse_val)\n",
    "print(\"Random Forest RMSE:\", rf_rmse_val)\n",
    "print(\"Ridge Regression RMSE:\", ridge_rmse_val)\n",
    "print(\"K-Nearest Neighbors RMSE:\", knn_rmse_val)\n",
    "print(\"Gaussian Process RMSE:\", gp_rmse_val)\n",
    "print(\"Polynomial Regression RMSE:\", poly_reg_rmse_val)\n",
    "print(\"Poly Kernel RMSE:\", poly_kernel_rmse_val)\n",
    "print(\"RBF Kernel RMSE:\", rbf_kernel_rmse_val)\n",
    "print(\"Gaussian Process Regression RMSE:\", gpr_rmse_val)\n",
    "print(\"Weighted K-NN RMSE:\", wknn_rmse_val)\n",
    "print(\"Gradient Boosting Regressor RMSE:\", gbr_rmse_val)\n",
    "print(\"AdaBoost Regressor RMSE:\", abr_rmse_val)\n",
    "print(\"LightGBM Regressor RMSE:\", lightgbm_rmse_val)\n",
    "print(\"CatBoost Regressor RMSE:\", catboost_rmse_val)\n",
    "print(\"XGBoost RMSE:\", xgb_rmse_val)\n",
    "print(\"LightGBM Regressor RMSE:\", lgb_rmse_val)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Linear Regression MAE:\", linear_mae_val)\n",
    "print(\"Decision Tree MAE:\", dt_mae_val)\n",
    "print(\"Random Forest MAE:\", rf_mae_val)\n",
    "print(\"Ridge Regression MAE:\", ridge_mae_val)\n",
    "print(\"K-Nearest Neighbors MAE:\", knn_mae_val)\n",
    "print(\"Gaussian Process MAE:\", gp_mae_val)\n",
    "print(\"Polynomial Regression MAE:\", poly_reg_mae_val)\n",
    "print(\"Poly Kernel MAE:\", poly_kernel_mae_val)\n",
    "print(\"RBF Kernel MAE:\", rbf_kernel_mae_val)\n",
    "print(\"Gaussian Process Regression MAE:\", gpr_mae_val)\n",
    "print(\"Weighted K-NN MAE:\", wknn_mae_val)\n",
    "print(\"Gradient Boosting Regressor MAE:\", gbr_mae_val)\n",
    "print(\"AdaBoost Regressor MAE:\", abr_mae_val)\n",
    "print(\"LightGBM Regressor MAE:\", lightgbm_mae_val)\n",
    "print(\"CatBoost Regressor MAE:\", catboost_mae_val)\n",
    "print(\"XGBoost MAE:\", xgb_mae_val)\n",
    "print(\"LightGBM Regressor MAE:\", lgb_mae_val)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Linear Regression R-squared:\", linear_r2_val)\n",
    "print(\"Decision Tree R-squared:\", dt_r2_val)\n",
    "print(\"Random Forest R-squared:\", rf_r2_val)\n",
    "print(\"Ridge Regression R-squared:\", ridge_r2_val)\n",
    "print(\"K-Nearest Neighbors R-squared:\", knn_r2_val)\n",
    "print(\"Gaussian Process R-squared:\", gp_r2_val)\n",
    "print(\"Polynomial Regression R-squared:\", poly_reg_r2_val)\n",
    "print(\"Poly Kernel R-squared:\", poly_kernel_r2_val)\n",
    "print(\"RBF Kernel R-squared:\", rbf_kernel_r2_val)\n",
    "print(\"Gaussian Process Regression R-squared:\", gpr_r2_val)\n",
    "print(\"Weighted K-NN R-squared:\", wknn_r2_val)\n",
    "print(\"Gradient Boosting Regressor R-squared:\", gbr_r2_val)\n",
    "print(\"AdaBoost Regressor R-squared:\", abr_r2_val)\n",
    "print(\"LightGBM Regressor R-squared:\", lightgbm_r2_val)\n",
    "print(\"CatBoost Regressor R-squared:\", catboost_r2_val)\n",
    "print(\"XGBoost R-squared:\", xgb_r2_val)\n",
    "print(\"LightGBM Regressor R-squared:\", lgb_r2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6607b4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LWLR RMSE: 1.6151202582352662e-16\n",
      "LWLR MAE: 6.094448088633645e-17\n",
      "LWLR R-squared: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Define the range of neighbors to consider\n",
    "num_neighbors = 5  # You can adjust this value\n",
    "\n",
    "# Initialize LWLR model\n",
    "lwlr = KNeighborsRegressor(n_neighbors=num_neighbors, weights='distance')\n",
    "\n",
    "# Train the LWLR model\n",
    "lwlr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "lwlr_pred = lwlr.predict(X_val)\n",
    "\n",
    "# Calculate metrics for LWLR\n",
    "lwlr_rmse = mean_squared_error(y_val, lwlr_pred, squared=False)\n",
    "lwlr_mae = mean_absolute_error(y_val, lwlr_pred)\n",
    "lwlr_r2 = r2_score(y_val, lwlr_pred)\n",
    "\n",
    "# Print the evaluation metrics for LWLR\n",
    "print(\"LWLR RMSE:\", lwlr_rmse)\n",
    "print(\"LWLR MAE:\", lwlr_mae)\n",
    "print(\"LWLR R-squared:\", lwlr_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9784868b",
   "metadata": {},
   "source": [
    "Based on the evaluation metrics provided, here are the 12 best models, ranked by RMSE, MAE, and R-squared values:\n",
    "\n",
    "1. Random Forest Regressor (RMSE: 4.5129170688300314e-15, MAE: 3.731747590232183e-15, R-squared: 1.0)\n",
    "2. lwlr\n",
    "3. Poly Kernel Regression (RMSE: 1.6127342607400202e-14, MAE: 1.2373097451168137e-14, R-squared: 1.0)\n",
    "4. RBF Kernel Regression (RMSE: 8.402295816463806e-12, MAE: 7.30005059367716e-12, R-squared: 1.0)\n",
    "5. Gaussian Process Regression (RMSE: 1.3658267901830649e-11, MAE: 1.321696512977017e-11, R-squared: 1.0)\n",
    "6. Weighted K-Nearest Neighbors (RMSE: 1.6151202582352662e-16, MAE: 6.094448088633645e-17, R-squared: 1.0)\n",
    "7. K-Nearest Neighbors (RMSE: 1.6151202582352662e-16, MAE: 6.094448088633645e-17, R-squared: 1.0)\n",
    "8. XGBoost Regressor (RMSE: 0.0001604180170547465, MAE: 0.00012571969879465955, R-squared: 0.9999999418520767)\n",
    "9. CatBoost Regressor (RMSE: 0.0004191192864975924, MAE: 0.00033127405418021457, R-squared: 0.9999996030797887)\n",
    "10. LightGBM Regressor (RMSE: 0.0032090330540582293, MAE: 0.002630020414763086, R-squared: 0.9999767310759211)\n",
    "11. Gradient Boosting Regressor (RMSE: 0.2065918821936626, MAE: 0.16683381944876388, R-squared: 0.9035606162870705)\n",
    "12. Ridge Regression (RMSE: 0.525636725173341, MAE: 0.429759090595957, R-squared: 0.37569139148812536)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2275b610",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654efb57",
   "metadata": {},
   "source": [
    "## Random Forest Regressor HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db09e61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for Random Forest: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Random Forest RMSE (Validation): 2.1772740281608205e-15\n",
      "Random Forest MAE (Validation): 1.7766608018984366e-15\n",
      "Random Forest R-squared (Validation): 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Initialize Random Forest model\n",
    "random_forest = RandomForestRegressor()\n",
    "\n",
    "# Define the hyperparameters and their possible values for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],  # You can adjust these values\n",
    "    'max_depth': [None, 5, 10],      # You can adjust these values\n",
    "    'min_samples_split': [2, 5, 10] # You can adjust these values\n",
    "}\n",
    "\n",
    "# Initialize Grid Search for Random Forest\n",
    "grid_search_rf = GridSearchCV(random_forest, param_grid_rf, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Perform Grid Search for Random Forest\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for Random Forest\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "\n",
    "# Predict on validation set using Random Forest\n",
    "rf_pred_val = best_rf.predict(X_val)\n",
    "\n",
    "# Calculate metrics for Random Forest on validation set\n",
    "rf_rmse_val = mean_squared_error(y_val, rf_pred_val, squared=False)\n",
    "rf_mae_val = mean_absolute_error(y_val, rf_pred_val)\n",
    "rf_r2_val = r2_score(y_val, rf_pred_val)\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for Random Forest on validation set\n",
    "print(\"Best Hyperparameters for Random Forest:\", best_params_rf)\n",
    "print(\"Random Forest RMSE (Validation):\", rf_rmse_val)\n",
    "print(\"Random Forest MAE (Validation):\", rf_mae_val)\n",
    "print(\"Random Forest R-squared (Validation):\", rf_r2_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8227f8e",
   "metadata": {},
   "source": [
    "## 2. LWLR HPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7bbb10",
   "metadata": {},
   "source": [
    "# lwlr doesn't need hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94dbcb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for LWLR: {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "LWLR RMSE (Validation): 1.6151202582352662e-16\n",
      "LWLR MAE (Validation): 6.094448088633645e-17\n",
      "LWLR R-squared (Validation): 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Define the range of neighbors to consider\n",
    "param_grid_lwlr = {\n",
    "    'n_neighbors': [3, 5, 7],  # You can adjust these values\n",
    "    'weights': ['uniform', 'distance']  # You can adjust these values\n",
    "}\n",
    "\n",
    "# Initialize LWLR model\n",
    "lwlr = KNeighborsRegressor()\n",
    "\n",
    "# Initialize Grid Search for LWLR\n",
    "grid_search_lwlr = GridSearchCV(lwlr, param_grid_lwlr, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Perform Grid Search for LWLR\n",
    "grid_search_lwlr.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for LWLR\n",
    "best_lwlr = grid_search_lwlr.best_estimator_\n",
    "best_params_lwlr = grid_search_lwlr.best_params_\n",
    "\n",
    "# Predict on validation set using LWLR\n",
    "lwlr_pred_val = best_lwlr.predict(X_val)\n",
    "\n",
    "# Calculate metrics for LWLR on validation set\n",
    "lwlr_rmse_val = mean_squared_error(y_val, lwlr_pred_val, squared=False)\n",
    "lwlr_mae_val = mean_absolute_error(y_val, lwlr_pred_val)\n",
    "lwlr_r2_val = r2_score(y_val, lwlr_pred_val)\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for LWLR on validation set\n",
    "print(\"Best Hyperparameters for LWLR:\", best_params_lwlr)\n",
    "print(\"LWLR RMSE (Validation):\", lwlr_rmse_val)\n",
    "print(\"LWLR MAE (Validation):\", lwlr_mae_val)\n",
    "print(\"LWLR R-squared (Validation):\", lwlr_r2_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbc222b",
   "metadata": {},
   "source": [
    "## 3. Gaussian Process Regression HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "091aeeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for Gaussian Process Regression: {'kernel': None}\n",
      "Gaussian Process RMSE (Validation): 1.3301686933559528e-11\n",
      "Gaussian Process MAE (Validation): 1.2774273387505519e-11\n",
      "Gaussian Process R-squared (Validation): 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, WhiteKernel\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Define the hyperparameters and their possible values for Gaussian Process Regression\n",
    "param_grid_gpr = {\n",
    "    'kernel': [None, 1.0 * RBF(length_scale=1.0), Matern(length_scale=1.0, nu=1.5), WhiteKernel(noise_level=1.0)]   \n",
    "    \n",
    "}\n",
    "\n",
    "# Initialize Grid Search for Gaussian Process Regression\n",
    "grid_search_gpr = GridSearchCV(GaussianProcessRegressor(), param_grid_gpr, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search_gpr.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for Gaussian Process Regression\n",
    "best_gpr = grid_search_gpr.best_estimator_\n",
    "best_params_gpr = grid_search_gpr.best_params_\n",
    "\n",
    "# Predict on validation set using Gaussian Process Regression\n",
    "gpr_pred_val = best_gpr.predict(X_val)\n",
    "\n",
    "# Calculate metrics for Gaussian Process Regression on validation set\n",
    "gpr_rmse_val = mean_squared_error(y_val, gpr_pred_val, squared=False)\n",
    "gpr_mae_val = mean_absolute_error(y_val, gpr_pred_val)\n",
    "gpr_r2_val = r2_score(y_val, gpr_pred_val)\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for Gaussian Process Regression on validation set\n",
    "print(\"Best Hyperparameters for Gaussian Process Regression:\", best_params_gpr)\n",
    "print(\"Gaussian Process RMSE (Validation):\", gpr_rmse_val)\n",
    "print(\"Gaussian Process MAE (Validation):\", gpr_mae_val)\n",
    "print(\"Gaussian Process R-squared (Validation):\", gpr_r2_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d5eb90",
   "metadata": {},
   "source": [
    "## 4. Weighted K-Nearest Neighbors HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "129ba1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for Weighted K-Nearest Neighbors: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'euclidean', 'n_neighbors': 9, 'p': 1, 'weights': 'uniform'}\n",
      "Weighted K-NN RMSE (Validation): 1.439459012139203e-16\n",
      "Weighted K-NN MAE (Validation): 5.1065699695284406e-17\n",
      "Weighted K-NN R-squared (Validation): 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Define the hyperparameters and their possible values for Weighted K-Nearest Neighbors\n",
    "param_grid_wknn = {\n",
    "     'n_neighbors': [3, 5, 7, 9,11],  # Adjust as needed\n",
    "    'weights': ['uniform', 'distance'],  # These are the most common, but you can explore other weighting options if available\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Algorithm used to compute the nearest neighbors\n",
    "    'leaf_size': [10, 30, 50],  # Leaf size for tree-based algorithms\n",
    "    'p': [1, 2],  # Power parameter for the Minkowski metric\n",
    "    'metric': ['euclidean', 'manhattan']  #\n",
    "}\n",
    "\n",
    "# Initialize Grid Search for Weighted K-Nearest Neighbors\n",
    "grid_search_wknn = GridSearchCV(KNeighborsRegressor(), param_grid_wknn, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search_wknn.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for Weighted K-Nearest Neighbors\n",
    "best_wknn = grid_search_wknn.best_estimator_\n",
    "best_params_wknn = grid_search_wknn.best_params_\n",
    "\n",
    "# Predict on validation set using Weighted K-Nearest Neighbors\n",
    "wknn_pred_val = best_wknn.predict(X_val)\n",
    "\n",
    "# Calculate metrics for Weighted K-Nearest Neighbors on validation set\n",
    "wknn_rmse_val = mean_squared_error(y_val, wknn_pred_val, squared=False)\n",
    "wknn_mae_val = mean_absolute_error(y_val, wknn_pred_val)\n",
    "wknn_r2_val = r2_score(y_val, wknn_pred_val)\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for Weighted K-Nearest Neighbors on validation set\n",
    "print(\"Best Hyperparameters for Weighted K-Nearest Neighbors:\", best_params_wknn)\n",
    "print(\"Weighted K-NN RMSE (Validation):\", wknn_rmse_val)\n",
    "print(\"Weighted K-NN MAE (Validation):\", wknn_mae_val)\n",
    "print(\"Weighted K-NN R-squared (Validation):\", wknn_r2_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f7b266",
   "metadata": {},
   "source": [
    "## 5. K-Nearest Neighbors HPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9942d0aa",
   "metadata": {},
   "source": [
    "### The KNeighborsRegressor (KNN) model doesn't have traditional hyperparameters like other models (e.g., Random Forest).However, I performed hyperparameter tuning for the Locally Weighted Linear Regression (LWLR) using Grid Search with a specified range of neighbors and weight options, ultimately finding the best hyperparameters and model for LWLR, and evaluating its performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71cfb6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for KNN: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'euclidean', 'n_neighbors': 9, 'p': 1, 'weights': 'uniform'}\n",
      "KNN RMSE: 1.439459012139203e-16\n",
      "KNN MAE: 5.1065699695284406e-17\n",
      "KNN R-squared: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Define the range of neighbors and weights to consider\n",
    "param_grid = {\n",
    "     'n_neighbors': [3, 5, 7, 9,11],  # Adjust as needed\n",
    "    'weights': ['uniform', 'distance'],  # These are the most common, but you can explore other weighting options if available\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Algorithm used to compute the nearest neighbors\n",
    "    'leaf_size': [10, 30, 50],  # Leaf size for tree-based algorithms\n",
    "    'p': [1, 2],  # Power parameter for the Minkowski metric\n",
    "    'metric': ['euclidean', 'manhattan'] \n",
    "}\n",
    "\n",
    "# Initialize KNN model\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train the KNN model with the best hyperparameters\n",
    "best_knn = KNeighborsRegressor(n_neighbors=best_params['n_neighbors'], weights=best_params['weights'])\n",
    "best_knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "knn_pred = best_knn.predict(X_val)\n",
    "\n",
    "# Calculate metrics for KNN\n",
    "knn_rmse = mean_squared_error(y_val, knn_pred, squared=False)\n",
    "knn_mae = mean_absolute_error(y_val, knn_pred)\n",
    "knn_r2 = r2_score(y_val, knn_pred)\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for KNN\n",
    "print(\"Best Hyperparameters for KNN:\", best_params)\n",
    "print(\"KNN RMSE:\", knn_rmse)\n",
    "print(\"KNN MAE:\", knn_mae)\n",
    "print(\"KNN R-squared:\", knn_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dd6ad8",
   "metadata": {},
   "source": [
    "## 6. XGBoost Regressor HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7302835f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Hyperparameters for XGBoost Regressor: OrderedDict([('gamma', 0.009563585051707605), ('learning_rate', 0.13856447107447098), ('max_depth', 5), ('n_estimators', 162)])\n",
      "XGBoost RMSE (Validation): 0.02703829621550143\n",
      "XGBoost MAE (Validation): 0.02076948565339519\n",
      "XGBoost R-squared (Validation): 0.998348089305399\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "param_dist = {\n",
    "    'n_estimators': Integer(100, 300),\n",
    "    'max_depth': Integer(3, 5),\n",
    "    'learning_rate': Real(0.01, 0.2, prior='uniform'),\n",
    "    'gamma': Real(0, 0.2, prior='uniform')\n",
    "}\n",
    "\n",
    "# Initialize Bayesian Optimization for XGBoost Regressor\n",
    "bayes_search_xgb = BayesSearchCV(\n",
    "    XGBRegressor(),\n",
    "    param_dist,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_iter=10,  # Adjust the number of iterations as needed\n",
    "    random_state=42,  # Set a seed for reproducibility\n",
    "    n_jobs=-1,  # Use multiple cores for parallelization\n",
    "    verbose=1,  # Print progress\n",
    "    n_points=5,  # Number of points to sample in each iteration\n",
    "    refit=True  # Refit the best estimator with the entire dataset\n",
    ")\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "bayes_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for XGBoost Regressor\n",
    "best_xgb = bayes_search_xgb.best_estimator_\n",
    "best_params_xgb = bayes_search_xgb.best_params_\n",
    "\n",
    "# Predict on validation set using XGBoost Regressor\n",
    "xgb_pred_val = best_xgb.predict(X_val)\n",
    "\n",
    "# Calculate metrics for XGBoost Regressor on validation set\n",
    "xgb_rmse_val = mean_squared_error(y_val, xgb_pred_val, squared=False)\n",
    "xgb_mae_val = mean_absolute_error(y_val, xgb_pred_val)\n",
    "xgb_r2_val = r2_score(y_val, xgb_pred_val)\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for XGBoost Regressor on validation set\n",
    "print(\"Best Hyperparameters for XGBoost Regressor:\", best_params_xgb)\n",
    "print(\"XGBoost RMSE (Validation):\", xgb_rmse_val)\n",
    "print(\"XGBoost MAE (Validation):\", xgb_mae_val)\n",
    "print(\"XGBoost R-squared (Validation):\", xgb_r2_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466338ea",
   "metadata": {},
   "source": [
    "## 7. CatBoost Regressor  HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4729524e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Hyperparameters for CatBoost Regressor: OrderedDict([('depth', 8), ('iterations', 226), ('learning_rate', 0.19853585997384401)])\n",
      "CatBoost RMSE (Validation): 7.982628541721926e-05\n",
      "CatBoost MAE (Validation): 6.421662678767478e-05\n",
      "CatBoost R-squared (Validation): 0.9999999856014167\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "param_dist = {\n",
    "    'iterations': Integer(100, 300),\n",
    "    'depth': Integer(4, 8),\n",
    "    'learning_rate': Real(0.01, 0.2, prior='uniform')\n",
    "}\n",
    "\n",
    "# Initialize Bayesian Optimization for CatBoost Regressor\n",
    "bayes_search_catboost = BayesSearchCV(\n",
    "    CatBoostRegressor(verbose=0),\n",
    "    param_dist,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_iter=10,  # Adjust the number of iterations as needed\n",
    "    random_state=42,  # Set a seed for reproducibility\n",
    "    n_jobs=-1,  # Use multiple cores for parallelization\n",
    "    verbose=1,  # Print progress\n",
    "    n_points=5,  # Number of points to sample in each iteration\n",
    "    refit=True  # Refit the best estimator with the entire dataset\n",
    ")\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "bayes_search_catboost.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for CatBoost Regressor\n",
    "best_catboost = bayes_search_catboost.best_estimator_\n",
    "best_params_catboost = bayes_search_catboost.best_params_\n",
    "\n",
    "# Predict on validation set using CatBoost Regressor\n",
    "catboost_pred_val = best_catboost.predict(X_val)\n",
    "\n",
    "# Calculate metrics for CatBoost Regressor on validation set\n",
    "catboost_rmse_val = mean_squared_error(y_val, catboost_pred_val, squared=False)\n",
    "catboost_mae_val = mean_absolute_error(y_val, catboost_pred_val)\n",
    "catboost_r2_val = r2_score(y_val, catboost_pred_val)\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for CatBoost Regressor on validation set\n",
    "print(\"Best Hyperparameters for CatBoost Regressor:\", best_params_catboost)\n",
    "print(\"CatBoost RMSE (Validation):\", catboost_rmse_val)\n",
    "print(\"CatBoost MAE (Validation):\", catboost_mae_val)\n",
    "print(\"CatBoost R-squared (Validation):\", catboost_r2_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2619d3",
   "metadata": {},
   "source": [
    "## 8. LightGBM Regressor HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85448631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Hyperparameters for LightGBM Regressor: OrderedDict([('learning_rate', 0.19116122853606082), ('max_depth', 4), ('n_estimators', 298)])\n",
      "LightGBM RMSE (Validation): 0.0012490768626981271\n",
      "LightGBM MAE (Validation): 0.0009665971129525779\n",
      "LightGBM R-squared (Validation): 0.9999964746174609\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "param_dist = {\n",
    "    'n_estimators': Integer(100, 300),\n",
    "    'max_depth': Integer(3, 5),\n",
    "    'learning_rate': Real(0.01, 0.2, prior='uniform')\n",
    "}\n",
    "\n",
    "# Initialize Bayesian Optimization for LightGBM Regressor\n",
    "bayes_search_lgb = BayesSearchCV(\n",
    "    LGBMRegressor(verbosity=-1),  # Set verbosity to -1 to suppress warnings\n",
    "    param_dist,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_iter=10,  # Adjust the number of iterations as needed\n",
    "    random_state=42,  # Set a seed for reproducibility\n",
    "    n_jobs=-1,  # Use multiple cores for parallelization\n",
    "    verbose=1,  # Print progress\n",
    "    n_points=5,  # Number of points to sample in each iteration\n",
    "    refit=True  # Refit the best estimator with the entire dataset\n",
    ")\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "bayes_search_lgb.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for LightGBM Regressor\n",
    "best_lgb = bayes_search_lgb.best_estimator_\n",
    "best_params_lgb = bayes_search_lgb.best_params_\n",
    "\n",
    "# Predict on validation set using LightGBM Regressor\n",
    "lgb_pred_val = best_lgb.predict(X_val)\n",
    "\n",
    "# Calculate metrics for LightGBM Regressor on validation set\n",
    "lgb_rmse_val = mean_squared_error(y_val, lgb_pred_val, squared=False)\n",
    "lgb_mae_val = mean_absolute_error(y_val, lgb_pred_val)\n",
    "lgb_r2_val = r2_score(y_val, lgb_pred_val)\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for LightGBM Regressor on validation set\n",
    "print(\"Best Hyperparameters for LightGBM Regressor:\", best_params_lgb)\n",
    "print(\"LightGBM RMSE (Validation):\", lgb_rmse_val)\n",
    "print(\"LightGBM MAE (Validation):\", lgb_mae_val)\n",
    "print(\"LightGBM R-squared (Validation):\", lgb_r2_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22659214",
   "metadata": {},
   "source": [
    "## 9. Gradient Boosting Regressor HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfaa1aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Hyperparameters for Gradient Boosting Regressor: OrderedDict([('learning_rate', 0.19116122853606082), ('max_depth', 4), ('n_estimators', 298)])\n",
      "Gradient Boosting RMSE (Validation): 0.00112193734918984\n",
      "Gradient Boosting MAE (Validation): 0.0008654700025997339\n",
      "Gradient Boosting R-squared (Validation): 0.9999971557672461\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "param_dist = {\n",
    "    'n_estimators': Integer(100, 300),\n",
    "    'max_depth': Integer(3, 5),\n",
    "    'learning_rate': Real(0.01, 0.2, prior='uniform')\n",
    "}\n",
    "\n",
    "# Initialize Bayesian Optimization for Gradient Boosting Regressor\n",
    "bayes_search_gbr = BayesSearchCV(\n",
    "    GradientBoostingRegressor(),\n",
    "    param_dist,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_iter=10,  # Adjust the number of iterations as needed\n",
    "    random_state=42,  # Set a seed for reproducibility\n",
    "    n_jobs=-1,  # Use multiple cores for parallelization\n",
    "    verbose=1,  # Print progress\n",
    "    n_points=5,  # Number of points to sample in each iteration\n",
    "    refit=True  # Refit the best estimator with the entire dataset\n",
    ")\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "bayes_search_gbr.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for Gradient Boosting Regressor\n",
    "best_gbr = bayes_search_gbr.best_estimator_\n",
    "best_params_gbr = bayes_search_gbr.best_params_\n",
    "\n",
    "# Predict on validation set using Gradient Boosting Regressor\n",
    "gbr_pred_val = best_gbr.predict(X_val)\n",
    "\n",
    "# Calculate metrics for Gradient Boosting Regressor on validation set\n",
    "gbr_rmse_val = mean_squared_error(y_val, gbr_pred_val, squared=False)\n",
    "gbr_mae_val = mean_absolute_error(y_val, gbr_pred_val)\n",
    "gbr_r2_val = r2_score(y_val, gbr_pred_val)\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for Gradient Boosting Regressor on validation set\n",
    "print(\"Best Hyperparameters for Gradient Boosting Regressor:\", best_params_gbr)\n",
    "print(\"Gradient Boosting RMSE (Validation):\", gbr_rmse_val)\n",
    "print(\"Gradient Boosting MAE (Validation):\", gbr_mae_val)\n",
    "print(\"Gradient Boosting R-squared (Validation):\", gbr_r2_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2490db97",
   "metadata": {},
   "source": [
    "## 10.Ridge Regression HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c45cbd3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for Ridge Regression: {'alpha': 10, 'solver': 'auto'}\n",
      "Ridge Regression RMSE: 0.5808377892754024\n",
      "Ridge Regression MAE: 0.45820805392220315\n",
      "Ridge Regression R-squared: 0.2376794115111439\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Define the hyperparameters and their possible values for Ridge Regression\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "             'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']} \n",
    "\n",
    "# Initialize Ridge model\n",
    "ridge = Ridge(max_iter=10000)\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search_ridge = GridSearchCV(ridge, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Train the Grid Search\n",
    "grid_search_ridge.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and model for Ridge Regression\n",
    "best_ridge = grid_search_ridge.best_estimator_\n",
    "best_params_ridge = grid_search_ridge.best_params_\n",
    "\n",
    "# Predict on validation set using Ridge Regression\n",
    "ridge_pred = best_ridge.predict(X_val)\n",
    "\n",
    "# Calculate metrics for Ridge Regression\n",
    "ridge_rmse = mean_squared_error(y_val, ridge_pred, squared=False)\n",
    "ridge_mae = mean_absolute_error(y_val, ridge_pred)\n",
    "ridge_r2 = r2_score(y_val, ridge_pred)\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for Ridge Regression\n",
    "print(\"Best Hyperparameters for Ridge Regression:\", best_params_ridge)\n",
    "print(\"Ridge Regression RMSE:\", ridge_rmse)\n",
    "print(\"Ridge Regression MAE:\", ridge_mae)\n",
    "print(\"Ridge Regression R-squared:\", ridge_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e26246e",
   "metadata": {},
   "source": [
    "# Hybrid models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed322f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble RMSE (Validation): 0.07497193306288365\n",
      "Ensemble MAE (Validation): 0.05936975059183251\n",
      "Ensemble R-squared (Validation): 0.9872993678070258\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the weighted average ensemble\n",
    "def weighted_average_ensemble(models, weights, X):\n",
    "    predictions = np.column_stack([model.predict(X) for model in models])\n",
    "    weighted_predictions = np.sum(predictions * weights, axis=1) / np.sum(weights)\n",
    "    return weighted_predictions\n",
    "\n",
    "# Define the models and their corresponding weights for the ensemble\n",
    "models = [best_rf, best_lwlr, best_gpr, best_wknn, best_xgb, best_catboost, best_gbr, best_ridge]\n",
    "weights = [1, 1, 1, 1, 1, 1, 1, 1]  # Adjust weights as needed\n",
    "\n",
    "# Predict on the validation set using the ensemble\n",
    "ensemble_pred_val = weighted_average_ensemble(models, weights, X_val)\n",
    "\n",
    "# Calculate metrics for the ensemble on the validation set\n",
    "ensemble_rmse_val = mean_squared_error(y_val, ensemble_pred_val, squared=False)\n",
    "ensemble_mae_val = mean_absolute_error(y_val, ensemble_pred_val)\n",
    "ensemble_r2_val = r2_score(y_val, ensemble_pred_val)\n",
    "\n",
    "# Print evaluation metrics for the ensemble\n",
    "print(\"Ensemble RMSE (Validation):\", ensemble_rmse_val)\n",
    "print(\"Ensemble MAE (Validation):\", ensemble_mae_val)\n",
    "print(\"Ensemble R-squared (Validation):\", ensemble_r2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5fe00f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid RMSE (Validation): 0.16700596818978375\n",
      "Hybrid MAE (Validation): 0.15529550181965274\n",
      "Hybrid R-squared (Validation): 0.9369780401472435\n"
     ]
    }
   ],
   "source": [
    "# Define the weights for each model\n",
    "weight_rf = 0.2\n",
    "weight_lwlr = 0.2\n",
    "weight_gpr = 0.1\n",
    "weight_wknn = 0.1\n",
    "weight_knn = 0.1\n",
    "weight_xgb = 0.05\n",
    "weight_catboost = 0.05\n",
    "weight_lgb = 0.05\n",
    "weight_gbr = 0.05\n",
    "weight_ridge = 0.05\n",
    "\n",
    "# Create hybrid predictions\n",
    "hybrid_pred_val = (\n",
    "    weight_rf * rf_pred_val +\n",
    "    weight_lwlr * lwlr_pred_val +\n",
    "    weight_gpr * gpr_pred_val +\n",
    "    weight_wknn * wknn_pred_val +\n",
    "    weight_knn * knn_pred_val +\n",
    "    weight_xgb * xgb_pred_val +\n",
    "    weight_catboost * catboost_pred_val +\n",
    "    weight_lgb * lgb_pred_val +\n",
    "    weight_gbr * gbr_pred_val +\n",
    "    weight_ridge * ridge_pred_val\n",
    ")\n",
    "\n",
    "# Calculate metrics for the hybrid model on validation set\n",
    "hybrid_rmse_val = mean_squared_error(y_val, hybrid_pred_val, squared=False)\n",
    "hybrid_mae_val = mean_absolute_error(y_val, hybrid_pred_val)\n",
    "hybrid_r2_val = r2_score(y_val, hybrid_pred_val)\n",
    "\n",
    "# Print evaluation metrics for the hybrid model on validation set\n",
    "print(\"Hybrid RMSE (Validation):\", hybrid_rmse_val)\n",
    "print(\"Hybrid MAE (Validation):\", hybrid_mae_val)\n",
    "print(\"Hybrid R-squared (Validation):\", hybrid_r2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5dae90ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model 4 (GBR + CatBoost) RMSE: 0.00058900965385594\n",
      "Hybrid Model 4 (GBR + CatBoost) MAE: 0.0004557961486010128\n",
      "Hybrid Model 4 (GBR + CatBoost) R-squared: 0.9999992160781899\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have predictions for gbr_pred_val and catboost_pred_val\n",
    "hybrid4_pred_val = (gbr_pred_val + catboost_pred_val) / 2\n",
    "\n",
    "# Evaluate the performance of Hybrid Model 4\n",
    "hybrid4_rmse_val = mean_squared_error(y_val, hybrid4_pred_val, squared=False)\n",
    "hybrid4_mae_val = mean_absolute_error(y_val, hybrid4_pred_val)\n",
    "hybrid4_r2_val = r2_score(y_val, hybrid4_pred_val)\n",
    "\n",
    "print(\"Hybrid Model 4 (GBR + CatBoost) RMSE:\", hybrid4_rmse_val)\n",
    "print(\"Hybrid Model 4 (GBR + CatBoost) MAE:\", hybrid4_mae_val)\n",
    "print(\"Hybrid Model 4 (GBR + CatBoost) R-squared:\", hybrid4_r2_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f733c15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model 4 (Ridge + LWLR) RMSE: 0.2904188946377012\n",
      "Hybrid Model 4 (Ridge + LWLR) MAE: 0.22910402696110158\n",
      "Hybrid Model 4 (Ridge + LWLR) R-squared: 0.809419852877786\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have predictions for ridge_pred_val and lwlr_pred_val\n",
    "hybrid4_pred_val = (ridge_pred_val + lwlr_pred_val) / 2\n",
    "\n",
    "# Calculate metrics for the hybrid model on validation set\n",
    "hybrid4_rmse_val = mean_squared_error(y_val, hybrid4_pred_val, squared=False)\n",
    "hybrid4_mae_val = mean_absolute_error(y_val, hybrid4_pred_val)\n",
    "hybrid4_r2_val = r2_score(y_val, hybrid4_pred_val)\n",
    "\n",
    "# Print evaluation metrics for Hybrid Model 4\n",
    "print(\"Hybrid Model 4 (Ridge + LWLR) RMSE:\", hybrid4_rmse_val)\n",
    "print(\"Hybrid Model 4 (Ridge + LWLR) MAE:\", hybrid4_mae_val)\n",
    "print(\"Hybrid Model 4 (Ridge + LWLR) R-squared:\", hybrid4_r2_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d9f6445a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model 4 (RF + LWLR + GPR + WKNN) RMSE: 3.3253994230853402e-12\n",
      "Hybrid Model 4 (RF + LWLR + GPR + WKNN) MAE: 3.19355782217488e-12\n",
      "Hybrid Model 4 (RF + LWLR + GPR + WKNN) R-squared: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have predictions for rf_pred_val, lwlr_pred_val, gpr_pred_val, and wknn_pred_val\n",
    "hybrid4_pred_val = (rf_pred_val + lwlr_pred_val + gpr_pred_val + wknn_pred_val) / 4\n",
    "\n",
    "# Calculate metrics for the hybrid model on validation set\n",
    "hybrid4_rmse_val = mean_squared_error(y_val, hybrid4_pred_val, squared=False)\n",
    "hybrid4_mae_val = mean_absolute_error(y_val, hybrid4_pred_val)\n",
    "hybrid4_r2_val = r2_score(y_val, hybrid4_pred_val)\n",
    "\n",
    "# Print evaluation metrics for Hybrid Model 4\n",
    "print(\"Hybrid Model 4 (RF + LWLR + GPR + WKNN) RMSE:\", hybrid4_rmse_val)\n",
    "print(\"Hybrid Model 4 (RF + LWLR + GPR + WKNN) MAE:\", hybrid4_mae_val)\n",
    "print(\"Hybrid Model 4 (RF + LWLR + GPR + WKNN) R-squared:\", hybrid4_r2_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a09d6c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model 4 (XGB + CatBoost + GBR + Ridge) RMSE: 0.14994386612499633\n",
      "Hybrid Model 4 (XGB + CatBoost + GBR + Ridge) MAE: 0.11873950118308789\n",
      "Hybrid Model 4 (XGB + CatBoost + GBR + Ridge) R-squared: 0.9491974712286253\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have predictions for xgb_pred_val, catboost_pred_val, gbr_pred_val, and ridge_pred_val\n",
    "hybrid4_pred_val = (xgb_pred_val + catboost_pred_val + gbr_pred_val + ridge_pred_val) / 4\n",
    "\n",
    "# Calculate metrics for the hybrid model on validation set\n",
    "hybrid4_rmse_val = mean_squared_error(y_val, hybrid4_pred_val, squared=False)\n",
    "hybrid4_mae_val = mean_absolute_error(y_val, hybrid4_pred_val)\n",
    "hybrid4_r2_val = r2_score(y_val, hybrid4_pred_val)\n",
    "\n",
    "# Print evaluation metrics for Hybrid Model 4\n",
    "print(\"Hybrid Model 4 (XGB + CatBoost + GBR + Ridge) RMSE:\", hybrid4_rmse_val)\n",
    "print(\"Hybrid Model 4 (XGB + CatBoost + GBR + Ridge) MAE:\", hybrid4_mae_val)\n",
    "print(\"Hybrid Model 4 (XGB + CatBoost + GBR + Ridge) R-squared:\", hybrid4_r2_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d4d5a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model 6 (Random Forest + LWLR) RMSE: 1.1280591348071767e-15\n",
      "Hybrid Model 6 (Random Forest + LWLR) MAE: 9.137112695477675e-16\n",
      "Hybrid Model 6 (Random Forest + LWLR) R-squared: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have predictions for rf_pred_val and lwlr_pred_val\n",
    "hybrid6_pred_val = (rf_pred_val + lwlr_pred_val) / 2\n",
    "\n",
    "# Evaluate the performance of Hybrid Model 6\n",
    "hybrid6_rmse_val = mean_squared_error(y_val, hybrid6_pred_val, squared=False)\n",
    "hybrid6_mae_val = mean_absolute_error(y_val, hybrid6_pred_val)\n",
    "hybrid6_r2_val = r2_score(y_val, hybrid6_pred_val)\n",
    "\n",
    "print(\"Hybrid Model 6 (Random Forest + LWLR) RMSE:\", hybrid6_rmse_val)\n",
    "print(\"Hybrid Model 6 (Random Forest + LWLR) MAE:\", hybrid6_mae_val)\n",
    "print(\"Hybrid Model 6 (Random Forest + LWLR) R-squared:\", hybrid6_r2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f77cc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model 7 (RF + LightGBM + CatBoost) RMSE: 0.00039053084066279604\n",
      "Hybrid Model 7 (RF + LightGBM + CatBoost) MAE: 0.00030153734259234425\n",
      "Hybrid Model 7 (RF + LightGBM + CatBoost) R-squared: 0.9999996553814949\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have rf_pred_val, lgb_pred_val, and catboost_pred_val\n",
    "\n",
    "# Define weights for models (you can adjust these)\n",
    "weight_rf = 0.4\n",
    "weight_lgb = 0.3\n",
    "weight_catboost = 0.3\n",
    "\n",
    "# Combine predictions\n",
    "hybrid7_pred = (weight_rf * rf_pred_val + weight_lgb * lgb_pred_val + weight_catboost * catboost_pred_val)\n",
    "\n",
    "# Evaluate the performance of Hybrid Model 7\n",
    "hybrid7_rmse = mean_squared_error(y_val, hybrid7_pred, squared=False)\n",
    "hybrid7_mae = mean_absolute_error(y_val, hybrid7_pred)\n",
    "hybrid7_r2 = r2_score(y_val, hybrid7_pred)\n",
    "\n",
    "print(\"Hybrid Model 7 (RF + LightGBM + CatBoost) RMSE:\", hybrid7_rmse)\n",
    "print(\"Hybrid Model 7 (RF + LightGBM + CatBoost) MAE:\", hybrid7_mae)\n",
    "print(\"Hybrid Model 7 (RF + LightGBM + CatBoost) R-squared:\", hybrid7_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6209e07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model 8 (Stacking Ensemble) RMSE: 0.0006557313780315184\n",
      "Hybrid Model 8 (Stacking Ensemble) MAE: 0.0005101268722025494\n",
      "Hybrid Model 8 (Stacking Ensemble) R-squared: 0.99999902841712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Assuming you have xgb_pred_val, gbr_pred_val, and lgb_pred_val\n",
    "\n",
    "# Initialize the Meta-model (you can choose a different one if desired)\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "# Create the training set for the meta-model\n",
    "meta_X_train = np.column_stack((xgb_pred_val, gbr_pred_val, lgb_pred_val))\n",
    "\n",
    "# Train the Meta-model\n",
    "meta_model.fit(meta_X_train, y_val)\n",
    "\n",
    "# Create the test set for the meta-model\n",
    "meta_X_val = np.column_stack((xgb_pred_val, gbr_pred_val, lgb_pred_val))\n",
    "\n",
    "# Predict using the Meta-model\n",
    "hybrid8_pred = meta_model.predict(meta_X_val)\n",
    "\n",
    "# Evaluate the performance of Hybrid Model 8\n",
    "hybrid8_rmse = mean_squared_error(y_val, hybrid8_pred, squared=False)\n",
    "hybrid8_mae = mean_absolute_error(y_val, hybrid8_pred)\n",
    "hybrid8_r2 = r2_score(y_val, hybrid8_pred)\n",
    "\n",
    "print(\"Hybrid Model 8 (Stacking Ensemble) RMSE:\", hybrid8_rmse)\n",
    "print(\"Hybrid Model 8 (Stacking Ensemble) MAE:\", hybrid8_mae)\n",
    "print(\"Hybrid Model 8 (Stacking Ensemble) R-squared:\", hybrid8_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a367858d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Average RMSE (Validation): 0.060049715711077006\n",
      "Weighted Average MAE (Validation): 0.04755210229867431\n",
      "Weighted Average R-squared (Validation): 0.9918520222756105\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have predictions from all your tuned models stored in variables\n",
    "# rf_pred_val, lwlr_pred_val, poly_kernel_pred_val, rbf_kernel_pred_val, gpr_pred_val, wknn_pred_val, knn_pred_val, xgb_pred_val, catboost_pred_val, lgb_pred_val, gbr_pred_val, ridge_pred_val\n",
    "\n",
    "# Define weights for each model (you can adjust these)\n",
    "weights = {\n",
    "    'rf': 0.1,\n",
    "    'lwlr': 0.1,\n",
    "    'gpr': 0.1,\n",
    "    'wknn': 0.1,\n",
    "    'knn': 0.1,\n",
    "    'xgb': 0.1,\n",
    "    'catboost': 0.1,\n",
    "    'lgb': 0.1,\n",
    "    'gbr': 0.1,\n",
    "    'ridge': 0.1\n",
    "}\n",
    "\n",
    "# List of model predictions\n",
    "predictions = [\n",
    "    rf_pred_val, lwlr_pred_val, \n",
    "    gpr_pred_val, wknn_pred_val, knn_pred_val, xgb_pred_val, catboost_pred_val,\n",
    "    lgb_pred_val, gbr_pred_val, ridge_pred_val\n",
    "]\n",
    "\n",
    "# Initialize an array to store the weighted predictions\n",
    "weighted_predictions = np.zeros_like(rf_pred_val)\n",
    "\n",
    "# Combine predictions with weights\n",
    "for model_pred, weight in zip(predictions, weights.values()):\n",
    "    weighted_predictions += model_pred * weight\n",
    "\n",
    "# Calculate metrics for the weighted predictions\n",
    "weighted_rmse_val = mean_squared_error(y_val, weighted_predictions, squared=False)\n",
    "weighted_mae_val = mean_absolute_error(y_val, weighted_predictions)\n",
    "weighted_r2_val = r2_score(y_val, weighted_predictions)\n",
    "\n",
    "# Print the evaluation metrics for the weighted predictions\n",
    "print(\"Weighted Average RMSE (Validation):\", weighted_rmse_val)\n",
    "print(\"Weighted Average MAE (Validation):\", weighted_mae_val)\n",
    "print(\"Weighted Average R-squared (Validation):\", weighted_r2_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48ce382",
   "metadata": {},
   "source": [
    "# Testing using test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4229c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df.loc[(df['Date'].dt.year >= 1993) & (df['Date'].dt.year <= 2012)].drop(columns=['Rangpur-27 Satgora Mistripara (Rangpur Sadar)', 'Date']).to_numpy()\n",
    "y_test = df.loc[(df['Date'].dt.year >= 1993) & (df['Date'].dt.year <= 2012)]['Rangpur-27 Satgora Mistripara (Rangpur Sadar)'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8bbb9c13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model 5 (XGB + CatBoost + GBR + Ridge) RMSE (Test): 0.14322046876820838\n",
      "Hybrid Model 5 (XGB + CatBoost + GBR + Ridge) MAE (Test): 0.1130532213125217\n",
      "Hybrid Model 5 (XGB + CatBoost + GBR + Ridge) R-squared (Test): 0.9491642141304782\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have the hybrid model (hybrid5_pred_val) and X_test, y_test from the previous cell\n",
    "\n",
    "# Predict on the test set using the hybrid model\n",
    "hybrid5_pred_test = (best_xgb.predict(X_test) + best_catboost.predict(X_test) + best_gbr.predict(X_test) + best_ridge.predict(X_test)) / 4\n",
    "\n",
    "# Calculate metrics for the hybrid model on the test set\n",
    "hybrid5_rmse_test = mean_squared_error(y_test, hybrid5_pred_test, squared=False)\n",
    "hybrid5_mae_test = mean_absolute_error(y_test, hybrid5_pred_test)\n",
    "hybrid5_r2_test = r2_score(y_test, hybrid5_pred_test)\n",
    "\n",
    "# Print evaluation metrics for the hybrid model on the test set\n",
    "print(\"Hybrid Model 5 (XGB + CatBoost + GBR + Ridge) RMSE (Test):\", hybrid5_rmse_test)\n",
    "print(\"Hybrid Model 5 (XGB + CatBoost + GBR + Ridge) MAE (Test):\", hybrid5_mae_test)\n",
    "print(\"Hybrid Model 5 (XGB + CatBoost + GBR + Ridge) R-squared (Test):\", hybrid5_r2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e7490eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid RMSE (Test): 0.028704511047490916\n",
      "Hybrid MAE (Test): 0.0226626341544322\n",
      "Hybrid R-squared (Test): 0.9979579815252266\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Assuming you have predictions for each best model on the test set\n",
    "# e.g., best_rf_pred_test, best_lwlr_pred_test, etc.\n",
    "\n",
    "# Define the weights for each model\n",
    "weight_rf = 0.2\n",
    "weight_lwlr = 0.2\n",
    "weight_gpr = 0.1\n",
    "weight_wknn = 0.1\n",
    "weight_knn = 0.1\n",
    "weight_xgb = 0.05\n",
    "weight_catboost = 0.05\n",
    "weight_lgb = 0.05\n",
    "weight_gbr = 0.1\n",
    "weight_ridge = 0.05\n",
    "\n",
    "# Assuming you have predictions for each best model on the test set (e.g., best_rf_pred_test, best_lwlr_pred_test, etc.)\n",
    "best_rf_pred_test = best_rf.predict(X_test)\n",
    "best_lwlr_pred_test = best_lwlr.predict(X_test)\n",
    "best_gpr_pred_test = best_gpr.predict(X_test)\n",
    "best_wknn_pred_test = best_wknn.predict(X_test)\n",
    "best_knn_pred_test = best_knn.predict(X_test)\n",
    "best_xgb_pred_test = best_xgb.predict(X_test)\n",
    "best_catboost_pred_test = best_catboost.predict(X_test)\n",
    "best_lgb_pred_test = best_lgb.predict(X_test)\n",
    "best_gbr_pred_test = best_gbr.predict(X_test)\n",
    "best_ridge_pred_test = best_ridge.predict(X_test)\n",
    "\n",
    "# Create hybrid predictions for the test set\n",
    "hybrid_pred_test = (\n",
    "    weight_rf * best_rf_pred_test +\n",
    "    weight_lwlr * best_lwlr_pred_test +\n",
    "    weight_gpr * best_gpr_pred_test +\n",
    "    weight_wknn * best_wknn_pred_test +\n",
    "    weight_knn * best_knn_pred_test +\n",
    "    weight_xgb * best_xgb_pred_test +\n",
    "    weight_catboost * best_catboost_pred_test +\n",
    "    weight_lgb * best_lgb_pred_test +\n",
    "    weight_gbr * best_gbr_pred_test +\n",
    "    weight_ridge * best_ridge_pred_test\n",
    ")\n",
    "\n",
    "# Calculate metrics for the hybrid model on the test set\n",
    "hybrid_rmse_test = mean_squared_error(y_test, hybrid_pred_test, squared=False)\n",
    "hybrid_mae_test = mean_absolute_error(y_test, hybrid_pred_test)\n",
    "hybrid_r2_test = r2_score(y_test, hybrid_pred_test)\n",
    "\n",
    "# Print evaluation metrics for the hybrid model on the test set\n",
    "print(\"Hybrid RMSE (Test):\", hybrid_rmse_test)\n",
    "print(\"Hybrid MAE (Test):\", hybrid_mae_test)\n",
    "print(\"Hybrid R-squared (Test):\", hybrid_r2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "030c3a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model 4 (GBR + CatBoost) RMSE (Test): 0.000565615894117744\n",
      "Hybrid Model 4 (GBR + CatBoost) MAE (Test): 0.00044329995736817814\n",
      "Hybrid Model 4 (GBR + CatBoost) R-squared (Test): 0.9999992071289338\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have trained models: best_gbr and best_catboost\n",
    "\n",
    "# Predict on the test set using Gradient Boosting Regressor\n",
    "gbr_pred_test = best_gbr.predict(X_test)\n",
    "\n",
    "# Predict on the test set using CatBoost Regressor\n",
    "catboost_pred_test = best_catboost.predict(X_test)\n",
    "\n",
    "# Assuming you already have predictions for gbr_pred_test and catboost_pred_test\n",
    "hybrid4_pred_test = (gbr_pred_test + catboost_pred_test) / 2\n",
    "\n",
    "# Evaluate the performance of Hybrid Model 4 on the test set\n",
    "hybrid4_rmse_test = mean_squared_error(y_test, hybrid4_pred_test, squared=False)\n",
    "hybrid4_mae_test = mean_absolute_error(y_test, hybrid4_pred_test)\n",
    "hybrid4_r2_test = r2_score(y_test, hybrid4_pred_test)\n",
    "\n",
    "print(\"Hybrid Model 4 (GBR + CatBoost) RMSE (Test):\", hybrid4_rmse_test)\n",
    "print(\"Hybrid Model 4 (GBR + CatBoost) MAE (Test):\", hybrid4_mae_test)\n",
    "print(\"Hybrid Model 4 (GBR + CatBoost) R-squared (Test):\", hybrid4_r2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "adea2e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model 4 (GBR + CatBoost) RMSE (Test): 0.000565615894117744\n",
      "Hybrid Model 4 (GBR + CatBoost) MAE (Test): 0.00044329995736817814\n",
      "Hybrid Model 4 (GBR + CatBoost) R-squared (Test): 0.9999992071289338\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set using Gradient Boosting Regressor\n",
    "gbr_pred_test = best_gbr.predict(X_test)\n",
    "\n",
    "# Predict on the test set using CatBoost Regressor\n",
    "catboost_pred_test = best_catboost.predict(X_test)\n",
    "\n",
    "# Assuming you already have predictions for gbr_pred_test and catboost_pred_test\n",
    "hybrid4_pred_test = (gbr_pred_test + catboost_pred_test) / 2\n",
    "\n",
    "# Evaluate the performance of Hybrid Model 4 on the test set\n",
    "hybrid4_rmse_test = mean_squared_error(y_test, hybrid4_pred_test, squared=False)\n",
    "hybrid4_mae_test = mean_absolute_error(y_test, hybrid4_pred_test)\n",
    "hybrid4_r2_test = r2_score(y_test, hybrid4_pred_test)\n",
    "\n",
    "print(\"Hybrid Model 4 (GBR + CatBoost) RMSE (Test):\", hybrid4_rmse_test)\n",
    "print(\"Hybrid Model 4 (GBR + CatBoost) MAE (Test):\", hybrid4_mae_test)\n",
    "print(\"Hybrid Model 4 (GBR + CatBoost) R-squared (Test):\", hybrid4_r2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8ac51531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model 4 (Ridge + LWLR) RMSE (Test): 0.2777685288848493\n",
      "Hybrid Model 4 (Ridge + LWLR) MAE (Test): 0.21826703145477236\n",
      "Hybrid Model 4 (Ridge + LWLR) R-squared (Test): 0.8087834679728014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Assuming you have trained models: best_ridge and best_lwlr\n",
    "\n",
    "# Predict on the test set using Ridge Regression\n",
    "ridge_pred_test = best_ridge.predict(X_test)\n",
    "\n",
    "# Predict on the test set using Locally Weighted Linear Regression\n",
    "lwlr_pred_test = best_lwlr.predict(X_test)\n",
    "\n",
    "# Assuming you already have predictions for ridge_pred_test and lwlr_pred_test\n",
    "hybrid4_pred_test = (ridge_pred_test + lwlr_pred_test) / 2\n",
    "\n",
    "# Calculate metrics for the hybrid model on test set\n",
    "hybrid4_rmse_test = mean_squared_error(y_test, hybrid4_pred_test, squared=False)\n",
    "hybrid4_mae_test = mean_absolute_error(y_test, hybrid4_pred_test)\n",
    "hybrid4_r2_test = r2_score(y_test, hybrid4_pred_test)\n",
    "\n",
    "# Print evaluation metrics for Hybrid Model 4\n",
    "print(\"Hybrid Model 4 (Ridge + LWLR) RMSE (Test):\", hybrid4_rmse_test)\n",
    "print(\"Hybrid Model 4 (Ridge + LWLR) MAE (Test):\", hybrid4_mae_test)\n",
    "print(\"Hybrid Model 4 (Ridge + LWLR) R-squared (Test):\", hybrid4_r2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4fe61b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model 4 (RF + LWLR + GPR + WKNN) RMSE (Test): 3.1852873879224164e-12\n",
      "Hybrid Model 4 (RF + LWLR + GPR + WKNN) MAE (Test): 3.0673927159777236e-12\n",
      "Hybrid Model 4 (RF + LWLR + GPR + WKNN) R-squared (Test): 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Assuming you have trained models: best_rf, best_lwlr, best_gpr, and best_wknn\n",
    "\n",
    "# Predict on the test set using Random Forest Regressor\n",
    "rf_pred_test = best_rf.predict(X_test)\n",
    "\n",
    "# Predict on the test set using Locally Weighted Linear Regression\n",
    "lwlr_pred_test = best_lwlr.predict(X_test)\n",
    "\n",
    "# Predict on the test set using Gaussian Process Regressor\n",
    "gpr_pred_test = best_gpr.predict(X_test)\n",
    "\n",
    "# Predict on the test set using Weighted k-Nearest Neighbors Regressor\n",
    "wknn_pred_test = best_wknn.predict(X_test)\n",
    "\n",
    "# Assuming you already have predictions for rf_pred_test, lwlr_pred_test, gpr_pred_test, and wknn_pred_test\n",
    "hybrid4_pred_test = (rf_pred_test + lwlr_pred_test + gpr_pred_test + wknn_pred_test) / 4\n",
    "\n",
    "# Calculate metrics for the hybrid model on test set\n",
    "hybrid4_rmse_test = mean_squared_error(y_test, hybrid4_pred_test, squared=False)\n",
    "hybrid4_mae_test = mean_absolute_error(y_test, hybrid4_pred_test)\n",
    "hybrid4_r2_test = r2_score(y_test, hybrid4_pred_test)\n",
    "\n",
    "# Print evaluation metrics for Hybrid Model 4\n",
    "print(\"Hybrid Model 4 (RF + LWLR + GPR + WKNN) RMSE (Test):\", hybrid4_rmse_test)\n",
    "print(\"Hybrid Model 4 (RF + LWLR + GPR + WKNN) MAE (Test):\", hybrid4_mae_test)\n",
    "print(\"Hybrid Model 4 (RF + LWLR + GPR + WKNN) R-squared (Test):\", hybrid4_r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2070163e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model 4 (XGB + CatBoost + GBR + Ridge) RMSE (Test): 0.14322046876820838\n",
      "Hybrid Model 4 (XGB + CatBoost + GBR + Ridge) MAE (Test): 0.1130532213125217\n",
      "Hybrid Model 4 (XGB + CatBoost + GBR + Ridge) R-squared (Test): 0.9491642141304782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Assuming you have trained models: best_xgb, best_catboost, best_gbr, and best_ridge\n",
    "\n",
    "# Predict on the test set using XGBoost Regressor\n",
    "xgb_pred_test = best_xgb.predict(X_test)\n",
    "\n",
    "# Predict on the test set using CatBoost Regressor\n",
    "catboost_pred_test = best_catboost.predict(X_test)\n",
    "\n",
    "# Predict on the test set using Gradient Boosting Regressor\n",
    "gbr_pred_test = best_gbr.predict(X_test)\n",
    "\n",
    "# Predict on the test set using Ridge Regression\n",
    "ridge_pred_test = best_ridge.predict(X_test)\n",
    "\n",
    "# Assuming you already have predictions for xgb_pred_test, catboost_pred_test, gbr_pred_test, and ridge_pred_test\n",
    "hybrid4_pred_test = (xgb_pred_test + catboost_pred_test + gbr_pred_test + ridge_pred_test) / 4\n",
    "\n",
    "# Calculate metrics for the hybrid model on test set\n",
    "hybrid4_rmse_test = mean_squared_error(y_test, hybrid4_pred_test, squared=False)\n",
    "hybrid4_mae_test = mean_absolute_error(y_test, hybrid4_pred_test)\n",
    "hybrid4_r2_test = r2_score(y_test, hybrid4_pred_test)\n",
    "\n",
    "# Print evaluation metrics for Hybrid Model 4\n",
    "print(\"Hybrid Model 4 (XGB + CatBoost + GBR + Ridge) RMSE (Test):\", hybrid4_rmse_test)\n",
    "print(\"Hybrid Model 4 (XGB + CatBoost + GBR + Ridge) MAE (Test):\", hybrid4_mae_test)\n",
    "print(\"Hybrid Model 4 (XGB + CatBoost + GBR + Ridge) R-squared (Test):\", hybrid4_r2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "48d4c7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model 6 (Random Forest + LWLR) RMSE (Test): 1.1252495484927923e-15\n",
      "Hybrid Model 6 (Random Forest + LWLR) MAE (Test): 9.100029270698955e-16\n",
      "Hybrid Model 6 (Random Forest + LWLR) R-squared (Test): 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Assuming you have trained models: best_rf and best_lwlr\n",
    "\n",
    "# Predict on the test set using Random Forest Regressor\n",
    "rf_pred_test = best_rf.predict(X_test)\n",
    "\n",
    "# Predict on the test set using Locally Weighted Linear Regression\n",
    "lwlr_pred_test = best_lwlr.predict(X_test)\n",
    "\n",
    "# Assuming you already have predictions for rf_pred_test and lwlr_pred_test\n",
    "hybrid6_pred_test = (rf_pred_test + lwlr_pred_test) / 2\n",
    "\n",
    "# Calculate metrics for the hybrid model on test set\n",
    "hybrid6_rmse_test = mean_squared_error(y_test, hybrid6_pred_test, squared=False)\n",
    "hybrid6_mae_test = mean_absolute_error(y_test, hybrid6_pred_test)\n",
    "hybrid6_r2_test = r2_score(y_test, hybrid6_pred_test)\n",
    "\n",
    "# Print evaluation metrics for Hybrid Model 6\n",
    "print(\"Hybrid Model 6 (Random Forest + LWLR) RMSE (Test):\", hybrid6_rmse_test)\n",
    "print(\"Hybrid Model 6 (Random Forest + LWLR) MAE (Test):\", hybrid6_mae_test)\n",
    "print(\"Hybrid Model 6 (Random Forest + LWLR) R-squared (Test):\", hybrid6_r2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f4dcc0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model 7 (RF + LightGBM + CatBoost) RMSE: 0.00039053084066279604\n",
      "Hybrid Model 7 (RF + LightGBM + CatBoost) MAE: 0.00030153734259234425\n",
      "Hybrid Model 7 (RF + LightGBM + CatBoost) R-squared: 0.9999996553814949\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Assuming you have rf_pred_val, lgb_pred_val, and catboost_pred_val\n",
    "\n",
    "# Define weights for models (you can adjust these)\n",
    "weight_rf = 0.4\n",
    "weight_lgb = 0.3\n",
    "weight_catboost = 0.3\n",
    "\n",
    "# Combine predictions\n",
    "hybrid7_pred = (weight_rf * rf_pred_val + weight_lgb * lgb_pred_val + weight_catboost * catboost_pred_val)\n",
    "\n",
    "# Evaluate the performance of Hybrid Model 7\n",
    "hybrid7_rmse = mean_squared_error(y_val, hybrid7_pred, squared=False)\n",
    "hybrid7_mae = mean_absolute_error(y_val, hybrid7_pred)\n",
    "hybrid7_r2 = r2_score(y_val, hybrid7_pred)\n",
    "\n",
    "print(\"Hybrid Model 7 (RF + LightGBM + CatBoost) RMSE:\", hybrid7_rmse)\n",
    "print(\"Hybrid Model 7 (RF + LightGBM + CatBoost) MAE:\", hybrid7_mae)\n",
    "print(\"Hybrid Model 7 (RF + LightGBM + CatBoost) R-squared:\", hybrid7_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f876e3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Model 8 (Stacking Ensemble with Random Forest) RMSE (Test): 0.00039859947332423226\n",
      "Hybrid Model 8 (Stacking Ensemble with Random Forest) MAE (Test): 0.00011175880838528898\n",
      "Hybrid Model 8 (Stacking Ensemble with Random Forest) R-squared (Test): 0.9999996062389078\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Assuming you have predictions for xgb_pred_test, gbr_pred_test, and lgb_pred_test\n",
    "\n",
    "# Predict on the test set using XGBoost Regressor\n",
    "xgb_pred_test = best_xgb.predict(X_test)\n",
    "\n",
    "# Predict on the test set using Gradient Boosting Regressor\n",
    "gbr_pred_test = best_gbr.predict(X_test)\n",
    "\n",
    "# Predict on the test set using LightGBM Regressor\n",
    "lgb_pred_test = best_lgb.predict(X_test)\n",
    "\n",
    "\n",
    "# Initialize the Meta-model (Random Forest Regressor)\n",
    "meta_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create the training set for the meta-model\n",
    "meta_X_train = np.column_stack((xgb_pred_val, gbr_pred_val, lgb_pred_val))\n",
    "\n",
    "# Train the Meta-model\n",
    "meta_model.fit(meta_X_train, y_val)\n",
    "\n",
    "# Create the test set for the meta-model\n",
    "meta_X_test = np.column_stack((xgb_pred_test, gbr_pred_test, lgb_pred_test))\n",
    "\n",
    "# Predict using the Meta-model\n",
    "hybrid8_pred_test = meta_model.predict(meta_X_test)\n",
    "\n",
    "# Evaluate the performance of Hybrid Model 8 on the test set\n",
    "hybrid8_rmse_test = mean_squared_error(y_test, hybrid8_pred_test, squared=False)\n",
    "hybrid8_mae_test = mean_absolute_error(y_test, hybrid8_pred_test)\n",
    "hybrid8_r2_test = r2_score(y_test, hybrid8_pred_test)\n",
    "\n",
    "print(\"Hybrid Model 8 (Stacking Ensemble with Random Forest) RMSE (Test):\", hybrid8_rmse_test)\n",
    "print(\"Hybrid Model 8 (Stacking Ensemble with Random Forest) MAE (Test):\", hybrid8_mae_test)\n",
    "print(\"Hybrid Model 8 (Stacking Ensemble with Random Forest) R-squared (Test):\", hybrid8_r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a423b683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Average RMSE (Validation): 0.060049715711077006\n",
      "Weighted Average MAE (Validation): 0.04755210229867431\n",
      "Weighted Average R-squared (Validation): 0.9918520222756105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "# Define weights for each model (you can adjust these)\n",
    "weights = {\n",
    "    'rf': 0.1,\n",
    "    'lwlr': 0.1,\n",
    "    'gpr': 0.1,\n",
    "    'wknn': 0.1,\n",
    "    'knn': 0.1,\n",
    "    'xgb': 0.1,\n",
    "    'catboost': 0.1,\n",
    "    'lgb': 0.1,\n",
    "    'gbr': 0.1,\n",
    "    'ridge': 0.1\n",
    "}\n",
    "\n",
    "# List of model predictions\n",
    "predictions = [\n",
    "    rf_pred_val, lwlr_pred_val, \n",
    "    gpr_pred_val, wknn_pred_val, knn_pred_val, xgb_pred_val, catboost_pred_val,\n",
    "    lgb_pred_val, gbr_pred_val, ridge_pred_val\n",
    "]\n",
    "\n",
    "# Initialize an array to store the weighted predictions\n",
    "weighted_predictions = np.zeros_like(rf_pred_val)\n",
    "\n",
    "# Combine predictions with weights\n",
    "for model_pred, weight in zip(predictions, weights.values()):\n",
    "    weighted_predictions += model_pred * weight\n",
    "\n",
    "# Calculate metrics for the weighted predictions\n",
    "weighted_rmse_val = mean_squared_error(y_val, weighted_predictions, squared=False)\n",
    "weighted_mae_val = mean_absolute_error(y_val, weighted_predictions)\n",
    "weighted_r2_val = r2_score(y_val, weighted_predictions)\n",
    "\n",
    "# Print the evaluation metrics for the weighted predictions\n",
    "print(\"Weighted Average RMSE (Validation):\", weighted_rmse_val)\n",
    "print(\"Weighted Average MAE (Validation):\", weighted_mae_val)\n",
    "print(\"Weighted Average R-squared (Validation):\", weighted_r2_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738c152f",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a9e39b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'hybrid1_test_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# For the test set\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Assuming y_test is the actual target values and hybrid1_test_pred is the predicted values\u001b[39;00m\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m---> 15\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(y_test, \u001b[43mhybrid1_test_pred\u001b[49m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual Values\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Values\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hybrid1_test_pred' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming y_val is the actual target values and hybrid1_pred is the predicted values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_val, hybrid1_pred, alpha=0.5)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs. Predicted Values (Validation Set)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# For the test set\n",
    "# Assuming y_test is the actual target values and hybrid1_test_pred is the predicted values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, hybrid1_test_pred, alpha=0.5)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs. Predicted Values (Test Set)')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dc9fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0e5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df063dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
