{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01c5d403",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3699631420.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    <div style = \"text-align: center\"><font size = 6 color = \"#B22222\" face = \"verdana\"><b>Ground water level prediction</b></font></div> <br/>\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<div style = \"text-align: center\"><font size = 6 color = \"#B22222\" face = \"verdana\"><b>Ground water level prediction</b></font></div> <br/> \n",
    "<div style = \"text-align: center\"><font size = 5 color = \"#00008B\" face = \"verdana\"><b>Md.Abdullah-Al Mamun</b></font></div><br/> \n",
    "<div style = \"text-align: center\"><font size = 5 color = \"#00008B\" face = \"verdana\"><b>Mst Nazneen Aktar</b></font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6cac28",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa44c777",
   "metadata": {},
   "source": [
    "## About the dataset\n",
    "\n",
    "\n",
    "Data collected from meteorological stations in Rangpur, Nilphamari, and Dinajpur was obtained from various sources, including the Bangladesh Meteorological Department (BMD), Bangladesh Water Development Board (BWDB), Food and Agricultural Organization (FAO), National Oceanic and Atmospheric Association (NOAA) Climate Prediction Center (CPC), Bangladesh Bureau of Statistics, and National Aeronautics and Space Administration (NASA). Additionally, monthly groundwater level (GWL) data for 12 selected wells was acquired from the Bangladesh Water Development Board (BWDB). The MODIS data was originally in Network Common Data Form (NetCDF) format and was subsequently converted to Excel format. This comprehensive dataset covers the period from 1993 to 2017.\n",
    "\n",
    "## Data\n",
    "\n",
    "\n",
    "**1. Groundwater Level (m) Data for 12 Selected Wells from the Bangladesh Water Development Board (BWDB)**\n",
    "- Dinajpur-34 (Dinajpur Sadar)\n",
    "\n",
    "**2. Monthly Temperature (°C)**\n",
    "- Dinajpur_Tave\n",
    "\n",
    "**3. Monthly Rainfall (mm)**\n",
    "- Dinajpur_PRCP\n",
    "\n",
    "**4. MODIS Normalized Difference Vegetation Index (NDVI)**\n",
    "- Dinajpur_NDVI\n",
    "\n",
    "**5. Indian Ocean Dipole (IOD)**\n",
    "- IOD_Value\n",
    "    \n",
    "**6. Southern Oscillation Index (SOI)**\n",
    "- SOI_Value\n",
    "    \n",
    "**7. Nina3.4 Value**\n",
    "- Nina3.4_Value\n",
    "    \n",
    "**8. MEI Value**\n",
    "- MEI_Value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e33f537",
   "metadata": {},
   "source": [
    "\n",
    "## Identify the Features and Targets\n",
    "\n",
    "### Features (Independent Variables):\n",
    "\n",
    "1. Temperature (°C) - Dinajpur_Tave (converted to monthly(mean)-->convert to daily)\n",
    "2. Rainfall (mm) - Dinajpur_PRCP Rainfall (mm) - Dinajpur_PRCP (averaged monthly, with the same value applied for each day, considering it as the mean monthly value)\n",
    "3. MODIS Normalized Difference Vegetation Index (NDVI) - Dinajpur_NDVI(monthly-->coverted daily with daily values assumed to be the mean value for the entire month)\n",
    "4. Indian Ocean Dipole (IOD) - IOD_Value\n",
    "5. Southern Oscillation Index (SOI) - SOI_Value\n",
    "6. Nina3.4 Value - Nina3.4_Value\n",
    "7. MEI Value - MEI_Value\n",
    "\n",
    "### Target (Dependent Variable):\n",
    "\n",
    "1. Groundwater Level (m) - Dinajpur-34 (Dinajpur Sadar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70960dbd",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6d594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from scipy import stats\n",
    "from tbats import TBATS\n",
    "import matplotlib.pyplot as plt\n",
    "from skopt import BayesSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from keras.models import Sequential\n",
    "from skopt.space import Integer, Real\n",
    "from sklearn.decomposition import PCA\n",
    "from catboost import CatBoostRegressor\n",
    "from keras.layers import LSTM, GRU, Dense\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from statsmodels.nonparametric.kernel_regression import KernelReg\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, WhiteKernel\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, explained_variance_score\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='xgboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8809d4",
   "metadata": {},
   "source": [
    "### Loading dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab40e9c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GWL_df= pd.read_excel('Final Dataset_GWL\\Final_GWL_Three_location merged all data.xlsx')  # Specify the header row number\n",
    "\n",
    "GWL_df = GWL_df.rename(columns={'Sayedpur_Tave': 'Saidpur_Tave','Sayedpur_PRCP': 'Saidpur_PRCP', 'Sayedpur_NDVI': 'Saidpur_NDVI'})\n",
    "\n",
    "GWL_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974b63cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68af490",
   "metadata": {},
   "outputs": [],
   "source": [
    "GWL_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41765b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Year', 'Month', 'Region', 'Well', 'Tave', 'PRCP', 'NDVI', 'IOD', 'SOI', 'Nina', 'MEI', 'Water_Level']\n",
    "\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "for index, row in GWL_df.iterrows():\n",
    "    Year = row['Year']\n",
    "    Month = row['Month']\n",
    "    IOD = row['IOD_Value']\n",
    "    SOI = row['SOI_Value']\n",
    "    Nina = row['Nina3.4_Value']\n",
    "    MEI = row['MEI_Value']\n",
    "    \n",
    "    for column in GWL_df.columns[2:14]:\n",
    "        Region = column.split('-')[0]\n",
    "        \n",
    "        Well = column.split('-')[1].split()[0]\n",
    "        PRCP = GWL_df.loc[index, Region+'_PRCP']\n",
    "        NDVI = GWL_df.loc[index, Region+'_NDVI']\n",
    "        Tave = GWL_df.loc[index, Region+'_Tave']\n",
    "        Water_Level = GWL_df.loc[index, column]\n",
    "\n",
    "        # Create a new row for the target DataFrame\n",
    "        new_row = {'Year':Year, 'Month':Month, 'Region':Region, 'Well':Well, 'PRCP':PRCP, 'Tave': Tave,\n",
    "                   'NDVI':NDVI, 'IOD':IOD, 'SOI':SOI, 'Nina':Nina, 'MEI':MEI, 'Water_Level':Water_Level}\n",
    "        \n",
    "        df0 = pd.DataFrame(new_row, index=[0])\n",
    "        df = pd.concat([df, df0], axis=0, ignore_index=True)\n",
    "        \n",
    "#         df = df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5507b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3e0fd9",
   "metadata": {},
   "source": [
    "# Yazid's Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f879b2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['Region'] = label_encoder.fit_transform(df['Region'])\n",
    "df['Region'] = df['Region'].astype(float)\n",
    "df['Well'] = df['Well'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4346f2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.loc[df['Year'] <= 2012].drop(columns=['Year'])\n",
    "df_test = df.loc[df['Year'] >= 2013].drop(columns=['Year'])\n",
    "\n",
    "X_train = df_train.drop(columns=['Water_Level'], axis=1).to_numpy()\n",
    "y_train = df_train['Water_Level'].to_numpy()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_test = df_test.drop(columns=['Water_Level'], axis=1).to_numpy()\n",
    "y_test = df_test['Water_Level'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314a915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45261082",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_test\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_test' is not defined"
     ]
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c482a8",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f086d309",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Ridge': Ridge(),\n",
    "    'K-Nearest Neighbors': KNeighborsRegressor(),\n",
    "    'Gaussian Process': GaussianProcessRegressor(),\n",
    "    'Gaussian Process Regressor': GaussianProcessRegressor(random_state=42),\n",
    "    'Weighted K-Nearest Neighbors': KNeighborsRegressor(weights='distance'),\n",
    "    'LightGBM': LGBMRegressor(random_state=42),\n",
    "    'CatBoost': CatBoostRegressor(random_state=42, verbose=0),\n",
    "    'XGBoost': XGBRegressor(),\n",
    "    'LGBM Regressor': lgb.LGBMRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'AdaBoost': AdaBoostRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the training set\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics for the training set\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    train_rae = mean_absolute_percentage_error(y_train, y_pred_train)\n",
    "    train_rrse = np.sqrt(np.sum((y_train - y_pred_train)**2) / np.sum((y_train - np.mean(y_train))**2))\n",
    "    train_cc = np.corrcoef(y_train, y_pred_train)[0, 1]\n",
    "\n",
    "    # Calculate metrics for the validation set\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "    val_mae = mean_absolute_error(y_val, y_pred_val)\n",
    "    val_r2 = r2_score(y_val, y_pred_val)\n",
    "    val_rae = mean_absolute_percentage_error(y_val, y_pred_val)\n",
    "    val_rrse = np.sqrt(np.sum((y_val - y_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "    val_cc = np.corrcoef(y_val, y_pred_val)[0, 1]\n",
    "    \n",
    "    # Calculate metrics for the test set\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    test_rae = mean_absolute_percentage_error(y_test, y_pred_test)\n",
    "    test_rrse = np.sqrt(np.sum((y_test - y_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "    test_cc = np.corrcoef(y_test, y_pred_test)[0, 1]\n",
    "\n",
    "    results[name] = {\n",
    "        'Train RMSE': train_rmse,\n",
    "        'Train MAE': train_mae,\n",
    "        'Train R-squared': train_r2,\n",
    "        'Train RAE': train_rae,\n",
    "        'Train RRSE': train_rrse,\n",
    "        'Train CC': train_cc,        \n",
    "        'Validation RMSE': val_rmse,\n",
    "        'Validation MAE': val_mae,\n",
    "        'Validation R-squared': val_r2,\n",
    "        'Validation RAE': val_rae,\n",
    "        'Validation RRSE': val_rrse,\n",
    "        'Validation CC': val_cc,\n",
    "        'Test RMSE': test_rmse,\n",
    "        'Test MAE': test_mae,\n",
    "        'Test R-squared': test_r2,\n",
    "        'Test RAE': test_rae,\n",
    "        'Test RRSE': test_rrse,\n",
    "        'Test CC': test_cc\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "for model, metrics in results.items():\n",
    "    print(f\"Metrics for {model}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.3f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbc4ae0",
   "metadata": {},
   "source": [
    "### LWLR model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6607b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neighbors = 5  \n",
    "\n",
    "# Initialize LWLR model\n",
    "lwlr = KNeighborsRegressor(n_neighbors=num_neighbors, weights='distance')\n",
    "\n",
    "# Train the LWLR model\n",
    "lwlr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "lwlr_pred = lwlr.predict(X_val)\n",
    "\n",
    "# Calculate metrics for LWLR\n",
    "lwlr_rmse = np.sqrt(mean_squared_error(y_val, lwlr_pred))\n",
    "lwlr_mae = mean_absolute_error(y_val, lwlr_pred)\n",
    "lwlr_r2 = r2_score(y_val, lwlr_pred)\n",
    "lwlr_rae = mean_absolute_percentage_error(y_val, lwlr_pred)\n",
    "lwlr_rrse = np.sqrt(np.sum((y_val - lwlr_pred)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "lwlr_cc = np.corrcoef(y_val, lwlr_pred)[0, 1]\n",
    "\n",
    "# the evaluation metrics for LWLR\n",
    "print(\"LWLR RMSE:\", lwlr_rmse)\n",
    "print(\"LWLR MAE:\", lwlr_mae)\n",
    "print(\"LWLR R-squared:\", lwlr_r2)\n",
    "print(\"LWLR RAE:\", lwlr_rae)\n",
    "print(\"LWLR RRSE:\", lwlr_rrse)\n",
    "print(\"LWLR CC:\", lwlr_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ba759e",
   "metadata": {},
   "source": [
    "Based on the evaluation metrics provided, here are the 12 best models, ranked by RMSE, MAE, and R-squared values:\n",
    "\n",
    "1. Random Forest Regressor (RMSE: 4.5129170688300314e-15, MAE: 3.731747590232183e-15, R-squared: 1.0)\n",
    "2. lwlr\n",
    "3. Poly Kernel Regression (RMSE: 1.6127342607400202e-14, MAE: 1.2373097451168137e-14, R-squared: 1.0)\n",
    "4. RBF Kernel Regression (RMSE: 8.402295816463806e-12, MAE: 7.30005059367716e-12, R-squared: 1.0)\n",
    "5. Gaussian Process Regression (RMSE: 1.3658267901830649e-11, MAE: 1.321696512977017e-11, R-squared: 1.0)\n",
    "6. Weighted K-Nearest Neighbors (RMSE: 1.6151202582352662e-16, MAE: 6.094448088633645e-17, R-squared: 1.0)\n",
    "7. K-Nearest Neighbors (RMSE: 1.6151202582352662e-16, MAE: 6.094448088633645e-17, R-squared: 1.0)\n",
    "8. XGBoost Regressor (RMSE: 0.0001604180170547465, MAE: 0.00012571969879465955, R-squared: 0.9999999418520767)\n",
    "9. CatBoost Regressor (RMSE: 0.0004191192864975924, MAE: 0.00033127405418021457, R-squared: 0.9999996030797887)\n",
    "10. LightGBM Regressor (RMSE: 0.0032090330540582293, MAE: 0.002630020414763086, R-squared: 0.9999767310759211)\n",
    "11. Gradient Boosting Regressor (RMSE: 0.2065918821936626, MAE: 0.16683381944876388, R-squared: 0.9035606162870705)\n",
    "12. Ridge Regression (RMSE: 0.525636725173341, MAE: 0.429759090595957, R-squared: 0.37569139148812536)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2275b610",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f369eeb",
   "metadata": {},
   "source": [
    "## 1. Random Forest Regressor HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db09e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Forest model\n",
    "random_forest = RandomForestRegressor()\n",
    "\n",
    "# the hyperparameters and their possible values for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],  \n",
    "    'max_depth': [None, 5, 10],    \n",
    "    'min_samples_split': [2, 5, 10] \n",
    "}\n",
    "\n",
    "# Initialize Grid Search for Random Forest\n",
    "grid_search_rf = GridSearchCV(random_forest, param_grid_rf, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Perform Grid Search for Random Forest\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for Random Forest\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "\n",
    "# Predict on validation set using Random Forest\n",
    "rf_pred_val = best_rf.predict(X_val)\n",
    "\n",
    "# Calculate metrics for Random Forest on validation set\n",
    "rf_rmse_val = np.sqrt(mean_squared_error(y_val, rf_pred_val))\n",
    "rf_mae_val = mean_absolute_error(y_val, rf_pred_val)\n",
    "rf_r2_val = r2_score(y_val, rf_pred_val)\n",
    "rf_rae_val = mean_absolute_percentage_error(y_val, rf_pred_val)\n",
    "rf_rrse_val = np.sqrt(np.sum((y_val - rf_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "rf_cc_val = np.corrcoef(y_val, rf_pred_val)[0, 1]\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for Random Forest on validation set\n",
    "print(\"Best Hyperparameters for Random Forest:\", best_params_rf)\n",
    "print(\"Random Forest RMSE (Validation):\", rf_rmse_val)\n",
    "print(\"Random Forest MAE (Validation):\", rf_mae_val)\n",
    "print(\"Random Forest R-squared (Validation):\", rf_r2_val)\n",
    "print(\"Random Forest RAE (Validation):\", rf_rae_val)\n",
    "print(\"Random Forest RRSE (Validation):\", rf_rrse_val)\n",
    "print(\"Random Forest CC (Validation):\", rf_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e877720",
   "metadata": {},
   "source": [
    "## 2. LWLR HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dbcb3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the range of neighbors to consider\n",
    "param_grid_lwlr = {\n",
    "    'n_neighbors': [3, 5, 7],  # You can adjust these values\n",
    "    'weights': ['uniform', 'distance']  # You can adjust these values\n",
    "}\n",
    "\n",
    "# Initialize LWLR model\n",
    "lwlr = KNeighborsRegressor()\n",
    "\n",
    "# Initialize Grid Search for LWLR\n",
    "grid_search_lwlr = GridSearchCV(lwlr, param_grid_lwlr, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Perform Grid Search for LWLR\n",
    "grid_search_lwlr.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for LWLR\n",
    "best_lwlr = grid_search_lwlr.best_estimator_\n",
    "best_params_lwlr = grid_search_lwlr.best_params_\n",
    "\n",
    "# Predict on validation set using LWLR\n",
    "lwlr_pred_val = best_lwlr.predict(X_val)\n",
    "\n",
    "# Calculate metrics for LWLR on validation set\n",
    "lwlr_rmse_val = np.sqrt(mean_squared_error(y_val, lwlr_pred_val))\n",
    "lwlr_mae_val = mean_absolute_error(y_val, lwlr_pred_val)\n",
    "lwlr_r2_val = r2_score(y_val, lwlr_pred_val)\n",
    "lwlr_rae_val = mean_absolute_percentage_error(y_val, lwlr_pred_val)\n",
    "lwlr_rrse_val = np.sqrt(np.sum((y_val - lwlr_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "lwlr_cc_val = np.corrcoef(y_val, lwlr_pred_val)[0, 1]\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for LWLR on validation set\n",
    "print(\"Best Hyperparameters for LWLR:\", best_params_lwlr)\n",
    "print(\"LWLR RMSE (Validation):\", lwlr_rmse_val)\n",
    "print(\"LWLR MAE (Validation):\", lwlr_mae_val)\n",
    "print(\"LWLR R-squared (Validation):\", lwlr_r2_val)\n",
    "print(\"LWLR RAE (Validation):\", lwlr_rae_val)\n",
    "print(\"LWLR RRSE (Validation):\", lwlr_rrse_val)\n",
    "print(\"LWLR CC (Validation):\", lwlr_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018efbc0",
   "metadata": {},
   "source": [
    "## 3. Gaussian Process Regression HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1961f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the hyperparameters and their possible values for Gaussian Process Regression\n",
    "param_grid_gpr = {\n",
    "    'kernel': [None, 1.0 * RBF(length_scale=1.0), Matern(length_scale=1.0, nu=1.5), WhiteKernel(noise_level=1.0)],   \n",
    "  \n",
    "}\n",
    "\n",
    "# Initialize Grid Search for Gaussian Process Regression\n",
    "grid_search_gpr = GridSearchCV(GaussianProcessRegressor(), param_grid_gpr, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search_gpr.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for Gaussian Process Regression\n",
    "best_gpr = grid_search_gpr.best_estimator_\n",
    "best_params_gpr = grid_search_gpr.best_params_\n",
    "\n",
    "# Predict on validation set using Gaussian Process Regression\n",
    "gpr_pred_val = best_gpr.predict(X_val)\n",
    "\n",
    "# Calculate metrics for Gaussian Process Regression on validation set\n",
    "gpr_rmse_val = np.sqrt(mean_squared_error(y_val, gpr_pred_val))\n",
    "gpr_mae_val = mean_absolute_error(y_val, gpr_pred_val)\n",
    "gpr_r2_val = r2_score(y_val, gpr_pred_val)\n",
    "gpr_rae_val = mean_absolute_percentage_error(y_val, gpr_pred_val)\n",
    "gpr_rrse_val = np.sqrt(np.sum((y_val - gpr_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "gpr_cc_val = np.corrcoef(y_val, gpr_pred_val)[0, 1]\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for Gaussian Process Regression on validation set\n",
    "print(\"Best Hyperparameters for Gaussian Process Regression:\", best_params_gpr)\n",
    "print(\"Gaussian Process RMSE (Validation):\", gpr_rmse_val)\n",
    "print(\"Gaussian Process MAE (Validation):\", gpr_mae_val)\n",
    "print(\"Gaussian Process R-squared (Validation):\", gpr_r2_val)\n",
    "print(\"Gaussian Process RAE (Validation):\", gpr_rae_val)\n",
    "print(\"Gaussian Process RRSE (Validation):\", gpr_rrse_val)\n",
    "print(\"Gaussian Process CC (Validation):\", gpr_cc_val)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4635a20",
   "metadata": {},
   "source": [
    "## 4. Weighted K-Nearest Neighbors HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064e8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the hyperparameters and their possible values for Weighted K-Nearest Neighbors\n",
    "param_grid_wknn = {\n",
    "     'n_neighbors': [3, 5, 7, 9, 11],  \n",
    "    'weights': ['uniform', 'distance'],  \n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  \n",
    "    'leaf_size': [10, 30, 50], \n",
    "    'p': [1, 2],\n",
    "    'metric': ['euclidean', 'manhattan']  \n",
    "}\n",
    "\n",
    "# Initialize Grid Search for Weighted K-Nearest Neighbors\n",
    "grid_search_wknn = GridSearchCV(KNeighborsRegressor(), param_grid_wknn, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search_wknn.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for Weighted K-Nearest Neighbors\n",
    "best_wknn = grid_search_wknn.best_estimator_\n",
    "best_params_wknn = grid_search_wknn.best_params_\n",
    "\n",
    "# Predict on validation set using Weighted K-Nearest Neighbors\n",
    "wknn_pred_val = best_wknn.predict(X_val)\n",
    "\n",
    "# Calculate metrics for Weighted K-Nearest Neighbors on validation set\n",
    "wknn_rmse_val = np.sqrt(mean_squared_error(y_val, wknn_pred_val))\n",
    "wknn_mae_val = mean_absolute_error(y_val, wknn_pred_val)\n",
    "wknn_r2_val = r2_score(y_val, wknn_pred_val)\n",
    "wknn_rae_val = mean_absolute_percentage_error(y_val, wknn_pred_val)\n",
    "wknn_rrse_val = np.sqrt(np.sum((y_val - wknn_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "wknn_cc_val = np.corrcoef(y_val, wknn_pred_val)[0, 1]\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for Weighted K-Nearest Neighbors on validation set\n",
    "print(\"Best Hyperparameters for Weighted K-Nearest Neighbors:\", best_params_wknn)\n",
    "print(\"Weighted K-NN RMSE (Validation):\", wknn_rmse_val)\n",
    "print(\"Weighted K-NN MAE (Validation):\", wknn_mae_val)\n",
    "print(\"Weighted K-NN R-squared (Validation):\", wknn_r2_val)\n",
    "print(\"Weighted K-NN RAE (Validation):\", wknn_rae_val)\n",
    "print(\"Weighted K-NN RRSE (Validation):\", wknn_rrse_val)\n",
    "print(\"Weighted K-NN CC (Validation):\", wknn_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7121d198",
   "metadata": {},
   "source": [
    "## 5. K-Nearest Neighbors HPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9942d0aa",
   "metadata": {},
   "source": [
    "### The KNeighborsRegressor (KNN) model doesn't have traditional hyperparameters like other models (e.g., Random Forest).However, I performed hyperparameter tuning for the Locally Weighted Linear Regression (LWLR) using Grid Search with a specified range of neighbors and weight options, ultimately finding the best hyperparameters and model for LWLR, and evaluating its performance on the validation set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cfb6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the range of neighbors and weights to consider\n",
    "param_grid = {\n",
    "     'n_neighbors': [3, 5, 7, 9, 11],  \n",
    "    'weights': ['uniform', 'distance'],  \n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  \n",
    "    'leaf_size': [10, 30, 50], \n",
    "    'p': [1, 2],  \n",
    "    'metric': ['euclidean', 'manhattan'] \n",
    "}\n",
    "\n",
    "# Initialize KNN model\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train the KNN model with the best hyperparameters\n",
    "best_knn = KNeighborsRegressor(n_neighbors=best_params['n_neighbors'], weights=best_params['weights'])\n",
    "best_knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "knn_pred = best_knn.predict(X_val)\n",
    "\n",
    "# Calculate metrics for KNN\n",
    "knn_rmse = np.sqrt(mean_squared_error(y_val, knn_pred))\n",
    "knn_mae = mean_absolute_error(y_val, knn_pred)\n",
    "knn_r2 = r2_score(y_val, knn_pred)\n",
    "knn_rae = mean_absolute_percentage_error(y_val, knn_pred)\n",
    "knn_rrse = np.sqrt(np.sum((y_val - knn_pred)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "knn_cc = np.corrcoef(y_val, knn_pred)[0, 1]\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for KNN\n",
    "print(\"Best Hyperparameters for KNN:\", best_params)\n",
    "print(\"KNN RMSE:\", knn_rmse)\n",
    "print(\"KNN MAE:\", knn_mae)\n",
    "print(\"KNN R-squared:\", knn_r2)\n",
    "print(\"KNN RAE:\", knn_rae)\n",
    "print(\"KNN RRSE:\", knn_rrse)\n",
    "print(\"KNN CC:\", knn_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c090340a",
   "metadata": {},
   "source": [
    "## 6. XGBoost Regressor HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a527588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for hyperparameters\n",
    "param_dist = {\n",
    "    'n_estimators': Integer(100, 300),\n",
    "    'max_depth': Integer(3, 5),\n",
    "    'learning_rate': Real(0.01, 0.2, prior='uniform'),\n",
    "    'gamma': Real(0, 0.2, prior='uniform')\n",
    "}\n",
    "\n",
    "# Initialize Bayesian Optimization for XGBoost Regressor\n",
    "bayes_search_xgb = BayesSearchCV(\n",
    "    XGBRegressor(),\n",
    "    param_dist,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_iter=10, \n",
    "    random_state=42,  \n",
    "    n_jobs=-1,  \n",
    "    verbose=1, \n",
    "    n_points=5, \n",
    "    refit=True  \n",
    ")\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "bayes_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for XGBoost Regressor\n",
    "best_xgb = bayes_search_xgb.best_estimator_\n",
    "best_params_xgb = bayes_search_xgb.best_params_\n",
    "\n",
    "# Predict on validation set using XGBoost Regressor\n",
    "xgb_pred_val = best_xgb.predict(X_val)\n",
    "\n",
    "# Calculate metrics for XGBoost Regressor on validation set\n",
    "xgb_rmse_val = np.sqrt(mean_squared_error(y_val, xgb_pred_val))\n",
    "xgb_mae_val = mean_absolute_error(y_val, xgb_pred_val)\n",
    "xgb_r2_val = r2_score(y_val, xgb_pred_val)\n",
    "xgb_rae_val = mean_absolute_percentage_error(y_val, xgb_pred_val)\n",
    "xgb_rrse_val = np.sqrt(np.sum((y_val - xgb_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "xgb_cc_val = np.corrcoef(y_val, xgb_pred_val)[0, 1]\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for XGBoost Regressor on validation set\n",
    "print(\"Best Hyperparameters for XGBoost Regressor:\", best_params_xgb)\n",
    "print(\"XGBoost RMSE (Validation):\", xgb_rmse_val)\n",
    "print(\"XGBoost MAE (Validation):\", xgb_mae_val)\n",
    "print(\"XGBoost R-squared (Validation):\", xgb_r2_val)\n",
    "print(\"XGBoost RAE (Validation):\", xgb_rae_val)\n",
    "print(\"XGBoost RRSE (Validation):\", xgb_rrse_val)\n",
    "print(\"XGBoost CC (Validation):\", xgb_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df8bac0",
   "metadata": {},
   "source": [
    "## 7. CatBoost Regressor  HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430d21f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the search space for hyperparameters\n",
    "param_dist = {\n",
    "    'iterations': Integer(100, 300),\n",
    "    'depth': Integer(4, 8),\n",
    "    'learning_rate': Real(0.01, 0.2, prior='uniform')\n",
    "}\n",
    "\n",
    "# Initialize Bayesian Optimization for CatBoost Regressor\n",
    "bayes_search_catboost = BayesSearchCV(\n",
    "    CatBoostRegressor(verbose=0),\n",
    "    param_dist,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_iter=10,\n",
    "    random_state=42,  \n",
    "    n_jobs=-1, \n",
    "    verbose=1,  \n",
    "    n_points=5,\n",
    "    refit=True  \n",
    ")\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "bayes_search_catboost.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for CatBoost Regressor\n",
    "best_catboost = bayes_search_catboost.best_estimator_\n",
    "best_params_catboost = bayes_search_catboost.best_params_\n",
    "\n",
    "# Predict on validation set using CatBoost Regressor\n",
    "catboost_pred_val = best_catboost.predict(X_val)\n",
    "\n",
    "# Calculate metrics for CatBoost Regressor on validation set\n",
    "catboost_rmse_val = np.sqrt(mean_squared_error(y_val, catboost_pred_val))\n",
    "catboost_mae_val = mean_absolute_error(y_val, catboost_pred_val)\n",
    "catboost_r2_val = r2_score(y_val, catboost_pred_val)\n",
    "catboost_rae_val = mean_absolute_percentage_error(y_val, catboost_pred_val)\n",
    "catboost_rrse_val = np.sqrt(np.sum((y_val - catboost_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "catboost_cc_val = np.corrcoef(y_val, catboost_pred_val)[0, 1]\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for CatBoost Regressor on validation set\n",
    "print(\"Best Hyperparameters for CatBoost Regressor:\", best_params_catboost)\n",
    "print(\"CatBoost RMSE (Validation):\", catboost_rmse_val)\n",
    "print(\"CatBoost MAE (Validation):\", catboost_mae_val)\n",
    "print(\"CatBoost R-squared (Validation):\", catboost_r2_val)\n",
    "print(\"CatBoost RAE (Validation):\", catboost_rae_val)\n",
    "print(\"CatBoost RRSE (Validation):\", catboost_rrse_val)\n",
    "print(\"CatBoost CC (Validation):\", catboost_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb836b",
   "metadata": {},
   "source": [
    "## 8. LightGBM Regressor HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c565915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for hyperparameters\n",
    "param_dist = {\n",
    "    'n_estimators': Integer(100, 300),\n",
    "    'max_depth': Integer(3, 5),\n",
    "    'learning_rate': Real(0.01, 0.2, prior='uniform')\n",
    "}\n",
    "\n",
    "# Initialize Bayesian Optimization for LightGBM Regressor\n",
    "bayes_search_lgb = BayesSearchCV(\n",
    "    LGBMRegressor(verbosity=-1), \n",
    "    param_dist,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_iter=10,  \n",
    "    random_state=42, \n",
    "    n_jobs=-1,  \n",
    "    verbose=1, \n",
    "    n_points=5,  \n",
    "    refit=True \n",
    ")\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "bayes_search_lgb.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for LightGBM Regressor\n",
    "best_lgb = bayes_search_lgb.best_estimator_\n",
    "best_params_lgb = bayes_search_lgb.best_params_\n",
    "\n",
    "# Predict on validation set using LightGBM Regressor\n",
    "lgb_pred_val = best_lgb.predict(X_val)\n",
    "\n",
    "# Calculate metrics for LightGBM Regressor on validation set\n",
    "lgb_rmse_val = np.sqrt(mean_squared_error(y_val, lgb_pred_val))\n",
    "lgb_mae_val = mean_absolute_error(y_val, lgb_pred_val)\n",
    "lgb_r2_val = r2_score(y_val, lgb_pred_val)\n",
    "lgb_rae_val = mean_absolute_percentage_error(y_val, lgb_pred_val)\n",
    "lgb_rrse_val = np.sqrt(np.sum((y_val - lgb_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "lgb_cc_val = np.corrcoef(y_val, lgb_pred_val)[0, 1]\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for LightGBM Regressor on validation set\n",
    "print(\"Best Hyperparameters for LightGBM Regressor:\", best_params_lgb)\n",
    "print(\"LightGBM RMSE (Validation):\", lgb_rmse_val)\n",
    "print(\"LightGBM MAE (Validation):\", lgb_mae_val)\n",
    "print(\"LightGBM R-squared (Validation):\", lgb_r2_val)\n",
    "print(\"LightGBM RAE (Validation):\", lgb_rae_val)\n",
    "print(\"LightGBM RRSE (Validation):\", lgb_rrse_val)\n",
    "print(\"LightGBM CC (Validation):\", lgb_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df17c84a",
   "metadata": {},
   "source": [
    "## 9. Gradient Boosting Regressor HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c67431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for hyperparameters\n",
    "param_dist = {\n",
    "    'n_estimators': Integer(100, 300),\n",
    "    'max_depth': Integer(3, 5),\n",
    "    'learning_rate': Real(0.01, 0.2, prior='uniform')\n",
    "}\n",
    "\n",
    "# Initialize Bayesian Optimization for Gradient Boosting Regressor\n",
    "bayes_search_gbr = BayesSearchCV(\n",
    "    GradientBoostingRegressor(random_state=42),  \n",
    "    param_dist,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_iter=10,  \n",
    "    random_state=42,\n",
    "    n_jobs=-1, \n",
    "    verbose=1, \n",
    "    n_points=5,  \n",
    "    refit=True  \n",
    ")\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "bayes_search_gbr.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for Gradient Boosting Regressor\n",
    "best_gbr = bayes_search_gbr.best_estimator_\n",
    "best_params_gbr = bayes_search_gbr.best_params_\n",
    "\n",
    "# Predict on validation set using Gradient Boosting Regressor\n",
    "gbr_pred_val = best_gbr.predict(X_val)\n",
    "\n",
    "# Calculate metrics for Gradient Boosting Regressor on validation set\n",
    "gbr_rmse_val = np.sqrt(mean_squared_error(y_val, gbr_pred_val))\n",
    "gbr_mae_val = mean_absolute_error(y_val, gbr_pred_val)\n",
    "gbr_r2_val = r2_score(y_val, gbr_pred_val)\n",
    "gbr_rae_val = mean_absolute_percentage_error(y_val, gbr_pred_val)\n",
    "gbr_rrse_val = np.sqrt(np.sum((y_val - gbr_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "gbr_cc_val = np.corrcoef(y_val, gbr_pred_val)[0, 1]\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for Gradient Boosting Regressor on validation set\n",
    "print(\"Best Hyperparameters for Gradient Boosting Regressor:\", best_params_gbr)\n",
    "print(\"Gradient Boosting RMSE (Validation):\", gbr_rmse_val)\n",
    "print(\"Gradient Boosting MAE (Validation):\", gbr_mae_val)\n",
    "print(\"Gradient Boosting R-squared (Validation):\", gbr_r2_val)\n",
    "print(\"Gradient Boosting RAE (Validation):\", gbr_rae_val)\n",
    "print(\"Gradient Boosting RRSE (Validation):\", gbr_rrse_val)\n",
    "print(\"Gradient Boosting CC (Validation):\", gbr_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba6037e",
   "metadata": {},
   "source": [
    "## 10.Ridge Regression HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c45cbd3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameters and their possible values for Ridge Regression\n",
    "param_grid_ridge = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']} \n",
    "\n",
    "# Initialize Ridge model\n",
    "ridge = Ridge(max_iter=10000)\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search_ridge = GridSearchCV(ridge, param_grid_ridge, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Train the Grid Search\n",
    "grid_search_ridge.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and model for Ridge Regression\n",
    "best_ridge = grid_search_ridge.best_estimator_\n",
    "\n",
    "# Predict on validation set using Ridge Regression\n",
    "ridge_pred_val = best_ridge.predict(X_val)\n",
    "\n",
    "# Calculate metrics for Ridge Regression\n",
    "ridge_rmse_val = np.sqrt(mean_squared_error(y_val, ridge_pred_val))\n",
    "ridge_mae_val = mean_absolute_error(y_val, ridge_pred_val)\n",
    "ridge_r2_val = r2_score(y_val, ridge_pred_val)\n",
    "ridge_rae_val = mean_absolute_percentage_error(y_val, ridge_pred_val)\n",
    "ridge_rrse_val = np.sqrt(np.sum((y_val - ridge_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "ridge_cc_val = np.corrcoef(y_val, ridge_pred_val)[0, 1]\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for Ridge Regression\n",
    "print(\"Best Hyperparameters for Ridge Regression:\", grid_search_ridge.best_params_)\n",
    "print(\"Ridge Regression RMSE (Validation):\", ridge_rmse_val)\n",
    "print(\"Ridge Regression MAE (Validation):\", ridge_mae_val)\n",
    "print(\"Ridge Regression R-squared (Validation):\", ridge_r2_val)\n",
    "print(\"Ridge Regression RAE (Validation):\", ridge_rae_val)\n",
    "print(\"Ridge Regression RRSE (Validation):\", ridge_rrse_val)\n",
    "print(\"Ridge Regression CC (Validation):\", ridge_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d42f73d",
   "metadata": {},
   "source": [
    "# Hybrid models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b24dd05",
   "metadata": {},
   "source": [
    "## Hybrid modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d8a5f5",
   "metadata": {},
   "source": [
    "## Hybrid model 1: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9eb4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid1_pred_val = (rf_pred_val + lwlr_pred_val) / 2\n",
    "\n",
    "# Evaluate the performance of Hybrid Model 1\n",
    "hybrid1_rmse_val = np.sqrt(mean_squared_error(y_val, hybrid1_pred_val))\n",
    "hybrid1_mae_val = mean_absolute_error(y_val, hybrid1_pred_val)\n",
    "hybrid1_r2_val = r2_score(y_val, hybrid1_pred_val)\n",
    "hybrid1_rae_val = mean_absolute_percentage_error(y_val, hybrid1_pred_val)\n",
    "hybrid1_rrse_val = np.sqrt(np.sum((y_val - hybrid1_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "hybrid1_cc_val = np.corrcoef(y_val, hybrid1_pred_val)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) RMSE (Validation):\", hybrid1_rmse_val)\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) MAE (Validation):\", hybrid1_mae_val)\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) R-squared (Validation):\", hybrid1_r2_val)\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) RAE (Validation):\", hybrid1_rae_val)\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) RRSE (Validation):\", hybrid1_rrse_val)\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) CC (Validation):\", hybrid1_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a7d66",
   "metadata": {},
   "source": [
    "## Hybrid model 1: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d392139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set using Random Forest Regressor\n",
    "rf_pred_test = best_rf.predict(X_test)\n",
    "\n",
    "# Predict on the test set using Locally Weighted Linear Regression\n",
    "lwlr_pred_test = best_lwlr.predict(X_test)\n",
    "\n",
    "\n",
    "hybrid1_pred_test = (rf_pred_test + lwlr_pred_test) / 2\n",
    "\n",
    "# Calculate metrics for the hybrid model on test set\n",
    "hybrid1_rmse_test = np.sqrt(mean_squared_error(y_test, hybrid1_pred_test))\n",
    "hybrid1_mae_test = mean_absolute_error(y_test, hybrid1_pred_test)\n",
    "hybrid1_r2_test = r2_score(y_test, hybrid1_pred_test)\n",
    "hybrid1_rae_test = mean_absolute_percentage_error(y_test, hybrid1_pred_test)\n",
    "hybrid1_rrse_test = np.sqrt(np.sum((y_test - hybrid1_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "hybrid1_cc_test = np.corrcoef(y_test, hybrid1_pred_test)[0, 1]\n",
    "\n",
    "# Print evaluation metrics for Hybrid Model 1\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) RMSE (Test):\", hybrid1_rmse_test)\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) MAE (Test):\", hybrid1_mae_test)\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) R-squared (Test):\", hybrid1_r2_test)\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) RAE (Test):\", hybrid1_rae_test)\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) RRSE (Test):\", hybrid1_rrse_test)\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) CC (Test):\", hybrid1_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4cf9a8",
   "metadata": {},
   "source": [
    "## Hybrid model 2: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e024242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predictions for Hybrid Model 2 (GBR + CatBoost) on validation set\n",
    "hybrid2_pred_val = (best_lgb.predict(X_val) + best_catboost.predict(X_val)) / 2\n",
    "\n",
    "# Evaluate the performance of Hybrid Model 2\n",
    "hybrid2_rmse_val = np.sqrt(mean_squared_error(y_val, hybrid2_pred_val))\n",
    "hybrid2_mae_val = mean_absolute_error(y_val, hybrid2_pred_val)\n",
    "hybrid2_r2_val = r2_score(y_val, hybrid2_pred_val)\n",
    "hybrid2_rae_val = mean_absolute_percentage_error(y_val, hybrid2_pred_val)\n",
    "hybrid2_rrse_val = np.sqrt(np.sum((y_val - np.mean(y_val))**2) / np.sum((y_val - hybrid2_pred_val)**2))\n",
    "hybrid2_cc_val = np.corrcoef(y_val, hybrid2_pred_val)[0, 1]\n",
    "\n",
    "# Print evaluation metrics for Hybrid Model 2\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) RMSE (Validation):\", hybrid2_rmse_val)\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) MAE (Validation):\", hybrid2_mae_val)\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) R-squared (Validation):\", hybrid2_r2_val)\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) RAE (Validation):\", hybrid2_rae_val)\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) RRSE (Validation):\", hybrid2_rrse_val)\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) CC (Validation):\", hybrid2_cc_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94876937",
   "metadata": {},
   "source": [
    "## Hybrid model 2: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd93872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set using Gradient Boosting Regressor\n",
    "gbr_pred_test = best_lgb.predict(X_test)\n",
    "\n",
    "# Predict on the test set using CatBoost Regressor\n",
    "catboost_pred_test = best_catboost.predict(X_test)\n",
    "\n",
    "\n",
    "hybrid2_pred_test = (gbr_pred_test + catboost_pred_test) / 2\n",
    "\n",
    "# Evaluate the performance of Hybrid Model 2 on the test set\n",
    "hybrid2_rmse_test = np.sqrt(mean_squared_error(y_test, hybrid2_pred_test))\n",
    "hybrid2_mae_test = mean_absolute_error(y_test, hybrid2_pred_test)\n",
    "hybrid2_r2_test = r2_score(y_test, hybrid2_pred_test)\n",
    "hybrid2_rae_test = mean_absolute_percentage_error(y_test, hybrid2_pred_test)\n",
    "hybrid2_rrse_test = np.sqrt(np.sum((y_test - hybrid2_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "hybrid2_cc_test = np.corrcoef(y_test, hybrid2_pred_test)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) RMSE (Test):\", hybrid2_rmse_test)\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) MAE (Test):\", hybrid2_mae_test)\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) R-squared (Test):\", hybrid2_r2_test)\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) RAE (Test):\", hybrid2_rae_test)\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) RRSE (Test):\", hybrid2_rrse_test)\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) CC (Test):\", hybrid2_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9947f938",
   "metadata": {},
   "source": [
    "## Hybrid model 3: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c51be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid3_pred_val = (ridge_pred_val + lwlr_pred_val) / 2\n",
    "\n",
    "# Calculate metrics for the hybrid model on validation set\n",
    "hybrid3_rmse_val = np.sqrt(mean_squared_error(y_val, hybrid3_pred_val))\n",
    "hybrid3_mae_val = mean_absolute_error(y_val, hybrid3_pred_val)\n",
    "hybrid3_r2_val = r2_score(y_val, hybrid3_pred_val)\n",
    "hybrid3_rae_val = mean_absolute_percentage_error(y_val, hybrid3_pred_val)\n",
    "hybrid3_rrse_val = np.sqrt(np.sum((y_val - hybrid3_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "hybrid3_cc_val = np.corrcoef(y_val, hybrid3_pred_val)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) RMSE (Validation):\", hybrid3_rmse_val)\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) MAE (Validation):\", hybrid3_mae_val)\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) R-squared (Validation):\", hybrid3_r2_val)\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) RAE (Validation):\", hybrid3_rae_val)\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) RRSE (Validation):\", hybrid3_rrse_val)\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) CC (Validation):\", hybrid3_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a23a6",
   "metadata": {},
   "source": [
    "## Hybrid model 3: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857f346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set using Ridge Regression\n",
    "ridge_pred_test = best_ridge.predict(X_test)\n",
    "\n",
    "# Predict on the test set using Locally Weighted Linear Regression\n",
    "lwlr_pred_test = best_lwlr.predict(X_test)\n",
    "\n",
    "hybrid3_pred_test = (ridge_pred_test + lwlr_pred_test) / 2\n",
    "\n",
    "# Calculate metrics for the hybrid model 3 on test set\n",
    "hybrid3_rmse_test = np.sqrt(mean_squared_error(y_test, hybrid3_pred_test))\n",
    "hybrid3_mae_test = mean_absolute_error(y_test, hybrid3_pred_test)\n",
    "hybrid3_r2_test = r2_score(y_test, hybrid3_pred_test)\n",
    "hybrid3_rae_test = mean_absolute_percentage_error(y_test, hybrid3_pred_test)\n",
    "hybrid3_rrse_test = np.sqrt(np.sum((y_test - hybrid3_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "hybrid3_cc_test = np.corrcoef(y_test, hybrid3_pred_test)[0, 1]\n",
    "\n",
    "# Print evaluation metrics for Hybrid Model 3\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) RMSE (Test):\", hybrid3_rmse_test)\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) MAE (Test):\", hybrid3_mae_test)\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) R-squared (Test):\", hybrid3_r2_test)\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) RAE (Test):\", hybrid3_rae_test)\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) RRSE (Test):\", hybrid3_rrse_test)\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) CC (Test):\", hybrid3_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b5fadf",
   "metadata": {},
   "source": [
    "## Hybrid model 4: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e8ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights for models\n",
    "weight_rf = 0.4\n",
    "weight_lgb = 0.3\n",
    "weight_catboost = 0.3\n",
    "\n",
    "# Combine predictions\n",
    "hybrid4_pred_val = (weight_rf * rf_pred_val + weight_lgb * lgb_pred_val + weight_catboost * catboost_pred_val)\n",
    "\n",
    "# Evaluate the performance of Hybrid Model 4\n",
    "hybrid4_rmse_val = np.sqrt(mean_squared_error(y_val, hybrid4_pred_val))\n",
    "hybrid4_mae_val = mean_absolute_error(y_val, hybrid4_pred_val)\n",
    "hybrid4_r2_val = r2_score(y_val, hybrid4_pred_val)\n",
    "hybrid4_rae_val = mean_absolute_percentage_error(y_val, hybrid4_pred_val)\n",
    "hybrid4_rrse_val = np.sqrt(np.sum((y_val - hybrid4_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "hybrid4_cc_val = np.corrcoef(y_val, hybrid4_pred_val)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) RMSE (Validation):\", hybrid4_rmse_val)\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) MAE (Validation):\", hybrid4_mae_val)\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) R-squared (Validation):\", hybrid4_r2_val)\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) RAE (Validation):\", hybrid4_rae_val)\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) RRSE (Validation):\", hybrid4_rrse_val)\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) CC (Validation):\", hybrid4_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db624188",
   "metadata": {},
   "source": [
    "## Hybrid model 4: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09784359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights for models\n",
    "weight_rf = 0.4\n",
    "weight_lgb = 0.3\n",
    "weight_catboost = 0.3\n",
    "\n",
    "\n",
    "rf_pred_test = best_rf.predict(X_test)  \n",
    "lgb_pred_test = best_lgb.predict(X_test) \n",
    "catboost_pred_test = best_catboost.predict(X_test)\n",
    "\n",
    "# Combine predictions for the test set\n",
    "hybrid4_pred_test = (weight_rf * rf_pred_test + weight_lgb * lgb_pred_test + weight_catboost * catboost_pred_test)\n",
    "\n",
    "# Evaluate the performance of Hybrid Model 4 on the test set\n",
    "hybrid4_rmse_test = np.sqrt(mean_squared_error(y_test, hybrid4_pred_test))\n",
    "hybrid4_mae_test = mean_absolute_error(y_test, hybrid4_pred_test)\n",
    "hybrid4_r2_test = r2_score(y_test, hybrid4_pred_test)\n",
    "hybrid4_rae_test = mean_absolute_percentage_error(y_test, hybrid4_pred_test)\n",
    "hybrid4_rrse_test = np.sqrt(np.sum((y_test - hybrid4_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "hybrid4_cc_test = np.corrcoef(y_test, hybrid4_pred_test)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) RMSE (Test):\", hybrid4_rmse_test)\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) MAE (Test):\", hybrid4_mae_test)\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) R-squared (Test):\", hybrid4_r2_test)\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) RAE (Test):\", hybrid4_rae_test)\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) RRSE (Test):\", hybrid4_rrse_test)\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) CC (Test):\", hybrid4_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ca5e23",
   "metadata": {},
   "source": [
    "## Hybrid model 5: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7fa830",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid5_pred_val = (rf_pred_val + gpr_pred_val + lgb_pred_val) / 3\n",
    "\n",
    "# Calculate metrics for the hybrid model 5 on validation set\n",
    "hybrid5_rmse_val = np.sqrt(mean_squared_error(y_val, hybrid5_pred_val))\n",
    "hybrid5_mae_val = mean_absolute_error(y_val, hybrid5_pred_val)\n",
    "hybrid5_r2_val = r2_score(y_val, hybrid5_pred_val)\n",
    "hybrid5_rae_val = mean_absolute_percentage_error(y_val, hybrid5_pred_val)\n",
    "hybrid5_rrse_val = np.sqrt(np.sum((y_val - hybrid5_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "hybrid5_cc_val = np.corrcoef(y_val, hybrid5_pred_val)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) RMSE:\", hybrid5_rmse_val)\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) MAE:\", hybrid5_mae_val)\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) R-squared:\", hybrid5_r2_val)\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) RAE:\", hybrid5_rae_val)\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) RRSE:\", hybrid5_rrse_val)\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) CC:\", hybrid5_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3ca246",
   "metadata": {},
   "source": [
    "## Hybrid model 5: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d1b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpr_pred_test = best_gpr.predict(X_test)\n",
    "\n",
    "hybrid5_pred_test = (rf_pred_test + gpr_pred_test + lgb_pred_test) / 3\n",
    "\n",
    "# Calculate metrics for the hybrid model 5 on the test set\n",
    "hybrid5_rmse_test = np.sqrt(mean_squared_error(y_test, hybrid5_pred_test))\n",
    "hybrid5_mae_test = mean_absolute_error(y_test, hybrid5_pred_test)\n",
    "hybrid5_r2_test = r2_score(y_test, hybrid5_pred_test)\n",
    "hybrid5_rae_test = mean_absolute_percentage_error(y_test, hybrid5_pred_test)\n",
    "hybrid5_rrse_test = np.sqrt(np.sum((y_test - hybrid5_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "hybrid5_cc_test = np.corrcoef(y_test, hybrid5_pred_test)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) RMSE (Test):\", hybrid5_rmse_test)\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) MAE (Test):\", hybrid5_mae_test)\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) R-squared (Test):\", hybrid5_r2_test)\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) RAE (Test):\", hybrid5_rae_test)\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) RRSE (Test):\", hybrid5_rrse_test)\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) CC (Test):\", hybrid5_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c8f0a8",
   "metadata": {},
   "source": [
    "## Hybrid model 6: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0b90c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid6_pred_val = (knn_pred + xgb_pred_val + catboost_pred_val) / 3\n",
    "\n",
    "# Calculate metrics for the hybrid model 6 on validation set\n",
    "hybrid6_rmse_val = np.sqrt(mean_squared_error(y_val, hybrid6_pred_val))\n",
    "hybrid6_mae_val = mean_absolute_error(y_val, hybrid6_pred_val)\n",
    "hybrid6_r2_val = r2_score(y_val, hybrid6_pred_val)\n",
    "hybrid6_rae_val = mean_absolute_percentage_error(y_val, hybrid6_pred_val)\n",
    "hybrid6_rrse_val = np.sqrt(np.sum((y_val - hybrid6_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "hybrid6_cc_val = np.corrcoef(y_val, hybrid6_pred_val)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) RMSE (Validation):\", hybrid6_rmse_val)\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) MAE (Validation):\", hybrid6_mae_val)\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) R-squared (Validation):\", hybrid6_r2_val)\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) RAE (Validation):\", hybrid6_rae_val)\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) RRSE (Validation):\", hybrid6_rrse_val)\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) CC (Validation):\", hybrid6_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a250919e",
   "metadata": {},
   "source": [
    "## Hybrid model 6: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c9a872",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn_pred_test = best_knn.predict(X_test)\n",
    "best_xgb_pred_test = best_xgb.predict(X_test)\n",
    "best_catboost_pred_test = best_catboost.predict(X_test)\n",
    "\n",
    "hybrid6_pred_test = (best_knn_pred_test + best_xgb_pred_test + best_catboost_pred_test) / 3\n",
    "\n",
    "# Calculate metrics for the hybrid model 6 on test set\n",
    "hybrid6_rmse_test = np.sqrt(mean_squared_error(y_test, hybrid6_pred_test))\n",
    "hybrid6_mae_test = mean_absolute_error(y_test, hybrid6_pred_test)\n",
    "hybrid6_r2_test = r2_score(y_test, hybrid6_pred_test)\n",
    "hybrid6_rae_test = mean_absolute_percentage_error(y_test, hybrid6_pred_test)\n",
    "hybrid6_rrse_test = np.sqrt(np.sum((y_test - hybrid6_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "hybrid6_cc_test = np.corrcoef(y_test, hybrid6_pred_test)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) RMSE (Test):\", hybrid6_rmse_test)\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) MAE (Test):\", hybrid6_mae_test)\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) R-squared (Test):\", hybrid6_r2_test)\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) RAE (Test):\", hybrid6_rae_test)\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) RRSE (Test):\", hybrid6_rrse_test)\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) CC (Test):\", hybrid6_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da6cba7",
   "metadata": {},
   "source": [
    "## Hybrid model 7: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e2ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid7_pred_val = (rf_pred_val + lwlr_pred_val + gpr_pred_val + wknn_pred_val) / 4\n",
    "\n",
    "# Calculate metrics for the hybrid model 7 on validation set\n",
    "hybrid7_rmse_val = np.sqrt(mean_squared_error(y_val, hybrid7_pred_val))\n",
    "hybrid7_mae_val = mean_absolute_error(y_val, hybrid7_pred_val)\n",
    "hybrid7_r2_val = r2_score(y_val, hybrid7_pred_val)\n",
    "hybrid7_rae_val = mean_absolute_percentage_error(y_val, hybrid7_pred_val)\n",
    "hybrid7_rrse_val = np.sqrt(np.sum((y_val - hybrid7_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "hybrid7_cc_val = np.corrcoef(y_val, hybrid7_pred_val)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) RMSE (Validation):\", hybrid7_rmse_val)\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) MAE (Validation):\", hybrid7_mae_val)\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) R-squared (Validation):\", hybrid7_r2_val)\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) RAE (Validation):\", hybrid7_rae_val)\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) RRSE (Validation):\", hybrid7_rrse_val)\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) CC (Validation):\", hybrid7_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb54ec10",
   "metadata": {},
   "source": [
    "## Hybrid model 7: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90405ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set using Random Forest Regressor\n",
    "rf_pred_test = best_rf.predict(X_test)\n",
    "\n",
    "# Predict on the test set using Locally Weighted Linear Regression\n",
    "lwlr_pred_test = best_lwlr.predict(X_test)\n",
    "\n",
    "# Predict on the test set using Gaussian Process Regressor\n",
    "gpr_pred_test = best_gpr.predict(X_test)\n",
    "\n",
    "# Predict on the test set using Weighted k-Nearest Neighbors Regressor\n",
    "wknn_pred_test = best_wknn.predict(X_test)\n",
    "\n",
    "hybrid7_pred_test = (rf_pred_test + lwlr_pred_test + gpr_pred_test + wknn_pred_test) / 4\n",
    "\n",
    "# Calculate metrics for the hybrid model 7 on test set\n",
    "hybrid7_rmse_test = np.sqrt(mean_squared_error(y_test, hybrid7_pred_test))\n",
    "hybrid7_mae_test = mean_absolute_error(y_test, hybrid7_pred_test)\n",
    "hybrid7_r2_test = r2_score(y_test, hybrid7_pred_test)\n",
    "hybrid7_rae_test = mean_absolute_percentage_error(y_test, hybrid7_pred_test)\n",
    "hybrid7_rrse_test = np.sqrt(np.sum((y_test - hybrid7_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "hybrid7_cc_test = np.corrcoef(y_test, hybrid7_pred_test)[0, 1]\n",
    "\n",
    "# Print evaluation metrics for Hybrid Model 7\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) RMSE (Test):\", hybrid7_rmse_test)\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) MAE (Test):\", hybrid7_mae_test)\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) R-squared (Test):\", hybrid7_r2_test)\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) RAE (Test):\", hybrid7_rae_test)\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) RRSE (Test):\", hybrid7_rrse_test)\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) CC (Test):\", hybrid7_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c569206",
   "metadata": {},
   "source": [
    "## Hybrid model 8: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d7c670",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hybrid8_pred_val = (xgb_pred_val + catboost_pred_val + lgb_pred_val + ridge_pred_val) / 4\n",
    "\n",
    "# Calculate metrics for the hybrid model on validation set\n",
    "hybrid8_rmse_val = np.sqrt(mean_squared_error(y_val, hybrid8_pred_val))\n",
    "hybrid8_mae_val = mean_absolute_error(y_val, hybrid8_pred_val)\n",
    "hybrid8_r2_val = r2_score(y_val, hybrid8_pred_val)\n",
    "hybrid8_rae_val = mean_absolute_percentage_error(y_val, hybrid8_pred_val)\n",
    "hybrid8_rrse_val = np.sqrt(np.sum((y_val - hybrid8_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "hybrid8_cc_val = np.corrcoef(y_val, hybrid8_pred_val)[0, 1]\n",
    "\n",
    "# Print evaluation metrics for Hybrid Model 8\n",
    "print(\"Hybrid Model 8 (XGB + CatBoost + GBR + Ridge) RMSE (Validation):\", hybrid8_rmse_val)\n",
    "print(\"Hybrid Model 8 (XGB + CatBoost + GBR + Ridge) MAE (Validation):\", hybrid8_mae_val)\n",
    "print(\"Hybrid Model 8 (XGB + CatBoost + GBR + Ridge) R-squared (Validation):\", hybrid8_r2_val)\n",
    "print(\"Hybrid Model 8 (XGB + CatBoost + GBR + Ridge) RAE (Validation):\", hybrid8_rae_val)\n",
    "print(\"Hybrid Model 8 (XGB + CatBoost + GBR + Ridge) RRSE (Validation):\", hybrid8_rrse_val)\n",
    "print(\"Hybrid Model 8 (XGB + CatBoost + GBR + Ridge) CC (Validation):\", hybrid8_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0acacce",
   "metadata": {},
   "source": [
    "## Hybrid model 8: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b594c43c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict on the test set using the hybrid model\n",
    "hybrid8_pred_test = (best_xgb.predict(X_test) + best_catboost.predict(X_test) + best_lgb.predict(X_test) + best_ridge.predict(X_test)) / 4\n",
    "\n",
    "# Calculate metrics for the hybrid model 8 on the test set\n",
    "hybrid8_rmse_test = np.sqrt(mean_squared_error(y_test, hybrid8_pred_test))\n",
    "hybrid8_mae_test = mean_absolute_error(y_test, hybrid8_pred_test)\n",
    "hybrid8_r2_test = r2_score(y_test, hybrid8_pred_test)\n",
    "hybrid8_rae_test = mean_absolute_percentage_error(y_test, hybrid8_pred_test)\n",
    "hybrid8_rrse_test = np.sqrt(np.sum((y_test - hybrid8_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "hybrid8_cc_test = np.corrcoef(y_test, hybrid8_pred_test)[0, 1]\n",
    "\n",
    "# Print evaluation metrics for the hybrid model 8 on the test set\n",
    "print(\"Hybrid Model 5 (XGB + CatBoost + GBR + Ridge) RMSE (Test):\", hybrid8_rmse_test)\n",
    "print(\"Hybrid Model 5 (XGB + CatBoost + GBR + Ridge) MAE (Test):\", hybrid8_mae_test)\n",
    "print(\"Hybrid Model 5 (XGB + CatBoost + GBR + Ridge) R-squared (Test):\", hybrid8_r2_test)\n",
    "print(\"Hybrid Model 5 (XGB + CatBoost + GBR + Ridge) RAE (Test):\", hybrid8_rae_test)\n",
    "print(\"Hybrid Model 5 (XGB + CatBoost + GBR + Ridge) RRSE (Test):\", hybrid8_rrse_test)\n",
    "print(\"Hybrid Model 5 (XGB + CatBoost + GBR + Ridge) CC (Test):\", hybrid8_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5becd",
   "metadata": {},
   "source": [
    "## Hybrid model 9: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23037212",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('rf', best_rf),\n",
    "    ('gpr', best_gpr),\n",
    "    ('lgb', best_lgb),\n",
    "    ('xgb', best_xgb),\n",
    "    ('catboost', best_catboost)\n",
    "]\n",
    "\n",
    "# Define the stacking model with a meta regressor \n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=best_lgb,  \n",
    "    cv=5  \n",
    ")\n",
    "\n",
    "# Fit the stacking model on the training data\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set using the stacking model\n",
    "hybrid9_pred_val = stacking_model.predict(X_val)\n",
    "\n",
    "# Calculate metrics for the hybrid model 9 on the validation set\n",
    "hybrid9_rmse_val = np.sqrt(mean_squared_error(y_val, hybrid9_pred_val))\n",
    "hybrid9_mae_val = mean_absolute_error(y_val, hybrid9_pred_val)\n",
    "hybrid9_r2_val = r2_score(y_val, hybrid9_pred_val)\n",
    "hybrid9_rae_val = mean_absolute_percentage_error(y_val, hybrid9_pred_val)\n",
    "hybrid9_rrse_val = np.sqrt(np.sum((y_val - hybrid9_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "hybrid9_cc_val = np.corrcoef(y_val, hybrid9_pred_val)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 9 RMSE (Validation):\", hybrid9_rmse_val)\n",
    "print(\"Hybrid Model 9 MAE (Validation):\", hybrid9_mae_val)\n",
    "print(\"Hybrid Model 9 R-squared (Validation):\", hybrid9_r2_val)\n",
    "print(\"Hybrid Model 9 RAE (Validation):\", hybrid9_rae_val)\n",
    "print(\"Hybrid Model 9 RRSE (Validation):\", hybrid9_rrse_val)\n",
    "print(\"Hybrid Model 9 CC (Validation):\", hybrid9_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5f32f7",
   "metadata": {},
   "source": [
    "## Hybrid model 9: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc2e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set using the stacking model\n",
    "hybrid9_pred_test = stacking_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for the hybrid model 9 on test set\n",
    "hybrid9_rmse_test = np.sqrt(mean_squared_error(y_test, hybrid9_pred_test))\n",
    "hybrid9_mae_test = mean_absolute_error(y_test, hybrid9_pred_test)\n",
    "hybrid9_r2_test = r2_score(y_test, hybrid9_pred_test)\n",
    "hybrid9_rae_test = mean_absolute_percentage_error(y_test, hybrid9_pred_test)\n",
    "hybrid9_rrse_test = np.sqrt(np.sum((y_test - hybrid9_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "hybrid9_cc_test = np.corrcoef(y_test, hybrid9_pred_test)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 9 RMSE (Test):\", hybrid9_rmse_test)\n",
    "print(\"Hybrid Model 9 MAE (Test):\", hybrid9_mae_test)\n",
    "print(\"Hybrid Model 9 R-squared (Test):\", hybrid9_r2_test)\n",
    "print(\"Hybrid Model 9 RAE (Test):\", hybrid9_rae_test)\n",
    "print(\"Hybrid Model 9 RRSE (Test):\", hybrid9_rrse_test)\n",
    "print(\"Hybrid Model 9 CC (Test):\", hybrid9_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57041f40",
   "metadata": {},
   "source": [
    "## Hybrid model 10: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a765c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the weights for each model\n",
    "weight_rf = 0.2\n",
    "weight_lwlr = 0.2\n",
    "weight_gpr = 0.1\n",
    "weight_wknn = 0.1\n",
    "weight_knn = 0.1\n",
    "weight_xgb = 0.05\n",
    "weight_catboost = 0.05\n",
    "weight_lgb = 0.05\n",
    "weight_gbr = 0.05\n",
    "weight_ridge = 0.05\n",
    "\n",
    "# Create hybrid predictions\n",
    "hybrid10_pred_val = (\n",
    "    weight_rf * rf_pred_val +\n",
    "    weight_lwlr * lwlr_pred_val +\n",
    "    weight_gpr * gpr_pred_val +\n",
    "    weight_wknn * wknn_pred_val +\n",
    "    weight_knn * knn_pred + \n",
    "    weight_xgb * xgb_pred_val +\n",
    "    weight_catboost * catboost_pred_val +\n",
    "    weight_gbr * gbr_pred_val +\n",
    "    weight_lgb * lgb_pred_val +\n",
    "    weight_ridge * ridge_pred_val  \n",
    ")\n",
    "\n",
    "# Calculate metrics for the hybrid model 10 on the validation set\n",
    "hybrid10_rmse_val = mean_squared_error(y_val, hybrid10_pred_val, squared=False)\n",
    "hybrid10_mae_val = mean_absolute_error(y_val, hybrid10_pred_val)\n",
    "hybrid10_r2_val = r2_score(y_val, hybrid10_pred_val)\n",
    "hybrid10_rae_val = hybrid10_mae_val / np.mean(np.abs(y_val - np.mean(y_val)))\n",
    "hybrid10_rrse_val = hybrid10_rmse_val / np.sqrt(np.mean((y_val - np.mean(y_val))**2))\n",
    "hybrid10_cc_val = np.corrcoef(y_val, hybrid10_pred_val)[0, 1]\n",
    "\n",
    "# Print evaluation metrics for the hybrid model 10 on the validation set\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) RMSE (Validation):\", hybrid10_rmse_val)\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) MAE (Validation):\", hybrid10_mae_val)\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) R-squared (Validation):\", hybrid10_r2_val)\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) RAE (Validation):\", hybrid10_rae_val)\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) RRSE (Validation):\", hybrid10_rrse_val)\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) CC (Validation):\", hybrid10_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb62c32",
   "metadata": {},
   "source": [
    "## Hybrid model 10: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4653c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the weights for each model\n",
    "weight_rf = 0.2\n",
    "weight_lwlr = 0.2\n",
    "weight_gpr = 0.1\n",
    "weight_wknn = 0.1\n",
    "weight_knn = 0.1\n",
    "weight_xgb = 0.05\n",
    "weight_catboost = 0.05\n",
    "weight_lgb = 0.05\n",
    "weight_gbr = 0.05\n",
    "weight_ridge = 0.05\n",
    "\n",
    "# Create hybrid predictions\n",
    "hybrid10_pred_test = (\n",
    "    weight_rf * rf_pred_test +\n",
    "    weight_lwlr * lwlr_pred_test +\n",
    "    weight_gpr * gpr_pred_test +\n",
    "    weight_wknn * wknn_pred_test +\n",
    "    weight_knn * knn_pred + \n",
    "    weight_xgb * xgb_pred_test +\n",
    "    weight_catboost * catboost_pred_test +\n",
    "    weight_gbr * gbr_pred_test +\n",
    "    weight_lgb * lgb_pred_test +\n",
    "    weight_ridge * ridge_pred_test  \n",
    ")\n",
    "\n",
    "\n",
    "rf_pred_test = best_rf.predict(X_test)\n",
    "lwlr_pred_test = best_lwlr.predict(X_test)\n",
    "gpr_pred_test = best_gpr.predict(X_test)\n",
    "wknn_pred_test=best_wknn.predict(X_test)\n",
    "knn_pred_test=best_knn.predict(X_test)\n",
    "xgb_pred_test = best_xgb.predict(X_test)\n",
    "catboost_pred_test = best_catboost.predict(X_test)\n",
    "gbr_pred_test = best_gbr.predict(X_test)\n",
    "lgb_pred_test = best_lgb.predict(X_test)\n",
    "ridge_pred_test = best_ridge.predict(X_test)\n",
    "\n",
    "# Calculate metrics for the hybrid model 10 on the testidation set\n",
    "hybrid10_rmse_test = mean_squared_error(y_test, hybrid10_pred_test, squared=False)\n",
    "hybrid10_mae_test = mean_absolute_error(y_test, hybrid10_pred_test)\n",
    "hybrid10_r2_test = r2_score(y_test, hybrid10_pred_test)\n",
    "hybrid10_rae_test = hybrid10_mae_test / np.mean(np.abs(y_test - np.mean(y_test)))\n",
    "hybrid10_rrse_test = hybrid10_rmse_test / np.sqrt(np.mean((y_test - np.mean(y_test))**2))\n",
    "hybrid10_cc_test = np.corrcoef(y_test, hybrid10_pred_test)[0, 1]\n",
    "\n",
    "# Print etestuation metrics for the hybrid model 10 on the testidation set\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) RMSE (testidation):\", hybrid10_rmse_test)\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) MAE (testidation):\", hybrid10_mae_test)\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) R-squared (testidation):\", hybrid10_r2_test)\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) RAE (testidation):\", hybrid10_rae_test)\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) RRSE (testidation):\", hybrid10_rrse_test)\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) CC (testidation):\", hybrid10_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dd5b90",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b413c681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e56cb7e3",
   "metadata": {},
   "source": [
    "## Scatter plot: Training: Actual vs. Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3bc900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.scatter(y_val, hybrid1_pred_val, color='red', edgecolors='black', s=40, linewidths=1.5, label='Hybrid Model 1')\n",
    "plt.scatter(y_val, hybrid2_pred_val, color='green', edgecolors='red', s=70, linewidths=1.5, alpha=0.2, label='Hybrid Model 2')\n",
    "plt.scatter(y_val, hybrid3_pred_val, color='blue', edgecolors='black', s=50, linewidths=1.5,alpha=0.1, label='Hybrid Model 3')\n",
    "plt.scatter(y_val, hybrid4_pred_val, color='orange', edgecolors='black', s=70, linewidths=1.5, label='Hybrid Model 4')\n",
    "plt.scatter(y_val,  hybrid5_pred_val, color='purple', edgecolors='blue', s=50, linewidths=1.5, label='Hybrid Model 5')\n",
    "plt.scatter(y_val, hybrid6_pred_val, color='pink', edgecolors='black', s=70, linewidths=1.5,alpha=0.3, label='Hybrid Model 6')\n",
    "plt.scatter(y_val,  hybrid7_pred_val, color='purple', edgecolors='black', s=50, linewidths=1.5, label='Hybrid Model 7')\n",
    "plt.scatter(y_val, hybrid8_pred_val, color='cyan', edgecolors='black', s=40, linewidths=1.5,alpha=0.2, label='Hybrid Model 8')\n",
    "plt.scatter(y_val, hybrid9_pred_val, color='#FF00FF', edgecolors='black', s=50, linewidths=1.5, label='Hybrid Model 9')\n",
    "plt.scatter(y_val, hybrid10_pred_val, color='#00FFFF', edgecolors='black', s=50, linewidths=2,alpha=0.1 ,label='Hybrid Model 10')\n",
    "\n",
    "plt.plot([2, 6], [2, 6], color='black')\n",
    "plt.xlabel('Actual Values (val)')\n",
    "plt.ylabel('Predicted Values (val)')\n",
    "plt.title('10 Hybrid Models: Actual vs. Predicted(val)')\n",
    "plt.grid(False)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96757e7",
   "metadata": {},
   "source": [
    "## Scatter plot: Test: Actual vs. Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dcf9c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.scatter(y_test, hybrid1_pred_test, color='red', edgecolors='black', s=40, linewidths=1.5, label='Hybrid Model 1')\n",
    "plt.scatter(y_test, hybrid2_pred_test, color='green', edgecolors='red', s=70, linewidths=1.5, alpha=0.2, label='Hybrid Model 2')\n",
    "plt.scatter(y_test, hybrid3_pred_test, color='blue', edgecolors='black', s=50, linewidths=1.5,alpha=0.1, label='Hybrid Model 3')\n",
    "plt.scatter(y_test, hybrid4_pred_test, color='orange', edgecolors='black', s=70, linewidths=1.5, label='Hybrid Model 4')\n",
    "plt.scatter(y_test,  hybrid5_pred_test, color='purple', edgecolors='blue', s=50, linewidths=1.5, label='Hybrid Model 5')\n",
    "plt.scatter(y_test, hybrid6_pred_test, color='pink', edgecolors='black', s=70, linewidths=1.5,alpha=0.3, label='Hybrid Model 6')\n",
    "plt.scatter(y_test,  hybrid7_pred_test, color='purple', edgecolors='black', s=50, linewidths=1.5, label='Hybrid Model 7')\n",
    "plt.scatter(y_test, hybrid8_pred_test, color='cyan', edgecolors='black', s=40, linewidths=1.5,alpha=0.2, label='Hybrid Model 8')\n",
    "plt.scatter(y_test, hybrid9_pred_test, color='#FF00FF', edgecolors='black', s=50, linewidths=1.5, label='Hybrid Model 9')\n",
    "plt.scatter(y_test, hybrid10_pred_test, color='#00FFFF', edgecolors='black', s=50, linewidths=2,alpha=0.1 ,label='Hybrid Model 10')\n",
    "\n",
    "plt.plot([2, 6], [2, 6], color='black')\n",
    "plt.xlabel('Actual Values (Test)')\n",
    "plt.ylabel('Predicted Values (Test)')\n",
    "plt.title('10 Hybrid Models: Actual vs. Predicted(Test)')\n",
    "plt.grid(False)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dd84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual and predicted values for test set\n",
    "\n",
    "hybrid1_test = pd.DataFrame({'Actual Values': y_test.values, 'Predicted Values': hybrid1_pred_test})\n",
    "print(\"\\nTest Set:\")\n",
    "hybrid1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c430f539",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the models and their corresponding predictions\n",
    "models_predictions = {\n",
    "    'Hybrid Model 1': hybrid1_pred_test,\n",
    "    'Hybrid Model 2': hybrid2_pred_test,\n",
    "    'Hybrid Model 3': hybrid3_pred_test,\n",
    "    'Hybrid Model 4': hybrid4_pred_test,\n",
    "    'Hybrid Model 5': hybrid5_pred_test,\n",
    "    'Hybrid Model 6': hybrid6_pred_test,\n",
    "    'Hybrid Model 7': hybrid7_pred_test,\n",
    "    'Hybrid Model 8': hybrid8_pred_test,\n",
    "    'Hybrid Model 9': hybrid9_pred_test,\n",
    "    'Hybrid Model 10': hybrid10_pred_test\n",
    "}\n",
    "\n",
    "# Create a DataFrame for the actual values (y_test)\n",
    "actual_values = pd.DataFrame({'Actual Values': y_test.values})\n",
    "\n",
    "# Create a plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the actual values\n",
    "plt.plot(actual_values.index, actual_values['Actual Values'], label='Actual Values', linestyle='-', marker='o', markersize=3)\n",
    "\n",
    "# Plot the predicted values for each model\n",
    "for model_name, predictions in models_predictions.items():\n",
    "    plt.plot(actual_values.index, predictions, label=model_name, linestyle='-', marker='o', markersize=3, alpha=0.7)\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Dinajpur-34 (Dinajpur Sadar)')\n",
    "plt.title(\"Actual vs. Predicted Values Over Index\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48962458",
   "metadata": {},
   "source": [
    "# Time series plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b53b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], format=\"%d.%m.%Y\")\n",
    "\n",
    "# Set the 'Date' column as the index\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Create a time series plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plotting the time series data for each hybrid model\n",
    "\n",
    "plt.plot(df.index, hybrid1_pred_val, color='red', linewidth=1.5, label='Hybrid Model 1')\n",
    "plt.plot(df.index, hybrid2_pred_val, color='green', linewidth=1.5, alpha=0.2, label='Hybrid Model 2')\n",
    "plt.plot(df.index, hybrid3_pred_val, color='blue', linewidth=1.5, alpha=0.3, label='Hybrid Model 3')\n",
    "plt.plot(df.index, hybrid4_pred_val, color='orange', linewidth=1.5, label='Hybrid Model 4')\n",
    "plt.plot(df.index, hybrid5_pred_val, color='purple', linewidth=1.5, label='Hybrid Model 5')\n",
    "plt.plot(df.index, hybrid6_pred_val, color='pink', linewidth=1.5, alpha=0.3, label='Hybrid Model 6')\n",
    "plt.plot(df.index, hybrid7_pred_val, color='purple', linewidth=1.5, label='Hybrid Model 7')\n",
    "plt.plot(df.index, hybrid8_pred_val, color='cyan', linewidth=1.5, alpha=0.2, label='Hybrid Model 8')\n",
    "plt.plot(df.index, hybrid9_pred_val, color='#00FFFF', linewidth=2, alpha=0.1, label='Hybrid Model 9')\n",
    "plt.plot(df.index, hybrid10_pred_val, color='#00FFFF', linewidth=2, alpha=0.1, label='Hybrid Model 10')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Predicted Values (Training)')\n",
    "plt.title('10 Hybrid Models: Actual vs. Predicted (Training)')\n",
    "plt.grid(False)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c7bd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the following variables:\n",
    "actual_values_train = df_train['Actual Values']  # Replace df_train with your actual DataFrame\n",
    "predicted_values_train = df_train['Predicted Values']  # Replace df_train with your actual DataFrame\n",
    "\n",
    "# Create a time axis (x-axis) for training set\n",
    "time_points_train = range(len(actual_values_train))\n",
    "\n",
    "# Plot the actual values during training\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_points_train, actual_values_train, label='Actual (Training)', color='blue')\n",
    "plt.plot(time_points_train, predicted_values_train, label='Predicted (Training)', color='red')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Actual vs. Predicted Values (Training Stage)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a7215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame with the time series data\n",
    "# Convert the 'Date' column to a datetime object\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Set the 'Date' column as the index\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Create a time series plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plotting the time series data for each hybrid model\n",
    "plt.plot(df.index, y_test, color='red', linewidth=1.5, label='Hybrid Model 1')\n",
    "plt.plot(df.index, hybrid1_pred_test, color='red', linewidth=1.5, label='Hybrid Model 1')\n",
    "plt.plot(df.index, hybrid2_pred_test, color='green', linewidth=1.5, alpha=0.2, label='Hybrid Model 2')\n",
    "plt.plot(df.index, hybrid3_pred_test, color='blue', linewidth=1.5, alpha=0.3, label='Hybrid Model 3')\n",
    "plt.plot(df.index, hybrid4_pred_test, color='orange', linewidth=1.5, label='Hybrid Model 4')\n",
    "plt.plot(df.index, hybrid5_pred_test, color='purple', linewidth=1.5, label='Hybrid Model 5')\n",
    "plt.plot(df.index, hybrid6_pred_test, color='pink', linewidth=1.5, alpha=0.3, label='Hybrid Model 6')\n",
    "plt.plot(df.index, hybrid7_pred_test, color='purple', linewidth=1.5, label='Hybrid Model 7')\n",
    "plt.plot(df.index, hybrid8_pred_test, color='cyan', linewidth=1.5, alpha=0.2, label='Hybrid Model 8')\n",
    "plt.plot(df.index, hybrid9_pred_test, color='#00FFFF', linewidth=2, alpha=0.1, label='Hybrid Model 9')\n",
    "plt.plot(df.index, hybrid10_pred_test, color='#00FFFF', linewidth=2, alpha=0.1, label='Hybrid Model 10')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Predicted testues (Training)')\n",
    "plt.title('10 Hybrid Models: Actual vs. Predicted (Training)')\n",
    "plt.grid(False)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fe2bf4",
   "metadata": {},
   "source": [
    "# Density Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac55a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming df is your DataFrame with the time series data\n",
    "# Convert the 'Date' column to a datetime object\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Set the 'Date' column as the index\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plotting density plots for each hybrid model\n",
    "sns.kdeplot(y_val, color='red', label='Hybrid Model 1')\n",
    "sns.kdeplot(hybrid1_pred_val, color='red', label='Hybrid Model 1')\n",
    "sns.kdeplot(hybrid2_pred_val, color='green', label='Hybrid Model 2')\n",
    "sns.kdeplot(hybrid3_pred_val, color='blue', label='Hybrid Model 3')\n",
    "sns.kdeplot(hybrid4_pred_val, color='orange', label='Hybrid Model 4')\n",
    "sns.kdeplot(hybrid5_pred_val, color='purple', label='Hybrid Model 5')\n",
    "sns.kdeplot(hybrid6_pred_val, color='pink', label='Hybrid Model 6')\n",
    "sns.kdeplot(hybrid7_pred_val, color='purple', label='Hybrid Model 7')\n",
    "sns.kdeplot(hybrid8_pred_val, color='cyan', label='Hybrid Model 8')\n",
    "sns.kdeplot(hybrid9_pred_val, color='#00FFFF', label='Hybrid Model 9')\n",
    "sns.kdeplot(hybrid10_pred_val, color='#00FFFF', label='Hybrid Model 10')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Density Plot of Hybrid Models')\n",
    "plt.grid(False)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1116a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming df is your DataFrame with the time series data\n",
    "# Convert the 'Date' column to a datetime object\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Set the 'Date' column as the index\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plotting density plots for each hybrid model\n",
    "sns.kdeplot(y_test, color='red', label='Hybrid Model 1')\n",
    "sns.kdeplot(hybrid1_pred_test, color='red', label='Hybrid Model 1')\n",
    "sns.kdeplot(hybrid2_pred_test, color='green', label='Hybrid Model 2')\n",
    "sns.kdeplot(hybrid3_pred_test, color='blue', label='Hybrid Model 3')\n",
    "sns.kdeplot(hybrid4_pred_test, color='orange', label='Hybrid Model 4')\n",
    "sns.kdeplot(hybrid5_pred_test, color='purple', label='Hybrid Model 5')\n",
    "sns.kdeplot(hybrid6_pred_test, color='pink', label='Hybrid Model 6')\n",
    "sns.kdeplot(hybrid7_pred_test, color='purple', label='Hybrid Model 7')\n",
    "sns.kdeplot(hybrid8_pred_test, color='cyan', label='Hybrid Model 8')\n",
    "sns.kdeplot(hybrid9_pred_test, color='#00FFFF', label='Hybrid Model 9')\n",
    "sns.kdeplot(hybrid10_pred_test, color='#00FFFF', label='Hybrid Model 10')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('testues')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Density Plot of Hybrid Models')\n",
    "plt.grid(False)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72fa85a",
   "metadata": {},
   "source": [
    "## Residual Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca1e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate residuals for Hybrid Model 1\n",
    "residuals_hybrid1 = y_val - hybrid1_pred_val\n",
    "\n",
    "# Create Residual Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(hybrid1_pred_val, residuals_hybrid1, color='blue')\n",
    "plt.title('Hybrid Model 1 Residual Plot')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddf0ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate residuals for Hybrid Model 1\n",
    "residuals_hybrid1 = y_test - hybrid1_pred_test\n",
    "\n",
    "# Create Residual Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(hybrid1_pred_test, residuals_hybrid1, color='blue')\n",
    "plt.title('Hybrid Model 1 Residual Plot')\n",
    "plt.xlabel('Predicted testues')\n",
    "plt.ylabel('Residuals')\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69807ded",
   "metadata": {},
   "source": [
    "# Densty plot /error distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de7123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Create Density Plot of Residuals for Hybrid Model 1\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(residuals_hybrid1, kde=True, color='blue')\n",
    "plt.title('Density Plot of Residuals (Hybrid Model 1)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629a2f38",
   "metadata": {},
   "source": [
    "# QQ Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2368aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Create QQ Plot for Hybrid Model 1\n",
    "plt.figure(figsize=(8, 6))\n",
    "sm.qqplot(residuals_hybrid1, line='45', fit=True, color='blue')\n",
    "plt.title('QQ Plot (Hybrid Model 1)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
