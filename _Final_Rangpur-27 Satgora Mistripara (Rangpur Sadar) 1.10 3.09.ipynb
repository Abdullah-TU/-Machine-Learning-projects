{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e33f537",
   "metadata": {},
   "source": [
    "**Features (Independent Variables):**\n",
    "- Dates\n",
    "- Fature_1_Target_1\n",
    "- Fature_2_Target_1\n",
    "- Fature_3_Target_1\n",
    "- Common_Feature_1\n",
    "- Common_Feature_2\n",
    "- Common_Feature_3\n",
    "- Common_Feature_4\n",
    "\n",
    "**Targets (dependent Variables):**\n",
    "- Rangpur-27\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70960dbd",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6d594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from scipy import stats\n",
    "from tbats import TBATS\n",
    "import matplotlib.pyplot as plt\n",
    "from skopt import BayesSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from keras.models import Sequential\n",
    "from skopt.space import Integer, Real\n",
    "from sklearn.decomposition import PCA\n",
    "from catboost import CatBoostRegressor\n",
    "from keras.layers import LSTM, GRU, Dense\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from statsmodels.nonparametric.kernel_regression import KernelReg\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, WhiteKernel\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, explained_variance_score\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='xgboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8809d4",
   "metadata": {},
   "source": [
    "### Loading dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51831ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'D:\\Jupyter\\Ground water level prediction(Towfiq Sir)\\GWP\\final_data_updated.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf276e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1878bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98adc96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b1a0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Rangpur-27\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c6b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_convert = df.columns.difference(['Date'])\n",
    "df[cols_to_convert] = df[cols_to_convert].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef97c80d",
   "metadata": {},
   "source": [
    "# 2. Data Exploration and Analysis\n",
    "## Visualizing the distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867deb26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_distribution(df, columns):\n",
    "    for column in columns:\n",
    "        if column != 'Date':  \n",
    "            sns.histplot(df[column], kde=True)\n",
    "            plt.title(f\"Distribution of {column}\")\n",
    "            plt.xlabel(column)  \n",
    "            plt.ylabel(\"Frequency\")  \n",
    "            plt.show()\n",
    "\n",
    "\n",
    "numerical_cols = df.columns[1:]  \n",
    "\n",
    "plot_distribution(df, numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48102a6",
   "metadata": {},
   "source": [
    "## Data Cleaning,Checking errors, Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2d4b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataFrame_Checker import DataFrameChecker\n",
    "\n",
    "#  an instance of DataFrameChecker\n",
    "checker = DataFrameChecker(df)\n",
    "\n",
    "# Called the checking functions\n",
    "checker.check_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f821ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "checker.check_missing_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87955a16",
   "metadata": {},
   "source": [
    "## Outlier detection(Normality test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d8c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(data, threshold=1.5):\n",
    "    outliers = None\n",
    "    total_outliers = 0\n",
    "    \n",
    "    if pd.api.types.is_numeric_dtype(data):\n",
    "        alpha = 0.05\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            stat, p = stats.shapiro(data.dropna())\n",
    "\n",
    "        if p > alpha:\n",
    "            # Normal distribution, using Z-score method (Shapiro-Wilk test)\n",
    "            z_scores = np.abs(stats.zscore(data))\n",
    "            column_outliers = data[z_scores > threshold]\n",
    "        else:\n",
    "            # Non-normal distribution, use Tukey's method\n",
    "            q1 = np.percentile(data, 25)\n",
    "            q3 = np.percentile(data, 75)\n",
    "            iqr = q3 - q1\n",
    "            lower_bound = q1 - threshold * iqr\n",
    "            upper_bound = q3 + threshold * iqr\n",
    "            column_outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "        \n",
    "        if column_outliers is not None:\n",
    "            outliers = column_outliers\n",
    "            total_outliers += len(column_outliers)\n",
    "    \n",
    "    return outliers, total_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9155c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_outliers(outliers):\n",
    "    if outliers is not None:\n",
    "        num_outliers = len(outliers.columns)\n",
    "        num_rows = (num_outliers + 2) // 3  # Calculate the number of rows needed\n",
    "        \n",
    "        fig, axs = plt.subplots(num_rows, 3, figsize=(15, 5*num_rows))\n",
    "        axs = axs.flatten()  # Flatten the axis array to iterate over it\n",
    "        \n",
    "        for i, column in enumerate(outliers.columns):\n",
    "            ax = axs[i]\n",
    "            ax.boxplot(outliers[column].values, showfliers=False)\n",
    "            ax.scatter(range(1, len(outliers)+1), outliers[column].values, color='red', marker='o', label='Outliers')\n",
    "            ax.set_xlabel('Columns')\n",
    "            ax.set_ylabel('Values')\n",
    "            ax.set_title(f'Outliers - {column}')\n",
    "            ax.legend()\n",
    "        \n",
    "        # Remove any unused subplots\n",
    "        for j in range(num_outliers, len(axs)):\n",
    "            fig.delaxes(axs[j])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('No outliers detected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa806c75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Detect outliers for all numeric columns\n",
    "all_outliers = pd.DataFrame()\n",
    "total_outliers = 0\n",
    "numeric_columns = df.select_dtypes(include=np.number).columns\n",
    "for column in numeric_columns:\n",
    "    column_data = df[column]\n",
    "    column_outliers, column_total_outliers = detect_outliers(column_data)\n",
    "    if column_outliers is not None:\n",
    "        all_outliers[column] = column_outliers\n",
    "        total_outliers += column_total_outliers\n",
    "\n",
    "# Visualize outliers with a maximum of 3 graphs in a row\n",
    "visualize_outliers(all_outliers)\n",
    "\n",
    "# the number of total outliers in all columns\n",
    "print(\"Number of total outliers:\", total_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33d0527",
   "metadata": {},
   "source": [
    "## Data Splitting for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76beffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Rangpur-27', 'Date'])\n",
    "y = df['Rangpur-27']\n",
    "\n",
    "# Split data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7dff29",
   "metadata": {},
   "source": [
    "# Split viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c56393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Convert 'Date' column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d.%m.%Y')\n",
    "\n",
    "# Sort DataFrame by 'Date'\n",
    "df = df.sort_values(by='Date')\n",
    "\n",
    "# Split data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create a time series plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the entire dataset\n",
    "plt.plot(df['Date'], df['Rangpur-27'], color='violet', label='Full Data')\n",
    "\n",
    "# Plot training data\n",
    "plt.plot(df['Date'][:len(X_train)], df['Rangpur-27'][:len(X_train)], color='green', label='Training Set')\n",
    "\n",
    "# Plot validation data\n",
    "plt.plot(df['Date'][len(X_train):len(X_train) + len(X_val)], df['Rangpur-27'][len(X_train):len(X_train) + len(X_val)], color='orange', label='Validation Set')\n",
    "\n",
    "# Plot test data\n",
    "plt.plot(df['Date'][len(X_train) + len(X_val):], df['Rangpur-27'][len(X_train) + len(X_val):], color='red', label='Test Set')\n",
    "\n",
    "# Add vertical lines\n",
    "plt.axvline(df['Date'][len(X_train)], color='black', linestyle='--')\n",
    "plt.axvline(df['Date'][len(X_train) + len(X_val)], color='black', linestyle='--')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('GWL(m)')\n",
    "plt.title('Time Series Plot of Rangpur-27')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Set the date tick frequency to display every year\n",
    "plt.gca().xaxis.set_major_locator(mdates.YearLocator())\n",
    "\n",
    "# Set the x-axis limits to show data from the first date to the last date\n",
    "plt.xlim(df['Date'].min(), df['Date'].max())\n",
    "plt.xticks(rotation=90) \n",
    "plt.grid(False)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ed02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0663bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a34f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e8676",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4743c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    " y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f04a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c265eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eb2255",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d214719",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be2a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e75dc0b",
   "metadata": {},
   "source": [
    "### Data Split Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cf6804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the data points in each set\n",
    "train_indices = X_train.index\n",
    "val_indices = X_val.index\n",
    "test_indices = X_test.index\n",
    "\n",
    "# Check if there's any overlap between the sets\n",
    "assert len(set(train_indices).intersection(val_indices)) == 0, \"Overlap between training and validation sets!\"\n",
    "assert len(set(train_indices).intersection(test_indices)) == 0, \"Overlap between training and test sets!\"\n",
    "assert len(set(val_indices).intersection(test_indices)) == 0, \"Overlap between validation and test sets!\"\n",
    "\n",
    "# If the code reaches this point, it means there is no overlap\n",
    "print(\"No overlap detected. Data splitting is correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb2aa55",
   "metadata": {},
   "source": [
    "# Descriptive Statistics(Training,Validation and Testing stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df018fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set Descriptive Statistics\n",
    "train_stats = X_train.describe()\n",
    "print(\"Training Set Descriptive Statistics:\")\n",
    "train_stats.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944f1d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Set Descriptive Statistics\n",
    "val_stats = X_val.describe()\n",
    "print(\"\\nValidation Set Descriptive Statistics:\")\n",
    "val_stats.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4543022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Set Descriptive Statistics\n",
    "test_stats = X_test.describe()\n",
    "print(\"\\nTesting Set Descriptive Statistics:\")\n",
    "test_stats.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe45718c",
   "metadata": {},
   "source": [
    "# Multicollinearity statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e1d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Assuming df contains all your conditioning variables (including the target variable)\n",
    "# df = ...\n",
    "\n",
    "# Select only the numerical columns (excluding the date column and Rangpur-27)\n",
    "numeric_df = df.iloc[:, 2:-1]  # Assuming Rangpur-27 is the last column\n",
    "\n",
    "# Calculate VIF for each variable\n",
    "vif_data = numeric_df.copy()\n",
    "vif_data['Intercept'] = 1  # Add a constant term for the intercept\n",
    "\n",
    "# Calculate VIF values\n",
    "vif_values = pd.Series([variance_inflation_factor(vif_data.values, i) \n",
    "                        for i in range(vif_data.shape[1])], \n",
    "                       index=vif_data.columns)\n",
    "\n",
    "# Calculate Tolerance from VIF\n",
    "tolerance_values = 1 / vif_values\n",
    "\n",
    "# Display the results\n",
    "print(\"VIF Values:\")\n",
    "print(vif_values)\n",
    "\n",
    "print(\"\\nTolerance Values:\")\n",
    "print(tolerance_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c482a8",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f086d309",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Ridge': Ridge(),\n",
    "    'K-Nearest Neighbors': KNeighborsRegressor(),\n",
    "    'Gaussian Process': GaussianProcessRegressor(),\n",
    "    'Gaussian Process Regressor': GaussianProcessRegressor(random_state=42),\n",
    "    'Weighted K-Nearest Neighbors': KNeighborsRegressor(weights='distance'),\n",
    "    'LightGBM': LGBMRegressor(random_state=42),\n",
    "    'CatBoost': CatBoostRegressor(random_state=42, verbose=0),\n",
    "    'XGBoost': XGBRegressor(),\n",
    "    'LGBM Regressor': lgb.LGBMRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'AdaBoost': AdaBoostRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the training set\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics for the training set\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    train_rae = mean_absolute_percentage_error(y_train, y_pred_train)\n",
    "    train_rrse = np.sqrt(np.sum((y_train - y_pred_train)**2) / np.sum((y_train - np.mean(y_train))**2))\n",
    "    train_cc = np.corrcoef(y_train, y_pred_train)[0, 1]\n",
    "\n",
    "    # Calculate metrics for the validation set\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "    val_mae = mean_absolute_error(y_val, y_pred_val)\n",
    "    val_r2 = r2_score(y_val, y_pred_val)\n",
    "    val_rae = mean_absolute_percentage_error(y_val, y_pred_val)\n",
    "    val_rrse = np.sqrt(np.sum((y_val - y_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "    val_cc = np.corrcoef(y_val, y_pred_val)[0, 1]\n",
    "    \n",
    "    # Calculate metrics for the test set\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    test_rae = mean_absolute_percentage_error(y_test, y_pred_test)\n",
    "    test_rrse = np.sqrt(np.sum((y_test - y_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "    test_cc = np.corrcoef(y_test, y_pred_test)[0, 1]\n",
    "\n",
    "    results[name] = {\n",
    "        'Train RMSE': train_rmse,\n",
    "        'Train MAE': train_mae,\n",
    "        'Train R-squared': train_r2,\n",
    "        'Train RAE': train_rae,\n",
    "        'Train RRSE': train_rrse,\n",
    "        'Train CC': train_cc,        \n",
    "        'Validation RMSE': val_rmse,\n",
    "        'Validation MAE': val_mae,\n",
    "        'Validation R-squared': val_r2,\n",
    "        'Validation RAE': val_rae,\n",
    "        'Validation RRSE': val_rrse,\n",
    "        'Validation CC': val_cc,\n",
    "        'Test RMSE': test_rmse,\n",
    "        'Test MAE': test_mae,\n",
    "        'Test R-squared': test_r2,\n",
    "        'Test RAE': test_rae,\n",
    "        'Test RRSE': test_rrse,\n",
    "        'Test CC': test_cc\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "for model, metrics in results.items():\n",
    "    print(f\"Metrics for {model}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.3f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86e6a25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Ridge': Ridge(),\n",
    "    'K-Nearest Neighbors': KNeighborsRegressor(),\n",
    "    'Gaussian Process': GaussianProcessRegressor(),\n",
    "    'Gaussian Process Regressor': GaussianProcessRegressor(random_state=42),\n",
    "    'Weighted K-Nearest Neighbors': KNeighborsRegressor(weights='distance'),\n",
    "    'LightGBM': LGBMRegressor(random_state=42),\n",
    "    'CatBoost': CatBoostRegressor(random_state=42, verbose=0),\n",
    "    'XGBoost': XGBRegressor(),\n",
    "    'LGBM Regressor': lgb.LGBMRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'AdaBoost': AdaBoostRegressor(random_state=42),\n",
    "    'Locally Weighted Linear Regression': KNeighborsRegressor(n_neighbors=5, weights='distance')\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the training set\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics for the training set\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    train_rae = mean_absolute_percentage_error(y_train, y_pred_train)\n",
    "    train_rrse = np.sqrt(np.sum((y_train - y_pred_train)**2) / np.sum((y_train - np.mean(y_train))**2))\n",
    "    train_cc = np.corrcoef(y_train, y_pred_train)[0, 1]\n",
    "\n",
    "    # Calculate metrics for the validation set\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "    val_mae = mean_absolute_error(y_val, y_pred_val)\n",
    "    val_r2 = r2_score(y_val, y_pred_val)\n",
    "    val_rae = mean_absolute_percentage_error(y_val, y_pred_val)\n",
    "    val_rrse = np.sqrt(np.sum((y_val - y_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "    val_cc = np.corrcoef(y_val, y_pred_val)[0, 1]\n",
    "    \n",
    "    # Calculate metrics for the test set\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    test_rae = mean_absolute_percentage_error(y_test, y_pred_test)\n",
    "    test_rrse = np.sqrt(np.sum((y_test - y_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "    test_cc = np.corrcoef(y_test, y_pred_test)[0, 1]\n",
    "\n",
    "    results[name] = {\n",
    "        'Train RMSE': train_rmse,\n",
    "        'Train MAE': train_mae,\n",
    "        'Train R-squared': train_r2,\n",
    "        'Train RAE': train_rae,\n",
    "        'Train RRSE': train_rrse,\n",
    "        'Train CC': train_cc,        \n",
    "        'Validation RMSE': val_rmse,\n",
    "        'Validation MAE': val_mae,\n",
    "        'Validation R-squared': val_r2,\n",
    "        'Validation RAE': val_rae,\n",
    "        'Validation RRSE': val_rrse,\n",
    "        'Validation CC': val_cc,\n",
    "        'Test RMSE': test_rmse,\n",
    "        'Test MAE': test_mae,\n",
    "        'Test R-squared': test_r2,\n",
    "        'Test RAE': test_rae,\n",
    "        'Test RRSE': test_rrse,\n",
    "        'Test CC': test_cc\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "for model, metrics in results.items():\n",
    "    print(f\"Metrics for {model}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2275b610",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f369eeb",
   "metadata": {},
   "source": [
    "## 1. Random Forest Regressor HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db09e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Forest model\n",
    "random_forest = RandomForestRegressor()\n",
    "\n",
    "# the hyperparameters and their possible values for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],  \n",
    "    'max_depth': [None, 5, 10],    \n",
    "    'min_samples_split': [2, 5, 10] \n",
    "}\n",
    "\n",
    "# Initialize Grid Search for Random Forest\n",
    "grid_search_rf = GridSearchCV(random_forest, param_grid_rf, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Perform Grid Search for Random Forest\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for Random Forest\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "\n",
    "# Predict on validation set using Random Forest\n",
    "rf_pred_val = best_rf.predict(X_val)\n",
    "\n",
    "# Calculate metrics for Random Forest on validation set\n",
    "rf_rmse_val = np.sqrt(mean_squared_error(y_val, rf_pred_val))\n",
    "rf_mae_val = mean_absolute_error(y_val, rf_pred_val)\n",
    "rf_r2_val = r2_score(y_val, rf_pred_val)\n",
    "rf_rae_val = mean_absolute_percentage_error(y_val, rf_pred_val)\n",
    "rf_rrse_val = np.sqrt(np.sum((y_val - rf_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "rf_cc_val = np.corrcoef(y_val, rf_pred_val)[0, 1]\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for Random Forest on validation set\n",
    "print(\"Best Hyperparameters for Random Forest:\", best_params_rf)\n",
    "print(\"Random Forest RMSE (Validation):\", rf_rmse_val)\n",
    "print(\"Random Forest MAE (Validation):\", rf_mae_val)\n",
    "print(\"Random Forest R-squared (Validation):\", rf_r2_val)\n",
    "print(\"Random Forest RAE (Validation):\", rf_rae_val)\n",
    "print(\"Random Forest RRSE (Validation):\", rf_rrse_val)\n",
    "print(\"Random Forest CC (Validation):\", rf_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e877720",
   "metadata": {},
   "source": [
    "## 2. LWLR HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dbcb3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the range of neighbors to consider\n",
    "param_grid_lwlr = {\n",
    "    'n_neighbors': [3, 5, 7],  # You can adjust these values\n",
    "    'weights': ['uniform', 'distance']  # You can adjust these values\n",
    "}\n",
    "\n",
    "# Initialize LWLR model\n",
    "lwlr = KNeighborsRegressor()\n",
    "\n",
    "# Initialize Grid Search for LWLR\n",
    "grid_search_lwlr = GridSearchCV(lwlr, param_grid_lwlr, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Perform Grid Search for LWLR\n",
    "grid_search_lwlr.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for LWLR\n",
    "best_lwlr = grid_search_lwlr.best_estimator_\n",
    "best_params_lwlr = grid_search_lwlr.best_params_\n",
    "\n",
    "# Predict on validation set using LWLR\n",
    "lwlr_pred_val = best_lwlr.predict(X_val)\n",
    "\n",
    "# Calculate metrics for LWLR on validation set\n",
    "lwlr_rmse_val = np.sqrt(mean_squared_error(y_val, lwlr_pred_val))\n",
    "lwlr_mae_val = mean_absolute_error(y_val, lwlr_pred_val)\n",
    "lwlr_r2_val = r2_score(y_val, lwlr_pred_val)\n",
    "lwlr_rae_val = mean_absolute_percentage_error(y_val, lwlr_pred_val)\n",
    "lwlr_rrse_val = np.sqrt(np.sum((y_val - lwlr_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "lwlr_cc_val = np.corrcoef(y_val, lwlr_pred_val)[0, 1]\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for LWLR on validation set\n",
    "print(\"Best Hyperparameters for LWLR:\", best_params_lwlr)\n",
    "print(\"LWLR RMSE (Validation):\", lwlr_rmse_val)\n",
    "print(\"LWLR MAE (Validation):\", lwlr_mae_val)\n",
    "print(\"LWLR R-squared (Validation):\", lwlr_r2_val)\n",
    "print(\"LWLR RAE (Validation):\", lwlr_rae_val)\n",
    "print(\"LWLR RRSE (Validation):\", lwlr_rrse_val)\n",
    "print(\"LWLR CC (Validation):\", lwlr_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018efbc0",
   "metadata": {},
   "source": [
    "## 3. Gaussian Process Regression HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1961f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the hyperparameters and their possible values for Gaussian Process Regression\n",
    "param_grid_gpr = {\n",
    "    'kernel': [None, 1.0 * RBF(length_scale=1.0), Matern(length_scale=1.0, nu=1.5), WhiteKernel(noise_level=1.0)],   \n",
    "  \n",
    "}\n",
    "\n",
    "# Initialize Grid Search for Gaussian Process Regression\n",
    "grid_search_gpr = GridSearchCV(GaussianProcessRegressor(), param_grid_gpr, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search_gpr.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for Gaussian Process Regression\n",
    "best_gpr = grid_search_gpr.best_estimator_\n",
    "best_params_gpr = grid_search_gpr.best_params_\n",
    "\n",
    "# Predict on validation set using Gaussian Process Regression\n",
    "gpr_pred_val = best_gpr.predict(X_val)\n",
    "\n",
    "# Calculate metrics for Gaussian Process Regression on validation set\n",
    "gpr_rmse_val = np.sqrt(mean_squared_error(y_val, gpr_pred_val))\n",
    "gpr_mae_val = mean_absolute_error(y_val, gpr_pred_val)\n",
    "gpr_r2_val = r2_score(y_val, gpr_pred_val)\n",
    "gpr_rae_val = mean_absolute_percentage_error(y_val, gpr_pred_val)\n",
    "gpr_rrse_val = np.sqrt(np.sum((y_val - gpr_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "gpr_cc_val = np.corrcoef(y_val, gpr_pred_val)[0, 1]\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for Gaussian Process Regression on validation set\n",
    "print(\"Best Hyperparameters for Gaussian Process Regression:\", best_params_gpr)\n",
    "print(\"Gaussian Process RMSE (Validation):\", gpr_rmse_val)\n",
    "print(\"Gaussian Process MAE (Validation):\", gpr_mae_val)\n",
    "print(\"Gaussian Process R-squared (Validation):\", gpr_r2_val)\n",
    "print(\"Gaussian Process RAE (Validation):\", gpr_rae_val)\n",
    "print(\"Gaussian Process RRSE (Validation):\", gpr_rrse_val)\n",
    "print(\"Gaussian Process CC (Validation):\", gpr_cc_val)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4635a20",
   "metadata": {},
   "source": [
    "## 4. Weighted K-Nearest Neighbors HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064e8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the hyperparameters and their possible values for Weighted K-Nearest Neighbors\n",
    "param_grid_wknn = {\n",
    "     'n_neighbors': [3, 5, 7, 9, 11],  \n",
    "    'weights': ['uniform', 'distance'],  \n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  \n",
    "    'leaf_size': [10, 30, 50], \n",
    "    'p': [1, 2],\n",
    "    'metric': ['euclidean', 'manhattan']  \n",
    "}\n",
    "\n",
    "# Initialize Grid Search for Weighted K-Nearest Neighbors\n",
    "grid_search_wknn = GridSearchCV(KNeighborsRegressor(), param_grid_wknn, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search_wknn.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for Weighted K-Nearest Neighbors\n",
    "best_wknn = grid_search_wknn.best_estimator_\n",
    "best_params_wknn = grid_search_wknn.best_params_\n",
    "\n",
    "# Predict on validation set using Weighted K-Nearest Neighbors\n",
    "wknn_pred_val = best_wknn.predict(X_val)\n",
    "\n",
    "# Calculate metrics for Weighted K-Nearest Neighbors on validation set\n",
    "wknn_rmse_val = np.sqrt(mean_squared_error(y_val, wknn_pred_val))\n",
    "wknn_mae_val = mean_absolute_error(y_val, wknn_pred_val)\n",
    "wknn_r2_val = r2_score(y_val, wknn_pred_val)\n",
    "wknn_rae_val = mean_absolute_percentage_error(y_val, wknn_pred_val)\n",
    "wknn_rrse_val = np.sqrt(np.sum((y_val - wknn_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "wknn_cc_val = np.corrcoef(y_val, wknn_pred_val)[0, 1]\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for Weighted K-Nearest Neighbors on validation set\n",
    "print(\"Best Hyperparameters for Weighted K-Nearest Neighbors:\", best_params_wknn)\n",
    "print(\"Weighted K-NN RMSE (Validation):\", wknn_rmse_val)\n",
    "print(\"Weighted K-NN MAE (Validation):\", wknn_mae_val)\n",
    "print(\"Weighted K-NN R-squared (Validation):\", wknn_r2_val)\n",
    "print(\"Weighted K-NN RAE (Validation):\", wknn_rae_val)\n",
    "print(\"Weighted K-NN RRSE (Validation):\", wknn_rrse_val)\n",
    "print(\"Weighted K-NN CC (Validation):\", wknn_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7121d198",
   "metadata": {},
   "source": [
    "## 5. K-Nearest Neighbors HPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9942d0aa",
   "metadata": {},
   "source": [
    "### The KNeighborsRegressor (KNN) model doesn't have traditional hyperparameters like other models (e.g., Random Forest).However, I performed hyperparameter tuning for the Locally Weighted Linear Regression (LWLR) using Grid Search with a specified range of neighbors and weight options, ultimately finding the best hyperparameters and model for LWLR, and evaluating its performance on the validation set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cfb6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the range of neighbors and weights to consider\n",
    "param_grid = {\n",
    "     'n_neighbors': [3, 5, 7, 9, 11],  \n",
    "    'weights': ['uniform', 'distance'],  \n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  \n",
    "    'leaf_size': [10, 30, 50], \n",
    "    'p': [1, 2],  \n",
    "    'metric': ['euclidean', 'manhattan'] \n",
    "}\n",
    "\n",
    "# Initialize KNN model\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train the KNN model with the best hyperparameters\n",
    "best_knn = KNeighborsRegressor(n_neighbors=best_params['n_neighbors'], weights=best_params['weights'])\n",
    "best_knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "knn_pred = best_knn.predict(X_val)\n",
    "\n",
    "# Calculate metrics for KNN\n",
    "knn_rmse = np.sqrt(mean_squared_error(y_val, knn_pred))\n",
    "knn_mae = mean_absolute_error(y_val, knn_pred)\n",
    "knn_r2 = r2_score(y_val, knn_pred)\n",
    "knn_rae = mean_absolute_percentage_error(y_val, knn_pred)\n",
    "knn_rrse = np.sqrt(np.sum((y_val - knn_pred)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "knn_cc = np.corrcoef(y_val, knn_pred)[0, 1]\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for KNN\n",
    "print(\"Best Hyperparameters for KNN:\", best_params)\n",
    "print(\"KNN RMSE:\", knn_rmse)\n",
    "print(\"KNN MAE:\", knn_mae)\n",
    "print(\"KNN R-squared:\", knn_r2)\n",
    "print(\"KNN RAE:\", knn_rae)\n",
    "print(\"KNN RRSE:\", knn_rrse)\n",
    "print(\"KNN CC:\", knn_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c090340a",
   "metadata": {},
   "source": [
    "## 6. XGBoost Regressor HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a527588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for hyperparameters\n",
    "param_dist = {\n",
    "    'n_estimators': Integer(100, 300),\n",
    "    'max_depth': Integer(3, 5),\n",
    "    'learning_rate': Real(0.01, 0.2, prior='uniform'),\n",
    "    'gamma': Real(0, 0.2, prior='uniform')\n",
    "}\n",
    "\n",
    "# Initialize Bayesian Optimization for XGBoost Regressor\n",
    "bayes_search_xgb = BayesSearchCV(\n",
    "    XGBRegressor(),\n",
    "    param_dist,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_iter=10, \n",
    "    random_state=42,  \n",
    "    n_jobs=-1,  \n",
    "    verbose=1, \n",
    "    n_points=5, \n",
    "    refit=True  \n",
    ")\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "bayes_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for XGBoost Regressor\n",
    "best_xgb = bayes_search_xgb.best_estimator_\n",
    "best_params_xgb = bayes_search_xgb.best_params_\n",
    "\n",
    "# Predict on validation set using XGBoost Regressor\n",
    "xgb_pred_val = best_xgb.predict(X_val)\n",
    "\n",
    "# Calculate metrics for XGBoost Regressor on validation set\n",
    "xgb_rmse_val = np.sqrt(mean_squared_error(y_val, xgb_pred_val))\n",
    "xgb_mae_val = mean_absolute_error(y_val, xgb_pred_val)\n",
    "xgb_r2_val = r2_score(y_val, xgb_pred_val)\n",
    "xgb_rae_val = mean_absolute_percentage_error(y_val, xgb_pred_val)\n",
    "xgb_rrse_val = np.sqrt(np.sum((y_val - xgb_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "xgb_cc_val = np.corrcoef(y_val, xgb_pred_val)[0, 1]\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for XGBoost Regressor on validation set\n",
    "print(\"Best Hyperparameters for XGBoost Regressor:\", best_params_xgb)\n",
    "print(\"XGBoost RMSE (Validation):\", xgb_rmse_val)\n",
    "print(\"XGBoost MAE (Validation):\", xgb_mae_val)\n",
    "print(\"XGBoost R-squared (Validation):\", xgb_r2_val)\n",
    "print(\"XGBoost RAE (Validation):\", xgb_rae_val)\n",
    "print(\"XGBoost RRSE (Validation):\", xgb_rrse_val)\n",
    "print(\"XGBoost CC (Validation):\", xgb_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df8bac0",
   "metadata": {},
   "source": [
    "## 7. CatBoost Regressor  HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430d21f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the search space for hyperparameters\n",
    "param_dist = {\n",
    "    'iterations': Integer(100, 300),\n",
    "    'depth': Integer(4, 8),\n",
    "    'learning_rate': Real(0.01, 0.2, prior='uniform')\n",
    "}\n",
    "\n",
    "# Initialize Bayesian Optimization for CatBoost Regressor\n",
    "bayes_search_catboost = BayesSearchCV(\n",
    "    CatBoostRegressor(verbose=0),\n",
    "    param_dist,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_iter=10,\n",
    "    random_state=42,  \n",
    "    n_jobs=-1, \n",
    "    verbose=1,  \n",
    "    n_points=5,\n",
    "    refit=True  \n",
    ")\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "bayes_search_catboost.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for CatBoost Regressor\n",
    "best_catboost = bayes_search_catboost.best_estimator_\n",
    "best_params_catboost = bayes_search_catboost.best_params_\n",
    "\n",
    "# Predict on validation set using CatBoost Regressor\n",
    "catboost_pred_val = best_catboost.predict(X_val)\n",
    "\n",
    "# Calculate metrics for CatBoost Regressor on validation set\n",
    "catboost_rmse_val = np.sqrt(mean_squared_error(y_val, catboost_pred_val))\n",
    "catboost_mae_val = mean_absolute_error(y_val, catboost_pred_val)\n",
    "catboost_r2_val = r2_score(y_val, catboost_pred_val)\n",
    "catboost_rae_val = mean_absolute_percentage_error(y_val, catboost_pred_val)\n",
    "catboost_rrse_val = np.sqrt(np.sum((y_val - catboost_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "catboost_cc_val = np.corrcoef(y_val, catboost_pred_val)[0, 1]\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for CatBoost Regressor on validation set\n",
    "print(\"Best Hyperparameters for CatBoost Regressor:\", best_params_catboost)\n",
    "print(\"CatBoost RMSE (Validation):\", catboost_rmse_val)\n",
    "print(\"CatBoost MAE (Validation):\", catboost_mae_val)\n",
    "print(\"CatBoost R-squared (Validation):\", catboost_r2_val)\n",
    "print(\"CatBoost RAE (Validation):\", catboost_rae_val)\n",
    "print(\"CatBoost RRSE (Validation):\", catboost_rrse_val)\n",
    "print(\"CatBoost CC (Validation):\", catboost_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb836b",
   "metadata": {},
   "source": [
    "## 8. LightGBM Regressor HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c565915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for hyperparameters\n",
    "param_dist = {\n",
    "    'n_estimators': Integer(100, 300),\n",
    "    'max_depth': Integer(3, 5),\n",
    "    'learning_rate': Real(0.01, 0.2, prior='uniform')\n",
    "}\n",
    "\n",
    "# Initialize Bayesian Optimization for LightGBM Regressor\n",
    "bayes_search_lgb = BayesSearchCV(\n",
    "    LGBMRegressor(verbosity=-1), \n",
    "    param_dist,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_iter=10,  \n",
    "    random_state=42, \n",
    "    n_jobs=-1,  \n",
    "    verbose=1, \n",
    "    n_points=5,  \n",
    "    refit=True \n",
    ")\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "bayes_search_lgb.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for LightGBM Regressor\n",
    "best_lgb = bayes_search_lgb.best_estimator_\n",
    "best_params_lgb = bayes_search_lgb.best_params_\n",
    "\n",
    "# Predict on validation set using LightGBM Regressor\n",
    "lgb_pred_val = best_lgb.predict(X_val)\n",
    "\n",
    "# Calculate metrics for LightGBM Regressor on validation set\n",
    "lgb_rmse_val = np.sqrt(mean_squared_error(y_val, lgb_pred_val))\n",
    "lgb_mae_val = mean_absolute_error(y_val, lgb_pred_val)\n",
    "lgb_r2_val = r2_score(y_val, lgb_pred_val)\n",
    "lgb_rae_val = mean_absolute_percentage_error(y_val, lgb_pred_val)\n",
    "lgb_rrse_val = np.sqrt(np.sum((y_val - lgb_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "lgb_cc_val = np.corrcoef(y_val, lgb_pred_val)[0, 1]\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for LightGBM Regressor on validation set\n",
    "print(\"Best Hyperparameters for LightGBM Regressor:\", best_params_lgb)\n",
    "print(\"LightGBM RMSE (Validation):\", lgb_rmse_val)\n",
    "print(\"LightGBM MAE (Validation):\", lgb_mae_val)\n",
    "print(\"LightGBM R-squared (Validation):\", lgb_r2_val)\n",
    "print(\"LightGBM RAE (Validation):\", lgb_rae_val)\n",
    "print(\"LightGBM RRSE (Validation):\", lgb_rrse_val)\n",
    "print(\"LightGBM CC (Validation):\", lgb_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df17c84a",
   "metadata": {},
   "source": [
    "## 9. Gradient Boosting Regressor HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c67431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for hyperparameters\n",
    "param_dist = {\n",
    "    'n_estimators': Integer(100, 300),\n",
    "    'max_depth': Integer(3, 5),\n",
    "    'learning_rate': Real(0.01, 0.2, prior='uniform')\n",
    "}\n",
    "\n",
    "# Initialize Bayesian Optimization for Gradient Boosting Regressor\n",
    "bayes_search_gbr = BayesSearchCV(\n",
    "    GradientBoostingRegressor(random_state=42),  \n",
    "    param_dist,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_iter=10,  \n",
    "    random_state=42,\n",
    "    n_jobs=-1, \n",
    "    verbose=1, \n",
    "    n_points=5,  \n",
    "    refit=True  \n",
    ")\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "bayes_search_gbr.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model for Gradient Boosting Regressor\n",
    "best_gbr = bayes_search_gbr.best_estimator_\n",
    "best_params_gbr = bayes_search_gbr.best_params_\n",
    "\n",
    "# Predict on validation set using Gradient Boosting Regressor\n",
    "gbr_pred_val = best_gbr.predict(X_val)\n",
    "\n",
    "# Calculate metrics for Gradient Boosting Regressor on validation set\n",
    "gbr_rmse_val = np.sqrt(mean_squared_error(y_val, gbr_pred_val))\n",
    "gbr_mae_val = mean_absolute_error(y_val, gbr_pred_val)\n",
    "gbr_r2_val = r2_score(y_val, gbr_pred_val)\n",
    "gbr_rae_val = mean_absolute_percentage_error(y_val, gbr_pred_val)\n",
    "gbr_rrse_val = np.sqrt(np.sum((y_val - gbr_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "gbr_cc_val = np.corrcoef(y_val, gbr_pred_val)[0, 1]\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for Gradient Boosting Regressor on validation set\n",
    "print(\"Best Hyperparameters for Gradient Boosting Regressor:\", best_params_gbr)\n",
    "print(\"Gradient Boosting RMSE (Validation):\", gbr_rmse_val)\n",
    "print(\"Gradient Boosting MAE (Validation):\", gbr_mae_val)\n",
    "print(\"Gradient Boosting R-squared (Validation):\", gbr_r2_val)\n",
    "print(\"Gradient Boosting RAE (Validation):\", gbr_rae_val)\n",
    "print(\"Gradient Boosting RRSE (Validation):\", gbr_rrse_val)\n",
    "print(\"Gradient Boosting CC (Validation):\", gbr_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba6037e",
   "metadata": {},
   "source": [
    "## 10.Ridge Regression HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c45cbd3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameters and their possible values for Ridge Regression\n",
    "param_grid_ridge = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']} \n",
    "\n",
    "# Initialize Ridge model\n",
    "ridge = Ridge(max_iter=10000)\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search_ridge = GridSearchCV(ridge, param_grid_ridge, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Train the Grid Search\n",
    "grid_search_ridge.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and model for Ridge Regression\n",
    "best_ridge = grid_search_ridge.best_estimator_\n",
    "\n",
    "# Predict on validation set using Ridge Regression\n",
    "ridge_pred_val = best_ridge.predict(X_val)\n",
    "\n",
    "# Calculate metrics for Ridge Regression\n",
    "ridge_rmse_val = np.sqrt(mean_squared_error(y_val, ridge_pred_val))\n",
    "ridge_mae_val = mean_absolute_error(y_val, ridge_pred_val)\n",
    "ridge_r2_val = r2_score(y_val, ridge_pred_val)\n",
    "ridge_rae_val = mean_absolute_percentage_error(y_val, ridge_pred_val)\n",
    "ridge_rrse_val = np.sqrt(np.sum((y_val - ridge_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "ridge_cc_val = np.corrcoef(y_val, ridge_pred_val)[0, 1]\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics for Ridge Regression\n",
    "print(\"Best Hyperparameters for Ridge Regression:\", grid_search_ridge.best_params_)\n",
    "print(\"Ridge Regression RMSE (Validation):\", ridge_rmse_val)\n",
    "print(\"Ridge Regression MAE (Validation):\", ridge_mae_val)\n",
    "print(\"Ridge Regression R-squared (Validation):\", ridge_r2_val)\n",
    "print(\"Ridge Regression RAE (Validation):\", ridge_rae_val)\n",
    "print(\"Ridge Regression RRSE (Validation):\", ridge_rrse_val)\n",
    "print(\"Ridge Regression CC (Validation):\", ridge_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d42f73d",
   "metadata": {},
   "source": [
    "# Hybrid models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b24dd05",
   "metadata": {},
   "source": [
    "## Hybrid modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d8a5f5",
   "metadata": {},
   "source": [
    "## Hybrid model 1: Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9eb4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid1_pred_val = (rf_pred_val + lwlr_pred_val) / 2\n",
    "\n",
    "# Evaluate the performance of Hybrid Model 1\n",
    "hybrid1_rmse_val = np.sqrt(mean_squared_error(y_val, hybrid1_pred_val))\n",
    "hybrid1_mae_val = mean_absolute_error(y_val, hybrid1_pred_val)\n",
    "hybrid1_r2_val = r2_score(y_val, hybrid1_pred_val)\n",
    "hybrid1_rae_val = mean_absolute_percentage_error(y_val, hybrid1_pred_val)\n",
    "hybrid1_rrse_val = np.sqrt(np.sum((y_val - hybrid1_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "hybrid1_cc_val = np.corrcoef(y_val, hybrid1_pred_val)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) RMSE (Validation):\", hybrid1_rmse_val)\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) MAE (Validation):\", hybrid1_mae_val)\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) R-squared (Validation):\", hybrid1_r2_val)\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) RAE (Validation):\", hybrid1_rae_val)\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) RRSE (Validation):\", hybrid1_rrse_val)\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) CC (Validation):\", hybrid1_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a7d66",
   "metadata": {},
   "source": [
    "## Hybrid model 1: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d392139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set using Random Forest Regressor\n",
    "rf_pred_test = best_rf.predict(X_test)\n",
    "\n",
    "# Predict on the test set using Locally Weighted Linear Regression\n",
    "lwlr_pred_test = best_lwlr.predict(X_test)\n",
    "\n",
    "\n",
    "hybrid1_pred_test = (rf_pred_test + lwlr_pred_test) / 2\n",
    "\n",
    "# Calculate metrics for the hybrid model on test set\n",
    "hybrid1_rmse_test = np.sqrt(mean_squared_error(y_test, hybrid1_pred_test))\n",
    "hybrid1_mae_test = mean_absolute_error(y_test, hybrid1_pred_test)\n",
    "hybrid1_r2_test = r2_score(y_test, hybrid1_pred_test)\n",
    "hybrid1_rae_test = mean_absolute_percentage_error(y_test, hybrid1_pred_test)\n",
    "hybrid1_rrse_test = np.sqrt(np.sum((y_test - hybrid1_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "hybrid1_cc_test = np.corrcoef(y_test, hybrid1_pred_test)[0, 1]\n",
    "\n",
    "# Print evaluation metrics for Hybrid Model 1\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) RMSE (Test):\", hybrid1_rmse_test)\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) MAE (Test):\", hybrid1_mae_test)\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) R-squared (Test):\", hybrid1_r2_test)\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) RAE (Test):\", hybrid1_rae_test)\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) RRSE (Test):\", hybrid1_rrse_test)\n",
    "print(\"Hybrid Model 1 (Random Forest + LWLR) CC (Test):\", hybrid1_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4cf9a8",
   "metadata": {},
   "source": [
    "## Hybrid model 2: Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e024242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predictions for Hybrid Model 2 (GBR + CatBoost) on validation set\n",
    "hybrid2_pred_val = (best_lgb.predict(X_val) + best_catboost.predict(X_val)) / 2\n",
    "\n",
    "# Evaluate the performance of Hybrid Model 2\n",
    "hybrid2_rmse_val = np.sqrt(mean_squared_error(y_val, hybrid2_pred_val))\n",
    "hybrid2_mae_val = mean_absolute_error(y_val, hybrid2_pred_val)\n",
    "hybrid2_r2_val = r2_score(y_val, hybrid2_pred_val)\n",
    "hybrid2_rae_val = mean_absolute_percentage_error(y_val, hybrid2_pred_val)\n",
    "hybrid2_rrse_val = np.sqrt(np.sum((y_val - np.mean(y_val))**2) / np.sum((y_val - hybrid2_pred_val)**2))\n",
    "hybrid2_cc_val = np.corrcoef(y_val, hybrid2_pred_val)[0, 1]\n",
    "\n",
    "# Print evaluation metrics for Hybrid Model 2\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) RMSE (Validation):\", hybrid2_rmse_val)\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) MAE (Validation):\", hybrid2_mae_val)\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) R-squared (Validation):\", hybrid2_r2_val)\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) RAE (Validation):\", hybrid2_rae_val)\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) RRSE (Validation):\", hybrid2_rrse_val)\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) CC (Validation):\", hybrid2_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94876937",
   "metadata": {},
   "source": [
    "## Hybrid model 2: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd93872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set using Gradient Boosting Regressor\n",
    "gbr_pred_test = best_lgb.predict(X_test)\n",
    "\n",
    "# Predict on the test set using CatBoost Regressor\n",
    "catboost_pred_test = best_catboost.predict(X_test)\n",
    "\n",
    "\n",
    "hybrid2_pred_test = (gbr_pred_test + catboost_pred_test) / 2\n",
    "\n",
    "# Evaluate the performance of Hybrid Model 2 on the test set\n",
    "hybrid2_rmse_test = np.sqrt(mean_squared_error(y_test, hybrid2_pred_test))\n",
    "hybrid2_mae_test = mean_absolute_error(y_test, hybrid2_pred_test)\n",
    "hybrid2_r2_test = r2_score(y_test, hybrid2_pred_test)\n",
    "hybrid2_rae_test = mean_absolute_percentage_error(y_test, hybrid2_pred_test)\n",
    "hybrid2_rrse_test = np.sqrt(np.sum((y_test - hybrid2_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "hybrid2_cc_test = np.corrcoef(y_test, hybrid2_pred_test)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) RMSE (Test):\", hybrid2_rmse_test)\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) MAE (Test):\", hybrid2_mae_test)\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) R-squared (Test):\", hybrid2_r2_test)\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) RAE (Test):\", hybrid2_rae_test)\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) RRSE (Test):\", hybrid2_rrse_test)\n",
    "print(\"Hybrid Model 2 (GBR + CatBoost) CC (Test):\", hybrid2_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9947f938",
   "metadata": {},
   "source": [
    "## Hybrid model 3: Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c51be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid3_pred_val = (ridge_pred_val + lwlr_pred_val) / 2\n",
    "\n",
    "# Calculate metrics for the hybrid model on validation set\n",
    "hybrid3_rmse_val = np.sqrt(mean_squared_error(y_val, hybrid3_pred_val))\n",
    "hybrid3_mae_val = mean_absolute_error(y_val, hybrid3_pred_val)\n",
    "hybrid3_r2_val = r2_score(y_val, hybrid3_pred_val)\n",
    "hybrid3_rae_val = mean_absolute_percentage_error(y_val, hybrid3_pred_val)\n",
    "hybrid3_rrse_val = np.sqrt(np.sum((y_val - hybrid3_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "hybrid3_cc_val = np.corrcoef(y_val, hybrid3_pred_val)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) RMSE (Validation):\", hybrid3_rmse_val)\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) MAE (Validation):\", hybrid3_mae_val)\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) R-squared (Validation):\", hybrid3_r2_val)\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) RAE (Validation):\", hybrid3_rae_val)\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) RRSE (Validation):\", hybrid3_rrse_val)\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) CC (Validation):\", hybrid3_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a23a6",
   "metadata": {},
   "source": [
    "## Hybrid model 3: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857f346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set using Ridge Regression\n",
    "ridge_pred_test = best_ridge.predict(X_test)\n",
    "\n",
    "# Predict on the test set using Locally Weighted Linear Regression\n",
    "lwlr_pred_test = best_lwlr.predict(X_test)\n",
    "\n",
    "hybrid3_pred_test = (ridge_pred_test + lwlr_pred_test) / 2\n",
    "\n",
    "# Calculate metrics for the hybrid model 3 on test set\n",
    "hybrid3_rmse_test = np.sqrt(mean_squared_error(y_test, hybrid3_pred_test))\n",
    "hybrid3_mae_test = mean_absolute_error(y_test, hybrid3_pred_test)\n",
    "hybrid3_r2_test = r2_score(y_test, hybrid3_pred_test)\n",
    "hybrid3_rae_test = mean_absolute_percentage_error(y_test, hybrid3_pred_test)\n",
    "hybrid3_rrse_test = np.sqrt(np.sum((y_test - hybrid3_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "hybrid3_cc_test = np.corrcoef(y_test, hybrid3_pred_test)[0, 1]\n",
    "\n",
    "# Print evaluation metrics for Hybrid Model 3\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) RMSE (Test):\", hybrid3_rmse_test)\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) MAE (Test):\", hybrid3_mae_test)\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) R-squared (Test):\", hybrid3_r2_test)\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) RAE (Test):\", hybrid3_rae_test)\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) RRSE (Test):\", hybrid3_rrse_test)\n",
    "print(\"Hybrid Model 3 (Ridge + LWLR) CC (Test):\", hybrid3_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b5fadf",
   "metadata": {},
   "source": [
    "## Hybrid model 4: Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e8ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights for models\n",
    "weight_rf = 0.4\n",
    "weight_lgb = 0.3\n",
    "weight_catboost = 0.3\n",
    "\n",
    "# Combine predictions\n",
    "hybrid4_pred_val = (weight_rf * rf_pred_val + weight_lgb * lgb_pred_val + weight_catboost * catboost_pred_val)\n",
    "\n",
    "# Evaluate the performance of Hybrid Model 4\n",
    "hybrid4_rmse_val = np.sqrt(mean_squared_error(y_val, hybrid4_pred_val))\n",
    "hybrid4_mae_val = mean_absolute_error(y_val, hybrid4_pred_val)\n",
    "hybrid4_r2_val = r2_score(y_val, hybrid4_pred_val)\n",
    "hybrid4_rae_val = mean_absolute_percentage_error(y_val, hybrid4_pred_val)\n",
    "hybrid4_rrse_val = np.sqrt(np.sum((y_val - hybrid4_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "hybrid4_cc_val = np.corrcoef(y_val, hybrid4_pred_val)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) RMSE (Validation):\", hybrid4_rmse_val)\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) MAE (Validation):\", hybrid4_mae_val)\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) R-squared (Validation):\", hybrid4_r2_val)\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) RAE (Validation):\", hybrid4_rae_val)\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) RRSE (Validation):\", hybrid4_rrse_val)\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) CC (Validation):\", hybrid4_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db624188",
   "metadata": {},
   "source": [
    "## Hybrid model 4: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09784359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights for models\n",
    "weight_rf = 0.4\n",
    "weight_lgb = 0.3\n",
    "weight_catboost = 0.3\n",
    "\n",
    "\n",
    "rf_pred_test = best_rf.predict(X_test)  \n",
    "lgb_pred_test = best_lgb.predict(X_test) \n",
    "catboost_pred_test = best_catboost.predict(X_test)\n",
    "\n",
    "# Combine predictions for the test set\n",
    "hybrid4_pred_test = (weight_rf * rf_pred_test + weight_lgb * lgb_pred_test + weight_catboost * catboost_pred_test)\n",
    "\n",
    "# Evaluate the performance of Hybrid Model 4 on the test set\n",
    "hybrid4_rmse_test = np.sqrt(mean_squared_error(y_test, hybrid4_pred_test))\n",
    "hybrid4_mae_test = mean_absolute_error(y_test, hybrid4_pred_test)\n",
    "hybrid4_r2_test = r2_score(y_test, hybrid4_pred_test)\n",
    "hybrid4_rae_test = mean_absolute_percentage_error(y_test, hybrid4_pred_test)\n",
    "hybrid4_rrse_test = np.sqrt(np.sum((y_test - hybrid4_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "hybrid4_cc_test = np.corrcoef(y_test, hybrid4_pred_test)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) RMSE (Test):\", hybrid4_rmse_test)\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) MAE (Test):\", hybrid4_mae_test)\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) R-squared (Test):\", hybrid4_r2_test)\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) RAE (Test):\", hybrid4_rae_test)\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) RRSE (Test):\", hybrid4_rrse_test)\n",
    "print(\"Hybrid Model 4 (RF + LightGBM + CatBoost) CC (Test):\", hybrid4_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ca5e23",
   "metadata": {},
   "source": [
    "## Hybrid model 5: Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7fa830",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid5_pred_val = (rf_pred_val + gpr_pred_val + lgb_pred_val) / 3\n",
    "\n",
    "# Calculate metrics for the hybrid model 5 on validation set\n",
    "hybrid5_rmse_val = np.sqrt(mean_squared_error(y_val, hybrid5_pred_val))\n",
    "hybrid5_mae_val = mean_absolute_error(y_val, hybrid5_pred_val)\n",
    "hybrid5_r2_val = r2_score(y_val, hybrid5_pred_val)\n",
    "hybrid5_rae_val = mean_absolute_percentage_error(y_val, hybrid5_pred_val)\n",
    "hybrid5_rrse_val = np.sqrt(np.sum((y_val - hybrid5_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "hybrid5_cc_val = np.corrcoef(y_val, hybrid5_pred_val)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) RMSE:\", hybrid5_rmse_val)\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) MAE:\", hybrid5_mae_val)\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) R-squared:\", hybrid5_r2_val)\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) RAE:\", hybrid5_rae_val)\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) RRSE:\", hybrid5_rrse_val)\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) CC:\", hybrid5_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3ca246",
   "metadata": {},
   "source": [
    "## Hybrid model 5: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d1b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpr_pred_test = best_gpr.predict(X_test)\n",
    "\n",
    "hybrid5_pred_test = (rf_pred_test + gpr_pred_test + lgb_pred_test) / 3\n",
    "\n",
    "# Calculate metrics for the hybrid model 5 on the test set\n",
    "hybrid5_rmse_test = np.sqrt(mean_squared_error(y_test, hybrid5_pred_test))\n",
    "hybrid5_mae_test = mean_absolute_error(y_test, hybrid5_pred_test)\n",
    "hybrid5_r2_test = r2_score(y_test, hybrid5_pred_test)\n",
    "hybrid5_rae_test = mean_absolute_percentage_error(y_test, hybrid5_pred_test)\n",
    "hybrid5_rrse_test = np.sqrt(np.sum((y_test - hybrid5_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "hybrid5_cc_test = np.corrcoef(y_test, hybrid5_pred_test)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) RMSE (Test):\", hybrid5_rmse_test)\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) MAE (Test):\", hybrid5_mae_test)\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) R-squared (Test):\", hybrid5_r2_test)\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) RAE (Test):\", hybrid5_rae_test)\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) RRSE (Test):\", hybrid5_rrse_test)\n",
    "print(\"Hybrid Model 5 (RF + GPR + LightGBM) CC (Test):\", hybrid5_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c8f0a8",
   "metadata": {},
   "source": [
    "## Hybrid model 6: Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0b90c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid6_pred_val = (knn_pred + xgb_pred_val + catboost_pred_val) / 3\n",
    "\n",
    "# Calculate metrics for the hybrid model 6 on validation set\n",
    "hybrid6_rmse_val = np.sqrt(mean_squared_error(y_val, hybrid6_pred_val))\n",
    "hybrid6_mae_val = mean_absolute_error(y_val, hybrid6_pred_val)\n",
    "hybrid6_r2_val = r2_score(y_val, hybrid6_pred_val)\n",
    "hybrid6_rae_val = mean_absolute_percentage_error(y_val, hybrid6_pred_val)\n",
    "hybrid6_rrse_val = np.sqrt(np.sum((y_val - hybrid6_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "hybrid6_cc_val = np.corrcoef(y_val, hybrid6_pred_val)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) RMSE (Validation):\", hybrid6_rmse_val)\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) MAE (Validation):\", hybrid6_mae_val)\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) R-squared (Validation):\", hybrid6_r2_val)\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) RAE (Validation):\", hybrid6_rae_val)\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) RRSE (Validation):\", hybrid6_rrse_val)\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) CC (Validation):\", hybrid6_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a250919e",
   "metadata": {},
   "source": [
    "## Hybrid model 6: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c9a872",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn_pred_test = best_knn.predict(X_test)\n",
    "best_xgb_pred_test = best_xgb.predict(X_test)\n",
    "best_catboost_pred_test = best_catboost.predict(X_test)\n",
    "\n",
    "hybrid6_pred_test = (best_knn_pred_test + best_xgb_pred_test + best_catboost_pred_test) / 3\n",
    "\n",
    "# Calculate metrics for the hybrid model 6 on test set\n",
    "hybrid6_rmse_test = np.sqrt(mean_squared_error(y_test, hybrid6_pred_test))\n",
    "hybrid6_mae_test = mean_absolute_error(y_test, hybrid6_pred_test)\n",
    "hybrid6_r2_test = r2_score(y_test, hybrid6_pred_test)\n",
    "hybrid6_rae_test = mean_absolute_percentage_error(y_test, hybrid6_pred_test)\n",
    "hybrid6_rrse_test = np.sqrt(np.sum((y_test - hybrid6_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "hybrid6_cc_test = np.corrcoef(y_test, hybrid6_pred_test)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) RMSE (Test):\", hybrid6_rmse_test)\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) MAE (Test):\", hybrid6_mae_test)\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) R-squared (Test):\", hybrid6_r2_test)\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) RAE (Test):\", hybrid6_rae_test)\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) RRSE (Test):\", hybrid6_rrse_test)\n",
    "print(\"Hybrid Model 6 (KNN + XGB + CatBoost) CC (Test):\", hybrid6_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da6cba7",
   "metadata": {},
   "source": [
    "## Hybrid model 7: Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e2ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid7_pred_val = (rf_pred_val + lwlr_pred_val + gpr_pred_val + wknn_pred_val) / 4\n",
    "\n",
    "# Calculate metrics for the hybrid model 7 on validation set\n",
    "hybrid7_rmse_val = np.sqrt(mean_squared_error(y_val, hybrid7_pred_val))\n",
    "hybrid7_mae_val = mean_absolute_error(y_val, hybrid7_pred_val)\n",
    "hybrid7_r2_val = r2_score(y_val, hybrid7_pred_val)\n",
    "hybrid7_rae_val = mean_absolute_percentage_error(y_val, hybrid7_pred_val)\n",
    "hybrid7_rrse_val = np.sqrt(np.sum((y_val - hybrid7_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "hybrid7_cc_val = np.corrcoef(y_val, hybrid7_pred_val)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) RMSE (Validation):\", hybrid7_rmse_val)\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) MAE (Validation):\", hybrid7_mae_val)\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) R-squared (Validation):\", hybrid7_r2_val)\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) RAE (Validation):\", hybrid7_rae_val)\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) RRSE (Validation):\", hybrid7_rrse_val)\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) CC (Validation):\", hybrid7_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb54ec10",
   "metadata": {},
   "source": [
    "## Hybrid model 7: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90405ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set using Random Forest Regressor\n",
    "rf_pred_test = best_rf.predict(X_test)\n",
    "\n",
    "# Predict on the test set using Locally Weighted Linear Regression\n",
    "lwlr_pred_test = best_lwlr.predict(X_test)\n",
    "\n",
    "# Predict on the test set using Gaussian Process Regressor\n",
    "gpr_pred_test = best_gpr.predict(X_test)\n",
    "\n",
    "# Predict on the test set using Weighted k-Nearest Neighbors Regressor\n",
    "wknn_pred_test = best_wknn.predict(X_test)\n",
    "\n",
    "hybrid7_pred_test = (rf_pred_test + lwlr_pred_test + gpr_pred_test + wknn_pred_test) / 4\n",
    "\n",
    "# Calculate metrics for the hybrid model 7 on test set\n",
    "hybrid7_rmse_test = np.sqrt(mean_squared_error(y_test, hybrid7_pred_test))\n",
    "hybrid7_mae_test = mean_absolute_error(y_test, hybrid7_pred_test)\n",
    "hybrid7_r2_test = r2_score(y_test, hybrid7_pred_test)\n",
    "hybrid7_rae_test = mean_absolute_percentage_error(y_test, hybrid7_pred_test)\n",
    "hybrid7_rrse_test = np.sqrt(np.sum((y_test - hybrid7_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "hybrid7_cc_test = np.corrcoef(y_test, hybrid7_pred_test)[0, 1]\n",
    "\n",
    "# Print evaluation metrics for Hybrid Model 7\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) RMSE (Test):\", hybrid7_rmse_test)\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) MAE (Test):\", hybrid7_mae_test)\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) R-squared (Test):\", hybrid7_r2_test)\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) RAE (Test):\", hybrid7_rae_test)\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) RRSE (Test):\", hybrid7_rrse_test)\n",
    "print(\"Hybrid Model 7 (RF + LWLR + GPR + WKNN) CC (Test):\", hybrid7_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c569206",
   "metadata": {},
   "source": [
    "## Hybrid model 8: Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d7c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid8_pred_val = (xgb_pred_val + catboost_pred_val + lgb_pred_val + ridge_pred_val) / 4\n",
    "\n",
    "# Calculate metrics for the hybrid model on validation set\n",
    "hybrid8_rmse_val = np.sqrt(mean_squared_error(y_val, hybrid8_pred_val))\n",
    "hybrid8_mae_val = mean_absolute_error(y_val, hybrid8_pred_val)\n",
    "hybrid8_r2_val = r2_score(y_val, hybrid8_pred_val)\n",
    "hybrid8_rae_val = mean_absolute_percentage_error(y_val, hybrid8_pred_val)\n",
    "hybrid8_rrse_val = np.sqrt(np.sum((y_val - hybrid8_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "hybrid8_cc_val = np.corrcoef(y_val, hybrid8_pred_val)[0, 1]\n",
    "\n",
    "# Print evaluation metrics for Hybrid Model 8\n",
    "print(\"Hybrid Model 8 (XGB + CatBoost + GBR + Ridge) RMSE (Validation):\", hybrid8_rmse_val)\n",
    "print(\"Hybrid Model 8 (XGB + CatBoost + GBR + Ridge) MAE (Validation):\", hybrid8_mae_val)\n",
    "print(\"Hybrid Model 8 (XGB + CatBoost + GBR + Ridge) R-squared (Validation):\", hybrid8_r2_val)\n",
    "print(\"Hybrid Model 8 (XGB + CatBoost + GBR + Ridge) RAE (Validation):\", hybrid8_rae_val)\n",
    "print(\"Hybrid Model 8 (XGB + CatBoost + GBR + Ridge) RRSE (Validation):\", hybrid8_rrse_val)\n",
    "print(\"Hybrid Model 8 (XGB + CatBoost + GBR + Ridge) CC (Validation):\", hybrid8_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0acacce",
   "metadata": {},
   "source": [
    "## Hybrid model 8: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b594c43c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict on the test set using the hybrid model\n",
    "hybrid8_pred_test = (best_xgb.predict(X_test) + best_catboost.predict(X_test) + best_lgb.predict(X_test) + best_ridge.predict(X_test)) / 4\n",
    "\n",
    "# Calculate metrics for the hybrid model 8 on the test set\n",
    "hybrid8_rmse_test = np.sqrt(mean_squared_error(y_test, hybrid8_pred_test))\n",
    "hybrid8_mae_test = mean_absolute_error(y_test, hybrid8_pred_test)\n",
    "hybrid8_r2_test = r2_score(y_test, hybrid8_pred_test)\n",
    "hybrid8_rae_test = mean_absolute_percentage_error(y_test, hybrid8_pred_test)\n",
    "hybrid8_rrse_test = np.sqrt(np.sum((y_test - hybrid8_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "hybrid8_cc_test = np.corrcoef(y_test, hybrid8_pred_test)[0, 1]\n",
    "\n",
    "# Print evaluation metrics for the hybrid model 8 on the test set\n",
    "print(\"Hybrid Model 5 (XGB + CatBoost + GBR + Ridge) RMSE (Test):\", hybrid8_rmse_test)\n",
    "print(\"Hybrid Model 5 (XGB + CatBoost + GBR + Ridge) MAE (Test):\", hybrid8_mae_test)\n",
    "print(\"Hybrid Model 5 (XGB + CatBoost + GBR + Ridge) R-squared (Test):\", hybrid8_r2_test)\n",
    "print(\"Hybrid Model 5 (XGB + CatBoost + GBR + Ridge) RAE (Test):\", hybrid8_rae_test)\n",
    "print(\"Hybrid Model 5 (XGB + CatBoost + GBR + Ridge) RRSE (Test):\", hybrid8_rrse_test)\n",
    "print(\"Hybrid Model 5 (XGB + CatBoost + GBR + Ridge) CC (Test):\", hybrid8_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5becd",
   "metadata": {},
   "source": [
    "## Hybrid model 9: Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23037212",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('rf', best_rf),\n",
    "    ('gpr', best_gpr),\n",
    "    ('lgb', best_lgb),\n",
    "    ('xgb', best_xgb),\n",
    "    ('catboost', best_catboost)\n",
    "]\n",
    "\n",
    "# Define the stacking model with a meta regressor \n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=best_lgb,  \n",
    "    cv=5  \n",
    ")\n",
    "\n",
    "# Fit the stacking model on the training data\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set using the stacking model\n",
    "hybrid9_pred_val = stacking_model.predict(X_val)\n",
    "\n",
    "# Calculate metrics for the hybrid model 9 on the validation set\n",
    "hybrid9_rmse_val = np.sqrt(mean_squared_error(y_val, hybrid9_pred_val))\n",
    "hybrid9_mae_val = mean_absolute_error(y_val, hybrid9_pred_val)\n",
    "hybrid9_r2_val = r2_score(y_val, hybrid9_pred_val)\n",
    "hybrid9_rae_val = mean_absolute_percentage_error(y_val, hybrid9_pred_val)\n",
    "hybrid9_rrse_val = np.sqrt(np.sum((y_val - hybrid9_pred_val)**2) / np.sum((y_val - np.mean(y_val))**2))\n",
    "hybrid9_cc_val = np.corrcoef(y_val, hybrid9_pred_val)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 9 RMSE (Validation):\", hybrid9_rmse_val)\n",
    "print(\"Hybrid Model 9 MAE (Validation):\", hybrid9_mae_val)\n",
    "print(\"Hybrid Model 9 R-squared (Validation):\", hybrid9_r2_val)\n",
    "print(\"Hybrid Model 9 RAE (Validation):\", hybrid9_rae_val)\n",
    "print(\"Hybrid Model 9 RRSE (Validation):\", hybrid9_rrse_val)\n",
    "print(\"Hybrid Model 9 CC (Validation):\", hybrid9_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5f32f7",
   "metadata": {},
   "source": [
    "## Hybrid model 9: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc2e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set using the stacking model\n",
    "hybrid9_pred_test = stacking_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for the hybrid model 9 on test set\n",
    "hybrid9_rmse_test = np.sqrt(mean_squared_error(y_test, hybrid9_pred_test))\n",
    "hybrid9_mae_test = mean_absolute_error(y_test, hybrid9_pred_test)\n",
    "hybrid9_r2_test = r2_score(y_test, hybrid9_pred_test)\n",
    "hybrid9_rae_test = mean_absolute_percentage_error(y_test, hybrid9_pred_test)\n",
    "hybrid9_rrse_test = np.sqrt(np.sum((y_test - hybrid9_pred_test)**2) / np.sum((y_test - np.mean(y_test))**2))\n",
    "hybrid9_cc_test = np.corrcoef(y_test, hybrid9_pred_test)[0, 1]\n",
    "\n",
    "print(\"Hybrid Model 9 RMSE (Test):\", hybrid9_rmse_test)\n",
    "print(\"Hybrid Model 9 MAE (Test):\", hybrid9_mae_test)\n",
    "print(\"Hybrid Model 9 R-squared (Test):\", hybrid9_r2_test)\n",
    "print(\"Hybrid Model 9 RAE (Test):\", hybrid9_rae_test)\n",
    "print(\"Hybrid Model 9 RRSE (Test):\", hybrid9_rrse_test)\n",
    "print(\"Hybrid Model 9 CC (Test):\", hybrid9_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57041f40",
   "metadata": {},
   "source": [
    "## Hybrid model 10: Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a765c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the weights for each model\n",
    "weight_rf = 0.2\n",
    "weight_lwlr = 0.2\n",
    "weight_gpr = 0.1\n",
    "weight_wknn = 0.1\n",
    "weight_knn = 0.1\n",
    "weight_xgb = 0.05\n",
    "weight_catboost = 0.05\n",
    "weight_lgb = 0.05\n",
    "weight_gbr = 0.05\n",
    "weight_ridge = 0.05\n",
    "\n",
    "# Create hybrid predictions\n",
    "hybrid10_pred_val = (\n",
    "    weight_rf * rf_pred_val +\n",
    "    weight_lwlr * lwlr_pred_val +\n",
    "    weight_gpr * gpr_pred_val +\n",
    "    weight_wknn * wknn_pred_val +\n",
    "    weight_knn * knn_pred + \n",
    "    weight_xgb * xgb_pred_val +\n",
    "    weight_catboost * catboost_pred_val +\n",
    "    weight_gbr * gbr_pred_val +\n",
    "    weight_lgb * lgb_pred_val +\n",
    "    weight_ridge * ridge_pred_val  \n",
    ")\n",
    "\n",
    "# Calculate metrics for the hybrid model 10 on the validation set\n",
    "hybrid10_rmse_val = mean_squared_error(y_val, hybrid10_pred_val, squared=False)\n",
    "hybrid10_mae_val = mean_absolute_error(y_val, hybrid10_pred_val)\n",
    "hybrid10_r2_val = r2_score(y_val, hybrid10_pred_val)\n",
    "hybrid10_rae_val = hybrid10_mae_val / np.mean(np.abs(y_val - np.mean(y_val)))\n",
    "hybrid10_rrse_val = hybrid10_rmse_val / np.sqrt(np.mean((y_val - np.mean(y_val))**2))\n",
    "hybrid10_cc_val = np.corrcoef(y_val, hybrid10_pred_val)[0, 1]\n",
    "\n",
    "# Print evaluation metrics for the hybrid model 10 on the validation set\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) RMSE (Validation):\", hybrid10_rmse_val)\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) MAE (Validation):\", hybrid10_mae_val)\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) R-squared (Validation):\", hybrid10_r2_val)\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) RAE (Validation):\", hybrid10_rae_val)\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) RRSE (Validation):\", hybrid10_rrse_val)\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) CC (Validation):\", hybrid10_cc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb62c32",
   "metadata": {},
   "source": [
    "## Hybrid model 10: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4653c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the weights for each model\n",
    "weight_rf = 0.2\n",
    "weight_lwlr = 0.2\n",
    "weight_gpr = 0.1\n",
    "weight_wknn = 0.1\n",
    "weight_knn = 0.1\n",
    "weight_xgb = 0.05\n",
    "weight_catboost = 0.05\n",
    "weight_lgb = 0.05\n",
    "weight_gbr = 0.05\n",
    "weight_ridge = 0.05\n",
    "\n",
    "\n",
    "rf_pred_test = best_rf.predict(X_test)\n",
    "lwlr_pred_test = best_lwlr.predict(X_test)\n",
    "gpr_pred_test = best_gpr.predict(X_test)\n",
    "wknn_pred_test=best_wknn.predict(X_test)\n",
    "knn_pred_test=best_knn.predict(X_test)\n",
    "xgb_pred_test = best_xgb.predict(X_test)\n",
    "catboost_pred_test = best_catboost.predict(X_test)\n",
    "gbr_pred_test = best_gbr.predict(X_test)\n",
    "lgb_pred_test = best_lgb.predict(X_test)\n",
    "ridge_pred_test = best_ridge.predict(X_test)\n",
    "\n",
    "# Create hybrid predictions\n",
    "hybrid10_pred_test = (\n",
    "    weight_rf * rf_pred_test +\n",
    "    weight_lwlr * lwlr_pred_test +\n",
    "    weight_gpr * gpr_pred_test +\n",
    "    weight_wknn * wknn_pred_test +\n",
    "    weight_knn * knn_pred + \n",
    "    weight_xgb * xgb_pred_test +\n",
    "    weight_catboost * catboost_pred_test +\n",
    "    weight_gbr * gbr_pred_test +\n",
    "    weight_lgb * lgb_pred_test +\n",
    "    weight_ridge * ridge_pred_test  \n",
    ")\n",
    "\n",
    "# Calculate metrics for the hybrid model 10 on the test set\n",
    "\n",
    "hybrid10_rmse_test = mean_squared_error(y_test, hybrid10_pred_test, squared=False)\n",
    "hybrid10_mae_test = mean_absolute_error(y_test, hybrid10_pred_test)\n",
    "hybrid10_r2_test = r2_score(y_test, hybrid10_pred_test)\n",
    "hybrid10_rae_test = hybrid10_mae_test / np.mean(np.abs(y_test - np.mean(y_test)))\n",
    "hybrid10_rrse_test = hybrid10_rmse_test / np.sqrt(np.mean((y_test - np.mean(y_test))**2))\n",
    "hybrid10_cc_test = np.corrcoef(y_test, hybrid10_pred_test)[0, 1]\n",
    "\n",
    "\n",
    "# Print etestuation metrics for the hybrid model 10 on the test set\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) RMSE (Test):\", hybrid10_rmse_test)\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) MAE (Test):\", hybrid10_mae_test)\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) R-squared (Test):\", hybrid10_r2_test)\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) RAE (Test):\", hybrid10_rae_test)\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) RRSE (Test):\", hybrid10_rrse_test)\n",
    "print(\"Hybrid Model 10 (RF + LWLR + GPR + WKNN + KNN + XGB + CatBoost + LGB + GBR + Ridge) CC (Test):\", hybrid10_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dd5b90",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56cb7e3",
   "metadata": {},
   "source": [
    "## Scatter plot: Validation: Actual vs. Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3bc900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "\n",
    "plt.scatter(y_val, hybrid1_pred_val, color='red', edgecolors='black', s=40, linewidths=1.5, label='Hybrid Model 1')\n",
    "plt.scatter(y_val, hybrid2_pred_val, color='green', edgecolors='red', s=70, linewidths=1.5, alpha=0.2, label='Hybrid Model 2')\n",
    "plt.scatter(y_val, hybrid3_pred_val, color='blue', edgecolors='black', s=50, linewidths=1.5,alpha=0.1, label='Hybrid Model 3')\n",
    "plt.scatter(y_val, hybrid4_pred_val, color='orange', edgecolors='black', s=70, linewidths=1.5, label='Hybrid Model 4')\n",
    "plt.scatter(y_val,  hybrid5_pred_val, color='purple', edgecolors='blue', s=50, linewidths=1.5, label='Hybrid Model 5')\n",
    "plt.scatter(y_val, hybrid6_pred_val, color='pink', edgecolors='black', s=70, linewidths=1.5,alpha=0.3, label='Hybrid Model 6')\n",
    "plt.scatter(y_val,  hybrid7_pred_val, color='purple', edgecolors='black', s=50, linewidths=1.5, label='Hybrid Model 7')\n",
    "plt.scatter(y_val, hybrid8_pred_val, color='cyan', edgecolors='black', s=40, linewidths=1.5,alpha=0.2, label='Hybrid Model 8')\n",
    "plt.scatter(y_val, hybrid9_pred_val, color='#FF00FF', edgecolors='black', s=50, linewidths=1.5, label='Hybrid Model 9')\n",
    "plt.scatter(y_val, hybrid10_pred_val, color='#00FFFF', edgecolors='black', s=50, linewidths=2,alpha=0.1 ,label='Hybrid Model 10')\n",
    "\n",
    "plt.plot([2, 6], [2, 6], color='black')\n",
    "plt.xlabel('Actual GWL(val)')\n",
    "plt.ylabel('Predicted GWL(val)')\n",
    "plt.text(0.02, 0.98, \"Rangpur-27\", transform=plt.gca().transAxes, va='top', ha='left', fontsize=10)\n",
    "plt.grid(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96757e7",
   "metadata": {},
   "source": [
    "## Scatter plot: Test: Actual vs. Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dcf9c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "\n",
    "plt.scatter(y_test, hybrid1_pred_test, color='red', edgecolors='black', s=40, linewidths=1.5, label='Hybrid Model 1')\n",
    "plt.scatter(y_test, hybrid2_pred_test, color='green', edgecolors='red', s=70, linewidths=1.5, alpha=0.2, label='Hybrid Model 2')\n",
    "plt.scatter(y_test, hybrid3_pred_test, color='blue', edgecolors='black', s=50, linewidths=1.5,alpha=0.1, label='Hybrid Model 3')\n",
    "plt.scatter(y_test, hybrid4_pred_test, color='orange', edgecolors='black', s=70, linewidths=1.5, label='Hybrid Model 4')\n",
    "plt.scatter(y_test,  hybrid5_pred_test, color='purple', edgecolors='blue', s=50, linewidths=1.5, label='Hybrid Model 5')\n",
    "plt.scatter(y_test, hybrid6_pred_test, color='pink', edgecolors='black', s=70, linewidths=1.5,alpha=0.3, label='Hybrid Model 6')\n",
    "plt.scatter(y_test,  hybrid7_pred_test, color='purple', edgecolors='black', s=50, linewidths=1.5, label='Hybrid Model 7')\n",
    "plt.scatter(y_test, hybrid8_pred_test, color='cyan', edgecolors='black', s=40, linewidths=1.5,alpha=0.2, label='Hybrid Model 8')\n",
    "plt.scatter(y_test, hybrid9_pred_test, color='#FF00FF', edgecolors='black', s=50, linewidths=1.5, label='Hybrid Model 9')\n",
    "plt.scatter(y_test, hybrid10_pred_test, color='#00FFFF', edgecolors='black', s=50, linewidths=2,alpha=0.1 ,label='Hybrid Model 10')\n",
    "\n",
    "plt.plot([2, 6], [2, 6], color='black')\n",
    "plt.xlabel('Actual GWL(Test)')\n",
    "plt.ylabel('Predicted GWL(Test)')\n",
    "plt.text(0.02, 0.98, \"Rangpur-27\", transform=plt.gca().transAxes, va='top', ha='left', fontsize=10)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c430f539",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the models and their corresponding predictions\n",
    "models_predictions = {\n",
    "    'Hybrid Model 1': hybrid1_pred_test,\n",
    "    'Hybrid Model 2': hybrid2_pred_test,\n",
    "    'Hybrid Model 3': hybrid3_pred_test,\n",
    "    'Hybrid Model 4': hybrid4_pred_test,\n",
    "    'Hybrid Model 5': hybrid5_pred_test,\n",
    "    'Hybrid Model 6': hybrid6_pred_test,\n",
    "    'Hybrid Model 7': hybrid7_pred_test,\n",
    "    'Hybrid Model 8': hybrid8_pred_test,\n",
    "    'Hybrid Model 9': hybrid9_pred_test,\n",
    "    'Hybrid Model 10': hybrid10_pred_test\n",
    "}\n",
    "\n",
    "# Create a DataFrame for the actual values (y_test)\n",
    "actual_values = pd.DataFrame({'Actual Values': y_test.values})\n",
    "\n",
    "# Create a plot with adjusted figure size and margins\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot the actual values\n",
    "plt.plot(actual_values.index, actual_values['Actual Values'], label='Actual Values', linestyle='-', marker='o', markersize=3)\n",
    "\n",
    "# Plot the predicted values for each model\n",
    "for model_name, predictions in models_predictions.items():\n",
    "    plt.plot(actual_values.index, predictions, label=model_name, linestyle='-', marker='o', markersize=3, alpha=0.7)\n",
    "\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Actual-Predicted GWL(m)')\n",
    "\n",
    "# Add text \"Rangpur-27\" at the bottom right corner with slight adjustment upwards\n",
    "plt.text(actual_values.index.max(), plt.ylim()[0] + 0.2, \"Rangpur-27\", va='bottom', ha='right', fontsize=10)\n",
    "\n",
    "plt.grid(False)\n",
    "\n",
    "# Manually adjust the margins\n",
    "plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5ec00e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the models and their corresponding predictions\n",
    "models_predictions_val = {\n",
    "    'Hybrid Model 1': hybrid1_pred_val,\n",
    "    'Hybrid Model 2': hybrid2_pred_val,\n",
    "    'Hybrid Model 3': hybrid3_pred_val,\n",
    "    'Hybrid Model 4': hybrid4_pred_val,\n",
    "    'Hybrid Model 5': hybrid5_pred_val,\n",
    "    'Hybrid Model 6': hybrid6_pred_val,\n",
    "    'Hybrid Model 7': hybrid7_pred_val,\n",
    "    'Hybrid Model 8': hybrid8_pred_val,\n",
    "    'Hybrid Model 9': hybrid9_pred_val,\n",
    "    'Hybrid Model 10': hybrid10_pred_val\n",
    "}\n",
    "\n",
    "# Create a DataFrame for the actual values (y_val)\n",
    "actual_values = pd.DataFrame({'Actual Values': y_val.values})\n",
    "\n",
    "# Create a plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot the actual values\n",
    "plt.plot(actual_values.index, actual_values['Actual Values'], label='Actual Values', linestyle='-', marker='o', markersize=3)\n",
    "\n",
    "# Plot the predicted values for each model\n",
    "for model_name, predictions in models_predictions_val.items():\n",
    "    plt.plot(actual_values.index, predictions, label=model_name, linestyle='-', marker='o', markersize=3, alpha=0.7)\n",
    "\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Actual-Predicted GWL(m)')\n",
    "plt.grid(False)\n",
    "plt.text(actual_values.index.max(), plt.ylim()[0] + 0.2, \"Rangpur-27\", va='bottom', ha='right', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa906a",
   "metadata": {},
   "source": [
    "# Validation stage: Distribution and Time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60371a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'Date' is a column in your original DataFrame 'df'\n",
    "dates_val = df.loc[y_val.index, 'Date']\n",
    "\n",
    "# Assuming 'hybrid1_pred_val' to 'hybrid10_pred_val' are your predicted values for 10 models\n",
    "hybrid_val_data = {'Actual Values': y_val.values,\n",
    "                    'Hybrid Model 1 Predictions': hybrid1_pred_val,\n",
    "                    'Hybrid Model 2 Predictions': hybrid2_pred_val,\n",
    "                    'Hybrid Model 3 Predictions': hybrid3_pred_val,\n",
    "                    'Hybrid Model 4 Predictions': hybrid4_pred_val,\n",
    "                    'Hybrid Model 5 Predictions': hybrid5_pred_val,\n",
    "                    'Hybrid Model 6 Predictions': hybrid6_pred_val,\n",
    "                    'Hybrid Model 7 Predictions': hybrid7_pred_val,\n",
    "                    'Hybrid Model 8 Predictions': hybrid8_pred_val,\n",
    "                    'Hybrid Model 9 Predictions': hybrid9_pred_val,\n",
    "                    'Hybrid Model 10 Predictions': hybrid10_pred_val,\n",
    "                    'Date': dates_val}\n",
    "\n",
    "hybrid_val_df = pd.DataFrame(hybrid_val_data)\n",
    "\n",
    "print(\"\\nValidation Set:\")\n",
    "hybrid_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f9013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to datetime format\n",
    "hybrid_val_df['Date'] = pd.to_datetime(hybrid_val_df['Date'], format='%d.%m.%Y')\n",
    "\n",
    "# Sort the DataFrame by 'Date'\n",
    "hybrid_val_df = hybrid_val_df.sort_values(by='Date')\n",
    "\n",
    "# Reset the index after sorting\n",
    "hybrid_val_df = hybrid_val_df.reset_index(drop=True)\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "hybrid_val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8cc16f",
   "metadata": {},
   "source": [
    "# Violin Plot: Distribution of Predicted vs Actual Values (Test Stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510f3415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'hybrid1_pred_val' to 'hybrid10_pred_val' are your predicted values for 10 models\n",
    "\n",
    "# Combine the predicted values into a single DataFrame\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Actual Values': y_val.values,\n",
    "    'Hybrid Model 1': hybrid1_pred_val,\n",
    "    'Hybrid Model 2': hybrid2_pred_val,\n",
    "    'Hybrid Model 3': hybrid3_pred_val,\n",
    "    'Hybrid Model 4': hybrid4_pred_val,\n",
    "    'Hybrid Model 5': hybrid5_pred_val,\n",
    "    'Hybrid Model 6': hybrid6_pred_val,\n",
    "    'Hybrid Model 7': hybrid7_pred_val,\n",
    "    'Hybrid Model 8': hybrid8_pred_val,\n",
    "    'Hybrid Model 9': hybrid9_pred_val,\n",
    "    'Hybrid Model 10': hybrid10_pred_val,\n",
    "})\n",
    "\n",
    "# Create a violin plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "ax = sns.violinplot(data=predictions_df)\n",
    "plt.text(0.02, 0.98, \"Rangpur-27\", transform=plt.gca().transAxes, va='top', ha='left', fontsize=10)\n",
    "plt.xlabel('Hybrid Models')\n",
    "plt.ylabel('Actual-Predicted GWL(m)')\n",
    "# Rotate x-axis ticks by 90 degrees\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dab1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the sorted DataFrame\n",
    "hybrid_val_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621814d4",
   "metadata": {},
   "source": [
    "# Time series plots: Test stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8264124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "hybrid_val_df['Date'] = pd.to_datetime(hybrid_val_df['Date'], format='%d.%m.%Y')\n",
    "\n",
    "# Sort the DataFrame by 'Date'\n",
    "hybrid_val_df = hybrid_val_df.sort_values(by='Date')\n",
    "\n",
    "# Reset the index after sorting\n",
    "hybrid_val_df = hybrid_val_df.reset_index(drop=True)\n",
    "\n",
    "# Create a time series plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Iterate over the hybrid models and plot their predictions\n",
    "for col in hybrid_val_df.columns[:-1]:\n",
    "    plt.plot(hybrid_val_df['Date'], hybrid_val_df[col], label=col)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Actual-Predicted GWL(m)')\n",
    "\n",
    "# Rotate x-axis labels for better visibility\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Set the date tick frequency to display every year\n",
    "plt.gca().xaxis.set_major_locator(mdates.YearLocator())\n",
    "\n",
    "# Set the x-axis limits to show data only from 1992 to 2018\n",
    "plt.xlim(pd.Timestamp('1992-10-01'), pd.Timestamp('2018-01-31'))\n",
    "\n",
    "\n",
    "plt.text(0.02, 0.98, \"Rangpur-27\", transform=plt.gca().transAxes, va='top', ha='left', fontsize=10)\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da19fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "hybrid_val_df['Date'] = pd.to_datetime(hybrid_val_df['Date'], format='%d.%m.%Y')\n",
    "\n",
    "# Sort the DataFrame by 'Date'\n",
    "hybrid_val_df = hybrid_val_df.sort_values(by='Date')\n",
    "\n",
    "# Reset the index after sorting\n",
    "hybrid_val_df = hybrid_val_df.reset_index(drop=True)\n",
    "\n",
    "# Create a time series plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Iterate over the hybrid models and plot their predictions\n",
    "for col in hybrid_val_df.columns[:-1]:\n",
    "    plt.plot(hybrid_val_df['Date'], hybrid_val_df[col], label=col, linewidth=1.2)  \n",
    "\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Actual-Predicted GWL(m)')\n",
    "\n",
    "# Rotate x-axis labels for better visibility\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Set the date tick frequency to display every year\n",
    "plt.gca().xaxis.set_major_locator(mdates.YearLocator())\n",
    "\n",
    "# Set the x-axis limits to show data only from 1992 to 2018\n",
    "plt.xlim(pd.Timestamp('1992-10-01'), pd.Timestamp('2018-01-31'))\n",
    "\n",
    "\n",
    "plt.text(0.02, 0.98, \"Rangpur-27\", transform=plt.gca().transAxes, va='top', ha='left', fontsize=10)\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b169fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "hybrid_val_df['Date'] = pd.to_datetime(hybrid_val_df['Date'], format='%d.%m.%Y')\n",
    "\n",
    "# Sort the DataFrame by 'Date'\n",
    "hybrid_val_df = hybrid_val_df.sort_values(by='Date')\n",
    "\n",
    "# Reset the index after sorting\n",
    "hybrid_val_df = hybrid_val_df.reset_index(drop=True)\n",
    "\n",
    "# Create a time series plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Iterate over the hybrid models and plot their predictions\n",
    "for col in hybrid_val_df.columns[:-1]:\n",
    "    plt.plot(hybrid_val_df['Date'], hybrid_val_df[col], label=col)\n",
    "\n",
    "# Add labels and title\n",
    "\n",
    "plt.ylabel('Actual-Predicted GWL(m)')\n",
    "\n",
    "# Rotate x-axis labels for better visibility\n",
    "plt.xticks(rotation=90, color='white')  # Set xticks color to white\n",
    "\n",
    "# Set the date tick frequency to display every year\n",
    "plt.gca().xaxis.set_major_locator(mdates.YearLocator())\n",
    "\n",
    "# Set the x-axis limits to show data only from 1992 to 2018\n",
    "plt.xlim(pd.Timestamp('1992-10-01'), pd.Timestamp('2018-01-31'))\n",
    "\n",
    "\n",
    "plt.text(0.02, 0.98, \"Rangpur-27\", transform=plt.gca().transAxes, va='top', ha='left', fontsize=10)\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c75ae4",
   "metadata": {},
   "source": [
    "# Test stage: Distribution and Time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca31aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'Date' is a column in your original DataFrame 'df'\n",
    "dates_test = df.loc[y_test.index, 'Date']\n",
    "\n",
    "# Assuming 'hybrid1_pred_test' to 'hybrid10_pred_test' are your predicted values for 10 models\n",
    "hybrid_test_data = {'Actual Values': y_test.values,\n",
    "                    'Hybrid Model 1 Predictions': hybrid1_pred_test,\n",
    "                    'Hybrid Model 2 Predictions': hybrid2_pred_test,\n",
    "                    'Hybrid Model 3 Predictions': hybrid3_pred_test,\n",
    "                    'Hybrid Model 4 Predictions': hybrid4_pred_test,\n",
    "                    'Hybrid Model 5 Predictions': hybrid5_pred_test,\n",
    "                    'Hybrid Model 6 Predictions': hybrid6_pred_test,\n",
    "                    'Hybrid Model 7 Predictions': hybrid7_pred_test,\n",
    "                    'Hybrid Model 8 Predictions': hybrid8_pred_test,\n",
    "                    'Hybrid Model 9 Predictions': hybrid9_pred_test,\n",
    "                    'Hybrid Model 10 Predictions': hybrid10_pred_test,\n",
    "                    'Date': dates_test}\n",
    "\n",
    "hybrid_test_df = pd.DataFrame(hybrid_test_data)\n",
    "\n",
    "print(\"\\nTest Set:\")\n",
    "hybrid_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c5c511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to datetime format\n",
    "hybrid_test_df['Date'] = pd.to_datetime(hybrid_test_df['Date'], format='%d.%m.%Y')\n",
    "\n",
    "# Sort the DataFrame by 'Date'\n",
    "hybrid_test_df = hybrid_test_df.sort_values(by='Date')\n",
    "\n",
    "# Reset the index after sorting\n",
    "hybrid_test_df = hybrid_test_df.reset_index(drop=True)\n",
    "hybrid_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e5bad3",
   "metadata": {},
   "source": [
    "# Violin Plot: Distribution of Predicted vs Actual Values (Test Stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9a53c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'hybrid1_pred_test' to 'hybrid10_pred_test' are your predicted values for 10 models\n",
    "\n",
    "# Combine the predicted values into a single DataFrame\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Actual': y_test.values,\n",
    "    'Model 1': hybrid1_pred_test,\n",
    "    'Model 2': hybrid2_pred_test,\n",
    "    'Model 3': hybrid3_pred_test,\n",
    "    'Model 4': hybrid4_pred_test,\n",
    "    'Model 5': hybrid5_pred_test,\n",
    "    'Model 6': hybrid6_pred_test,\n",
    "    'Model 7': hybrid7_pred_test,\n",
    "    'Model 8': hybrid8_pred_test,\n",
    "    'Model 9': hybrid9_pred_test,\n",
    "    'Model 10': hybrid10_pred_test,\n",
    "})\n",
    "\n",
    "# Create a violin plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "ax = sns.violinplot(data=predictions_df)\n",
    "plt.xlabel('Hybrid Models')\n",
    "plt.ylabel('Actual-Predicted GWL(m)')\n",
    "plt.text(0.02, 0.98, \"Rangpur-27\", transform=plt.gca().transAxes, va='top', ha='left', fontsize=10)\n",
    "# Rotate x-axis ticks by 90 degrees\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73949b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to datetime format\n",
    "hybrid_test_df['Date'] = pd.to_datetime(hybrid_test_df['Date'], format='%d.%m.%Y')\n",
    "\n",
    "# Sort the DataFrame by 'Date'\n",
    "hybrid_test_df = hybrid_test_df.sort_values(by='Date')\n",
    "\n",
    "# Reset the index after sorting\n",
    "hybrid_test_df = hybrid_test_df.reset_index(drop=True)\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "hybrid_test_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d40cd1e",
   "metadata": {},
   "source": [
    "# Time series plots: Test stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f51235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "hybrid_test_df['Date'] = pd.to_datetime(hybrid_test_df['Date'], format='%d.%m.%Y')\n",
    "\n",
    "# Sort the DataFrame by 'Date'\n",
    "hybrid_test_df = hybrid_test_df.sort_values(by='Date')\n",
    "\n",
    "# Reset the index after sorting\n",
    "hybrid_test_df = hybrid_test_df.reset_index(drop=True)\n",
    "\n",
    "# Create a time series plot\n",
    "plt.figure(figsize=(10, 3))\n",
    "\n",
    "\n",
    "# Iterate over the hybrid models and plot their predictions\n",
    "for col in hybrid_test_df.columns[:-1]:\n",
    "    plt.plot(hybrid_test_df['Date'], hybrid_test_df[col], label=col)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Actual-Predicted GWL(m)')\n",
    "\n",
    "\n",
    "# Rotate x-axis labels for better visibility\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Set the date tick frequency to display every year\n",
    "plt.gca().xaxis.set_major_locator(mdates.YearLocator())\n",
    "\n",
    "# Set the x-axis limits to show data only from 1992 to 2018\n",
    "plt.xlim(pd.Timestamp('1992-10-01'), pd.Timestamp('2018-01-31'))\n",
    "\n",
    "plt.text(0.02, 0.98, \"Rangpur-27\", transform=plt.gca().transAxes, va='top', ha='left', fontsize=10)\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fe2bf4",
   "metadata": {},
   "source": [
    "# Density Plot: Validation stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac55a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Plotting density plots for each hybrid model\n",
    "sns.kdeplot(hybrid1_pred_val, color='green', label='Hybrid Model 1')\n",
    "sns.kdeplot(hybrid2_pred_val, color='blue', label='Hybrid Model 2')\n",
    "sns.kdeplot(hybrid3_pred_val, color='green', label='Hybrid Model 3')\n",
    "sns.kdeplot(hybrid4_pred_val, color='purple', label='Hybrid Model 4')\n",
    "sns.kdeplot(hybrid5_pred_val, color='orange', label='Hybrid Model 5')\n",
    "sns.kdeplot(hybrid6_pred_val, color='red', label='Hybrid Model 6')\n",
    "sns.kdeplot(hybrid7_pred_val, color='purple', label='Hybrid Model 7')\n",
    "sns.kdeplot(hybrid8_pred_val, color='orange', label='Hybrid Model 8')\n",
    "sns.kdeplot(hybrid9_pred_val, color='blue', label='Hybrid Model 9')\n",
    "sns.kdeplot(hybrid10_pred_val, color='red', label='Hybrid Model 10')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Actual-Predicted GWL(m)')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(False)\n",
    "plt.text(0.02, 0.98, \"Rangpur-27\", transform=plt.gca().transAxes, va='top', ha='left', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281fba3b",
   "metadata": {},
   "source": [
    "# Density Plot: Test stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1116a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Define a list of colors for the density plots\n",
    "colors = ['green', 'blue', 'green', 'purple', 'orange', 'red', 'purple', 'orange', 'blue', \"red\"]\n",
    "\n",
    "# Plotting density plots for each hybrid model with different colors\n",
    "sns.kdeplot(hybrid1_pred_test, color=colors[0], label='Hybrid Model 1')\n",
    "sns.kdeplot(hybrid2_pred_test, color=colors[1], alpha=0.3, label='Hybrid Model 2')\n",
    "sns.kdeplot(hybrid3_pred_test, color=colors[2], label='Hybrid Model 3')\n",
    "sns.kdeplot(hybrid4_pred_test, color=colors[3], label='Hybrid Model 4')\n",
    "sns.kdeplot(hybrid5_pred_test, color=colors[4], label='Hybrid Model 5')\n",
    "sns.kdeplot(hybrid6_pred_test, color=colors[5], label='Hybrid Model 6')\n",
    "sns.kdeplot(hybrid7_pred_test, color=colors[6], label='Hybrid Model 7')\n",
    "sns.kdeplot(hybrid8_pred_test, color=colors[7],label='Hybrid Model 8')\n",
    "sns.kdeplot(hybrid9_pred_test, color=colors[8], label='Hybrid Model 9')\n",
    "sns.kdeplot(hybrid10_pred_test, color=colors[9], alpha=0.3,label='Hybrid Model 10')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Actual-Predicted GWL(m)')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(False)\n",
    "plt.text(0.02, 0.98, \"Rangpur-27\", transform=plt.gca().transAxes, va='top', ha='left', fontsize=10)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
